[
  {
    "iteration": 1,
    "episode_reward_mean": -156.03333354897848,
    "episodes_this_iter": 4,
    "timesteps_total": 11000
  },
  {
    "iteration": 2,
    "episode_reward_mean": -158.90521955050946,
    "episodes_this_iter": 4,
    "timesteps_total": 13000
  },
  {
    "iteration": 3,
    "episode_reward_mean": -157.48600775493568,
    "episodes_this_iter": 4,
    "timesteps_total": 15000
  },
  {
    "iteration": 4,
    "episode_reward_mean": -160.81954930020032,
    "episodes_this_iter": 4,
    "timesteps_total": 17000
  },
  {
    "iteration": 5,
    "episode_reward_mean": -160.3663287849922,
    "episodes_this_iter": 4,
    "timesteps_total": 19000
  },
  {
    "iteration": 6,
    "episode_reward_mean": -157.4275350304111,
    "episodes_this_iter": 4,
    "timesteps_total": 21000
  },
  {
    "iteration": 7,
    "episode_reward_mean": -157.42974941610828,
    "episodes_this_iter": 4,
    "timesteps_total": 23000
  },
  {
    "iteration": 8,
    "episode_reward_mean": -160.98519042031842,
    "episodes_this_iter": 4,
    "timesteps_total": 25000
  },
  {
    "iteration": 9,
    "episode_reward_mean": -168.6354596758518,
    "episodes_this_iter": 4,
    "timesteps_total": 27000
  },
  {
    "iteration": 10,
    "episode_reward_mean": -178.232759429547,
    "episodes_this_iter": 4,
    "timesteps_total": 29000
  },
  {
    "iteration": 11,
    "episode_reward_mean": -179.17632336593928,
    "episodes_this_iter": 4,
    "timesteps_total": 31000
  },
  {
    "iteration": 12,
    "episode_reward_mean": -178.07509938013965,
    "episodes_this_iter": 4,
    "timesteps_total": 33000
  },
  {
    "iteration": 13,
    "episode_reward_mean": -174.61679420979922,
    "episodes_this_iter": 4,
    "timesteps_total": 35000
  },
  {
    "iteration": 14,
    "episode_reward_mean": -166.39329358679706,
    "episodes_this_iter": 4,
    "timesteps_total": 37000
  },
  {
    "iteration": 15,
    "episode_reward_mean": -160.12558344411897,
    "episodes_this_iter": 4,
    "timesteps_total": 39000
  },
  {
    "iteration": 16,
    "episode_reward_mean": -163.96003013520038,
    "episodes_this_iter": 4,
    "timesteps_total": 41000
  },
  {
    "iteration": 17,
    "episode_reward_mean": -169.26056066723078,
    "episodes_this_iter": 4,
    "timesteps_total": 43000
  },
  {
    "iteration": 18,
    "episode_reward_mean": -167.06418550515198,
    "episodes_this_iter": 4,
    "timesteps_total": 45000
  },
  {
    "iteration": 19,
    "episode_reward_mean": -164.37216613114575,
    "episodes_this_iter": 4,
    "timesteps_total": 47000
  },
  {
    "iteration": 20,
    "episode_reward_mean": -166.39363060076724,
    "episodes_this_iter": 4,
    "timesteps_total": 49000
  },
  {
    "iteration": 21,
    "episode_reward_mean": -163.07086231677798,
    "episodes_this_iter": 4,
    "timesteps_total": 51000
  },
  {
    "iteration": 22,
    "episode_reward_mean": -163.27787629912606,
    "episodes_this_iter": 4,
    "timesteps_total": 53000
  },
  {
    "iteration": 23,
    "episode_reward_mean": -156.90123982581076,
    "episodes_this_iter": 4,
    "timesteps_total": 55000
  },
  {
    "iteration": 24,
    "episode_reward_mean": -152.21108047210612,
    "episodes_this_iter": 4,
    "timesteps_total": 57000
  },
  {
    "iteration": 25,
    "episode_reward_mean": -155.74944525981434,
    "episodes_this_iter": 4,
    "timesteps_total": 59000
  },
  {
    "iteration": 26,
    "episode_reward_mean": -169.9260841660411,
    "episodes_this_iter": 4,
    "timesteps_total": 61000
  },
  {
    "iteration": 27,
    "episode_reward_mean": -169.29519351601365,
    "episodes_this_iter": 4,
    "timesteps_total": 63000
  },
  {
    "iteration": 28,
    "episode_reward_mean": -161.36166771233783,
    "episodes_this_iter": 4,
    "timesteps_total": 65000
  },
  {
    "iteration": 29,
    "episode_reward_mean": -160.7414270490198,
    "episodes_this_iter": 4,
    "timesteps_total": 67000
  },
  {
    "iteration": 30,
    "episode_reward_mean": -157.50354092738363,
    "episodes_this_iter": 4,
    "timesteps_total": 69000
  },
  {
    "iteration": 31,
    "episode_reward_mean": -162.1072345974471,
    "episodes_this_iter": 4,
    "timesteps_total": 71000
  },
  {
    "iteration": 32,
    "episode_reward_mean": -164.1391088892694,
    "episodes_this_iter": 4,
    "timesteps_total": 73000
  },
  {
    "iteration": 33,
    "episode_reward_mean": -160.0350709138566,
    "episodes_this_iter": 4,
    "timesteps_total": 75000
  },
  {
    "iteration": 34,
    "episode_reward_mean": -156.38897340068831,
    "episodes_this_iter": 4,
    "timesteps_total": 77000
  },
  {
    "iteration": 35,
    "episode_reward_mean": -165.76259954751237,
    "episodes_this_iter": 4,
    "timesteps_total": 79000
  },
  {
    "iteration": 36,
    "episode_reward_mean": -169.21235994477874,
    "episodes_this_iter": 4,
    "timesteps_total": 81000
  },
  {
    "iteration": 37,
    "episode_reward_mean": -165.54616089698627,
    "episodes_this_iter": 4,
    "timesteps_total": 83000
  },
  {
    "iteration": 38,
    "episode_reward_mean": -153.94524808957476,
    "episodes_this_iter": 4,
    "timesteps_total": 85000
  },
  {
    "iteration": 39,
    "episode_reward_mean": -147.62984552059442,
    "episodes_this_iter": 4,
    "timesteps_total": 87000
  },
  {
    "iteration": 40,
    "episode_reward_mean": -148.2303827107814,
    "episodes_this_iter": 4,
    "timesteps_total": 89000
  },
  {
    "iteration": 41,
    "episode_reward_mean": -151.21502924240193,
    "episodes_this_iter": 4,
    "timesteps_total": 91000
  },
  {
    "iteration": 42,
    "episode_reward_mean": -159.76852326558904,
    "episodes_this_iter": 4,
    "timesteps_total": 93000
  },
  {
    "iteration": 43,
    "episode_reward_mean": -164.4064499723702,
    "episodes_this_iter": 4,
    "timesteps_total": 95000
  },
  {
    "iteration": 44,
    "episode_reward_mean": -157.29674913313704,
    "episodes_this_iter": 4,
    "timesteps_total": 97000
  },
  {
    "iteration": 45,
    "episode_reward_mean": -149.5304329175758,
    "episodes_this_iter": 4,
    "timesteps_total": 99000
  },
  {
    "iteration": 46,
    "episode_reward_mean": -145.5341308481642,
    "episodes_this_iter": 4,
    "timesteps_total": 101000
  },
  {
    "iteration": 47,
    "episode_reward_mean": -150.61449320801535,
    "episodes_this_iter": 4,
    "timesteps_total": 103000
  },
  {
    "iteration": 48,
    "episode_reward_mean": -153.47113473637032,
    "episodes_this_iter": 4,
    "timesteps_total": 105000
  },
  {
    "iteration": 49,
    "episode_reward_mean": -155.52960378610993,
    "episodes_this_iter": 4,
    "timesteps_total": 107000
  },
  {
    "iteration": 50,
    "episode_reward_mean": -159.61111956030246,
    "episodes_this_iter": 4,
    "timesteps_total": 109000
  }
]