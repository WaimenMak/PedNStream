Iteration 0:  80%|████████  | 16/20 [00:33<00:08,  2.14s/it, episode=10, norm_ret=-12.442, true_ret=-298470688.000, steps=600]
Agent gate_2 episode reward: [-92.27945751]
All agents episode reward: [-92.27945751]
Agent gate_2 episode reward: [-3.65652583]
All agents episode reward: [-3.65652583]
Agent gate_2 episode reward: [-2.35091764]
All agents episode reward: [-2.35091764]
Agent gate_2 episode reward: [-4.48958999]
All agents episode reward: [-4.48958999]
Agent gate_2 episode reward: [-2.667574]
All agents episode reward: [-2.667574]
Agent gate_2 episode reward: [-3.83698512]
All agents episode reward: [-3.83698512]
Agent gate_2 episode reward: [-3.08982861]
All agents episode reward: [-3.08982861]
Agent gate_2 episode reward: [-3.72852265]
All agents episode reward: [-3.72852265]
Agent gate_2 episode reward: [-4.19165854]
All agents episode reward: [-4.19165854]
Agent gate_2 episode reward: [-4.12837152]
All agents episode reward: [-4.12837152]
Agent gate_2 episode reward: [-3.82901169]
All agents episode reward: [-3.82901169]
Agent gate_2 episode reward: [-5.31176009]
All agents episode reward: [-5.31176009]
Agent gate_2 episode reward: [-4.24010179]
All agents episode reward: [-4.24010179]
Agent gate_2 episode reward: [-4.81831149]
All agents episode reward: [-4.81831149]
Agent gate_2 episode reward: [-4.73362143]
All agents episode reward: [-4.73362143]
Agent gate_2 episode reward: [-5.04823275]
All agents episode reward: [-5.04823275]
Agent gate_2 episode reward: [-4.90631118]
All agents episode reward: [-4.90631118]
Agent gate_2 episode reward: [-4.812068]
All agents episode reward: [-4.812068]
Agent gate_2 episode reward: [-5.34649735]
All agents episode reward: [-5.34649735]
Agent gate_2 episode reward: [-5.67716496]
All agents episode reward: [-5.67716496]
Iteration 1:  80%|████████  | 16/20 [00:31<00:07,  1.97s/it, episode=30, norm_ret=-5.765, true_ret=-277417408.000, steps=600]
Agent gate_2 episode reward: [-5.32009369]
All agents episode reward: [-5.32009369]
Agent gate_2 episode reward: [-5.68987204]
All agents episode reward: [-5.68987204]
Agent gate_2 episode reward: [-5.53324015]
All agents episode reward: [-5.53324015]
Agent gate_2 episode reward: [-5.91404705]
All agents episode reward: [-5.91404705]
Agent gate_2 episode reward: [-5.457211]
All agents episode reward: [-5.457211]
Agent gate_2 episode reward: [-5.90764446]
All agents episode reward: [-5.90764446]
Agent gate_2 episode reward: [-6.22723019]
All agents episode reward: [-6.22723019]
Agent gate_2 episode reward: [-5.84435075]
All agents episode reward: [-5.84435075]
Agent gate_2 episode reward: [-5.93250299]
All agents episode reward: [-5.93250299]
Agent gate_2 episode reward: [-5.82093541]
All agents episode reward: [-5.82093541]
Agent gate_2 episode reward: [-6.14716548]
All agents episode reward: [-6.14716548]
Agent gate_2 episode reward: [-6.00000688]
All agents episode reward: [-6.00000688]
Agent gate_2 episode reward: [-6.51519283]
All agents episode reward: [-6.51519283]
Agent gate_2 episode reward: [-6.28454427]
All agents episode reward: [-6.28454427]
Agent gate_2 episode reward: [-6.77927741]
All agents episode reward: [-6.77927741]
Agent gate_2 episode reward: [-6.68904815]
All agents episode reward: [-6.68904815]
Agent gate_2 episode reward: [-6.69843798]
All agents episode reward: [-6.69843798]
Agent gate_2 episode reward: [-6.83197933]
All agents episode reward: [-6.83197933]
Agent gate_2 episode reward: [-6.6882544]
All agents episode reward: [-6.6882544]
Agent gate_2 episode reward: [-6.76724026]
All agents episode reward: [-6.76724026]
Iteration 2:  80%|████████  | 16/20 [00:31<00:07,  1.97s/it, episode=50, norm_ret=-8.858, true_ret=-278020000.000, steps=600]
Agent gate_2 episode reward: [-7.45707275]
All agents episode reward: [-7.45707275]
Agent gate_2 episode reward: [-6.44889109]
All agents episode reward: [-6.44889109]
Agent gate_2 episode reward: [-7.90586084]
All agents episode reward: [-7.90586084]
Agent gate_2 episode reward: [-6.85794074]
All agents episode reward: [-6.85794074]
Agent gate_2 episode reward: [-14.93307121]
All agents episode reward: [-14.93307121]
Agent gate_2 episode reward: [-7.66724996]
All agents episode reward: [-7.66724996]
Agent gate_2 episode reward: [-19.83616575]
All agents episode reward: [-19.83616575]
Agent gate_2 episode reward: [-6.16235721]
All agents episode reward: [-6.16235721]
Agent gate_2 episode reward: [-5.62955894]
All agents episode reward: [-5.62955894]
Agent gate_2 episode reward: [-5.67907873]
All agents episode reward: [-5.67907873]
Agent gate_2 episode reward: [-6.01459353]
All agents episode reward: [-6.01459353]
Agent gate_2 episode reward: [-6.20289564]
All agents episode reward: [-6.20289564]
Agent gate_2 episode reward: [-6.38631847]
All agents episode reward: [-6.38631847]
Agent gate_2 episode reward: [-5.58728114]
All agents episode reward: [-5.58728114]
Agent gate_2 episode reward: [-6.04547075]
All agents episode reward: [-6.04547075]
Agent gate_2 episode reward: [-6.5613967]
All agents episode reward: [-6.5613967]
Agent gate_2 episode reward: [-6.12269358]
All agents episode reward: [-6.12269358]
Agent gate_2 episode reward: [-6.05509554]
All agents episode reward: [-6.05509554]
Agent gate_2 episode reward: [-6.47034265]
All agents episode reward: [-6.47034265]
Agent gate_2 episode reward: [-5.83934422]
All agents episode reward: [-5.83934422]
Iteration 3:  80%|████████  | 16/20 [00:31<00:07,  1.98s/it, episode=70, norm_ret=-6.505, true_ret=-307648032.000, steps=600]
Agent gate_2 episode reward: [-6.27500535]
All agents episode reward: [-6.27500535]
Agent gate_2 episode reward: [-6.34171245]
All agents episode reward: [-6.34171245]
Agent gate_2 episode reward: [-6.27248061]
All agents episode reward: [-6.27248061]
Agent gate_2 episode reward: [-6.85010308]
All agents episode reward: [-6.85010308]
Agent gate_2 episode reward: [-6.89216441]
All agents episode reward: [-6.89216441]
Agent gate_2 episode reward: [-6.53178866]
All agents episode reward: [-6.53178866]
Agent gate_2 episode reward: [-6.31245405]
All agents episode reward: [-6.31245405]
Agent gate_2 episode reward: [-6.24254188]
All agents episode reward: [-6.24254188]
Agent gate_2 episode reward: [-6.32028916]
All agents episode reward: [-6.32028916]
Agent gate_2 episode reward: [-7.00953933]
All agents episode reward: [-7.00953933]
Agent gate_2 episode reward: [-6.46945668]
All agents episode reward: [-6.46945668]
Agent gate_2 episode reward: [-6.92812403]
All agents episode reward: [-6.92812403]
Agent gate_2 episode reward: [-7.16371828]
All agents episode reward: [-7.16371828]
Agent gate_2 episode reward: [-6.78313069]
All agents episode reward: [-6.78313069]
Agent gate_2 episode reward: [-6.80055671]
All agents episode reward: [-6.80055671]
Agent gate_2 episode reward: [-6.79057814]
All agents episode reward: [-6.79057814]
Agent gate_2 episode reward: [-6.53996571]
All agents episode reward: [-6.53996571]
Agent gate_2 episode reward: [-7.07887224]
All agents episode reward: [-7.07887224]
Agent gate_2 episode reward: [-7.36431798]
All agents episode reward: [-7.36431798]
Agent gate_2 episode reward: [-6.78281123]
All agents episode reward: [-6.78281123]
Iteration 4:  80%|████████  | 16/20 [00:32<00:07,  1.96s/it, episode=90, norm_ret=-7.096, true_ret=-300562656.000, steps=600]
Agent gate_2 episode reward: [-6.73911077]
All agents episode reward: [-6.73911077]
Agent gate_2 episode reward: [-7.35131749]
All agents episode reward: [-7.35131749]
Agent gate_2 episode reward: [-7.3449007]
All agents episode reward: [-7.3449007]
Agent gate_2 episode reward: [-6.83438502]
All agents episode reward: [-6.83438502]
Agent gate_2 episode reward: [-7.23647222]
All agents episode reward: [-7.23647222]
Agent gate_2 episode reward: [-7.18533434]
All agents episode reward: [-7.18533434]
Agent gate_2 episode reward: [-7.24731516]
All agents episode reward: [-7.24731516]
Agent gate_2 episode reward: [-7.0258859]
All agents episode reward: [-7.0258859]
Agent gate_2 episode reward: [-6.62844456]
All agents episode reward: [-6.62844456]
Agent gate_2 episode reward: [-7.36354078]
All agents episode reward: [-7.36354078]
Agent gate_2 episode reward: [-6.99059986]
All agents episode reward: [-6.99059986]
Agent gate_2 episode reward: [-7.31065036]
All agents episode reward: [-7.31065036]
Agent gate_2 episode reward: [-7.03550533]
All agents episode reward: [-7.03550533]
Agent gate_2 episode reward: [-6.92556604]
All agents episode reward: [-6.92556604]
Agent gate_2 episode reward: [-7.82636817]
All agents episode reward: [-7.82636817]
Agent gate_2 episode reward: [-7.31692016]
All agents episode reward: [-7.31692016]
Agent gate_2 episode reward: [-7.52211308]
All agents episode reward: [-7.52211308]
Agent gate_2 episode reward: [-7.19815303]
All agents episode reward: [-7.19815303]
Agent gate_2 episode reward: [-7.10244715]
All agents episode reward: [-7.10244715]
Agent gate_2 episode reward: [-7.92479451]
All agents episode reward: [-7.92479451]
Iteration 5:  60%|██████    | 12/20 [00:26<00:17,  2.15s/it, episode=110, norm_ret=-7.534, true_ret=-286521856.000, steps=600]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -297687296.000 at episode 101 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-7.51928164]
All agents episode reward: [-7.51928164]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -286118624.000 at episode 102 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-7.24542985]
All agents episode reward: [-7.24542985]
Agent gate_2 episode reward: [-7.71913175]
All agents episode reward: [-7.71913175]
Agent gate_2 episode reward: [-7.51897507]
All agents episode reward: [-7.51897507]
Agent gate_2 episode reward: [-7.66586857]
All agents episode reward: [-7.66586857]
Agent gate_2 episode reward: [-7.72538067]
All agents episode reward: [-7.72538067]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -279452064.000 at episode 107 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-7.16059039]
All agents episode reward: [-7.16059039]
Agent gate_2 episode reward: [-7.18172336]
All agents episode reward: [-7.18172336]
Agent gate_2 episode reward: [-8.21207326]
All agents episode reward: [-8.21207326]
Agent gate_2 episode reward: [-7.39122043]
All agents episode reward: [-7.39122043]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -278089056.000 at episode 111 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-7.18996494]
All agents episode reward: [-7.18996494]
Agent gate_2 episode reward: [-8.2101811]
All agents episode reward: [-8.2101811]
Agent gate_2 episode reward: [-7.71427743]
All agents episode reward: [-7.71427743]
Agent gate_2 episode reward: [-7.34341162]
All agents episode reward: [-7.34341162]
Agent gate_2 episode reward: [-7.85251797]
All agents episode reward: [-7.85251797]
Agent gate_2 episode reward: [-7.83490339]
All agents episode reward: [-7.83490339]
Agent gate_2 episode reward: [-7.70106133]
All agents episode reward: [-7.70106133]
Agent gate_2 episode reward: [-7.37458173]
All agents episode reward: [-7.37458173]
Agent gate_2 episode reward: [-7.77949324]
All agents episode reward: [-7.77949324]
Agent gate_2 episode reward: [-7.3403688]
All agents episode reward: [-7.3403688]
Iteration 6:  75%|███████▌  | 15/20 [00:29<00:09,  1.96s/it, episode=130, norm_ret=-7.845, true_ret=-284769152.000, steps=600]
Agent gate_2 episode reward: [-7.59652943]
All agents episode reward: [-7.59652943]
Agent gate_2 episode reward: [-7.67424411]
All agents episode reward: [-7.67424411]
Agent gate_2 episode reward: [-7.50907589]
All agents episode reward: [-7.50907589]
Agent gate_2 episode reward: [-8.03672519]
All agents episode reward: [-8.03672519]
Agent gate_2 episode reward: [-8.07357589]
All agents episode reward: [-8.07357589]
Agent gate_2 episode reward: [-8.01846389]
All agents episode reward: [-8.01846389]
Agent gate_2 episode reward: [-7.94003911]
All agents episode reward: [-7.94003911]
Agent gate_2 episode reward: [-8.14386882]
All agents episode reward: [-8.14386882]
Agent gate_2 episode reward: [-7.8147089]
All agents episode reward: [-7.8147089]
Agent gate_2 episode reward: [-7.63996477]
All agents episode reward: [-7.63996477]
Agent gate_2 episode reward: [-7.72973199]
All agents episode reward: [-7.72973199]
Agent gate_2 episode reward: [-7.79650937]
All agents episode reward: [-7.79650937]
Agent gate_2 episode reward: [-8.59492595]
All agents episode reward: [-8.59492595]
Agent gate_2 episode reward: [-7.83012086]
All agents episode reward: [-7.83012086]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -267755008.000 at episode 135 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-7.24428165]
All agents episode reward: [-7.24428165]
Agent gate_2 episode reward: [-7.59350713]
All agents episode reward: [-7.59350713]
Agent gate_2 episode reward: [-7.45323229]
All agents episode reward: [-7.45323229]
Agent gate_2 episode reward: [-7.7511914]
All agents episode reward: [-7.7511914]
Agent gate_2 episode reward: [-8.84130264]
All agents episode reward: [-8.84130264]
Agent gate_2 episode reward: [-7.61917261]
All agents episode reward: [-7.61917261]
Iteration 7:  80%|████████  | 16/20 [00:33<00:08,  2.16s/it, episode=150, norm_ret=-8.007, true_ret=-304770112.000, steps=600]
Agent gate_2 episode reward: [-7.5727173]
All agents episode reward: [-7.5727173]
Agent gate_2 episode reward: [-8.83088831]
All agents episode reward: [-8.83088831]
Agent gate_2 episode reward: [-7.87433996]
All agents episode reward: [-7.87433996]
Agent gate_2 episode reward: [-7.92926131]
All agents episode reward: [-7.92926131]
Agent gate_2 episode reward: [-7.74885812]
All agents episode reward: [-7.74885812]
Agent gate_2 episode reward: [-7.83002515]
All agents episode reward: [-7.83002515]
Agent gate_2 episode reward: [-7.91404235]
All agents episode reward: [-7.91404235]
Agent gate_2 episode reward: [-7.77177472]
All agents episode reward: [-7.77177472]
Agent gate_2 episode reward: [-8.16068103]
All agents episode reward: [-8.16068103]
Agent gate_2 episode reward: [-8.43727482]
All agents episode reward: [-8.43727482]
Agent gate_2 episode reward: [-7.51368227]
All agents episode reward: [-7.51368227]
Agent gate_2 episode reward: [-8.14476802]
All agents episode reward: [-8.14476802]
Agent gate_2 episode reward: [-8.67237139]
All agents episode reward: [-8.67237139]
Agent gate_2 episode reward: [-8.05333668]
All agents episode reward: [-8.05333668]
Agent gate_2 episode reward: [-8.03486027]
All agents episode reward: [-8.03486027]
Agent gate_2 episode reward: [-8.57111425]
All agents episode reward: [-8.57111425]
Agent gate_2 episode reward: [-8.19685457]
All agents episode reward: [-8.19685457]
Agent gate_2 episode reward: [-7.90811911]
All agents episode reward: [-7.90811911]
Agent gate_2 episode reward: [-8.38396179]
All agents episode reward: [-8.38396179]
Agent gate_2 episode reward: [-8.54388164]
All agents episode reward: [-8.54388164]
Iteration 8:  80%|████████  | 16/20 [00:34<00:08,  2.17s/it, episode=170, norm_ret=-8.308, true_ret=-291204448.000, steps=600]
Agent gate_2 episode reward: [-8.51012162]
All agents episode reward: [-8.51012162]
Agent gate_2 episode reward: [-8.23349091]
All agents episode reward: [-8.23349091]
Agent gate_2 episode reward: [-8.75051095]
All agents episode reward: [-8.75051095]
Agent gate_2 episode reward: [-8.04255827]
All agents episode reward: [-8.04255827]
Agent gate_2 episode reward: [-8.14917178]
All agents episode reward: [-8.14917178]
Agent gate_2 episode reward: [-8.10934946]
All agents episode reward: [-8.10934946]
Agent gate_2 episode reward: [-8.06503999]
All agents episode reward: [-8.06503999]
Agent gate_2 episode reward: [-8.74000922]
All agents episode reward: [-8.74000922]
Agent gate_2 episode reward: [-8.21721215]
All agents episode reward: [-8.21721215]
Agent gate_2 episode reward: [-8.26176266]
All agents episode reward: [-8.26176266]
Agent gate_2 episode reward: [-8.33129985]
All agents episode reward: [-8.33129985]
Agent gate_2 episode reward: [-7.98961959]
All agents episode reward: [-7.98961959]
Agent gate_2 episode reward: [-8.7615206]
All agents episode reward: [-8.7615206]
Agent gate_2 episode reward: [-8.85613263]
All agents episode reward: [-8.85613263]
Agent gate_2 episode reward: [-8.21166733]
All agents episode reward: [-8.21166733]
Agent gate_2 episode reward: [-8.5575971]
All agents episode reward: [-8.5575971]
Agent gate_2 episode reward: [-8.51898848]
All agents episode reward: [-8.51898848]
Agent gate_2 episode reward: [-8.16212808]
All agents episode reward: [-8.16212808]
Agent gate_2 episode reward: [-8.01959458]
All agents episode reward: [-8.01959458]
Agent gate_2 episode reward: [-9.28325223]
All agents episode reward: [-9.28325223]
Iteration 9:  80%|████████  | 16/20 [00:32<00:08,  2.07s/it, episode=190, norm_ret=-8.349, true_ret=-292132128.000, steps=600]
Agent gate_2 episode reward: [-7.90959421]
All agents episode reward: [-7.90959421]
Agent gate_2 episode reward: [-8.25078502]
All agents episode reward: [-8.25078502]
Agent gate_2 episode reward: [-8.82429811]
All agents episode reward: [-8.82429811]
Agent gate_2 episode reward: [-8.26081381]
All agents episode reward: [-8.26081381]
Agent gate_2 episode reward: [-8.11857264]
All agents episode reward: [-8.11857264]
Agent gate_2 episode reward: [-8.37325858]
All agents episode reward: [-8.37325858]
Agent gate_2 episode reward: [-8.01858634]
All agents episode reward: [-8.01858634]
Agent gate_2 episode reward: [-8.93300054]
All agents episode reward: [-8.93300054]
Agent gate_2 episode reward: [-8.33368324]
All agents episode reward: [-8.33368324]
Agent gate_2 episode reward: [-8.46325475]
All agents episode reward: [-8.46325475]
Agent gate_2 episode reward: [-9.02640465]
All agents episode reward: [-9.02640465]
Agent gate_2 episode reward: [-8.67280978]
All agents episode reward: [-8.67280978]
Agent gate_2 episode reward: [-8.97003139]
All agents episode reward: [-8.97003139]
Agent gate_2 episode reward: [-8.27719779]
All agents episode reward: [-8.27719779]
Agent gate_2 episode reward: [-8.2046045]
All agents episode reward: [-8.2046045]
Agent gate_2 episode reward: [-8.48673249]
All agents episode reward: [-8.48673249]
Agent gate_2 episode reward: [-9.25143338]
All agents episode reward: [-9.25143338]
Agent gate_2 episode reward: [-8.9280229]
All agents episode reward: [-8.9280229]
Agent gate_2 episode reward: [-8.89890302]
All agents episode reward: [-8.89890302]
Agent gate_2 episode reward: [-8.46968248]
All agents episode reward: [-8.46968248]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -695382272.000 ± 201946688.000
  Average reward: -695382272.000 ± 201946688.000
  Total reward: -695382272.000 ± 201946688.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -290569664.000 ± 13135490.000
  Average reward: -290569664.000 ± 13135490.000
  Total reward: -290569664.000 ± 13135490.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -300888896.000 ± 14159829.000
  Average reward: -300888896.000 ± 14159829.000
  Total reward: -300888896.000 ± 14159829.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -695382272.000
Rule-based avg reward: -290569664.000
No control avg reward: -300888896.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
