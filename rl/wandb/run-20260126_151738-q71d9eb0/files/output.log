Iteration 0:  80%|████████  | 16/20 [00:36<00:09,  2.37s/it, episode=10, norm_ret=-8.321, true_ret=-5178.858, steps=600]
Agent gate_2 episode reward: [-58.18070228]
All agents episode reward: [-58.18070228]
Agent gate_2 episode reward: [-6.73627754]
All agents episode reward: [-6.73627754]
Agent gate_2 episode reward: [-2.3347731]
All agents episode reward: [-2.3347731]
Agent gate_2 episode reward: [-5.67953469]
All agents episode reward: [-5.67953469]
Agent gate_2 episode reward: [-2.60388561]
All agents episode reward: [-2.60388561]
Agent gate_2 episode reward: [-2.10113482]
All agents episode reward: [-2.10113482]
Agent gate_2 episode reward: [-1.47147107]
All agents episode reward: [-1.47147107]
Agent gate_2 episode reward: [-1.40231245]
All agents episode reward: [-1.40231245]
Agent gate_2 episode reward: [-1.31097955]
All agents episode reward: [-1.31097955]
Agent gate_2 episode reward: [-1.39160618]
All agents episode reward: [-1.39160618]
Agent gate_2 episode reward: [-1.382023]
All agents episode reward: [-1.382023]
Agent gate_2 episode reward: [-1.39912226]
All agents episode reward: [-1.39912226]
Agent gate_2 episode reward: [-1.32080984]
All agents episode reward: [-1.32080984]
Agent gate_2 episode reward: [-1.25329521]
All agents episode reward: [-1.25329521]
Agent gate_2 episode reward: [-1.31037522]
All agents episode reward: [-1.31037522]
Agent gate_2 episode reward: [-1.43379417]
All agents episode reward: [-1.43379417]
Agent gate_2 episode reward: [-1.4133875]
All agents episode reward: [-1.4133875]
Agent gate_2 episode reward: [-1.42773059]
All agents episode reward: [-1.42773059]
Agent gate_2 episode reward: [-1.54741809]
All agents episode reward: [-1.54741809]
Agent gate_2 episode reward: [-1.5809366]
All agents episode reward: [-1.5809366]
Iteration 1:  80%|████████  | 16/20 [00:33<00:08,  2.12s/it, episode=30, norm_ret=-1.664, true_ret=-4123.000, steps=600]
Agent gate_2 episode reward: [-1.61104876]
All agents episode reward: [-1.61104876]
Agent gate_2 episode reward: [-1.50416838]
All agents episode reward: [-1.50416838]
Agent gate_2 episode reward: [-1.56040137]
All agents episode reward: [-1.56040137]
Agent gate_2 episode reward: [-1.58250967]
All agents episode reward: [-1.58250967]
Agent gate_2 episode reward: [-1.70583189]
All agents episode reward: [-1.70583189]
Agent gate_2 episode reward: [-1.59689335]
All agents episode reward: [-1.59689335]
Agent gate_2 episode reward: [-1.84855016]
All agents episode reward: [-1.84855016]
Agent gate_2 episode reward: [-1.64395039]
All agents episode reward: [-1.64395039]
Agent gate_2 episode reward: [-1.83646407]
All agents episode reward: [-1.83646407]
Agent gate_2 episode reward: [-1.74977096]
All agents episode reward: [-1.74977096]
Agent gate_2 episode reward: [-1.70155323]
All agents episode reward: [-1.70155323]
Agent gate_2 episode reward: [-1.84543957]
All agents episode reward: [-1.84543957]
Agent gate_2 episode reward: [-1.69348066]
All agents episode reward: [-1.69348066]
Agent gate_2 episode reward: [-1.81934301]
All agents episode reward: [-1.81934301]
Agent gate_2 episode reward: [-1.73292145]
All agents episode reward: [-1.73292145]
Agent gate_2 episode reward: [-1.85102977]
All agents episode reward: [-1.85102977]
Agent gate_2 episode reward: [-1.90314808]
All agents episode reward: [-1.90314808]
Agent gate_2 episode reward: [-1.93110163]
All agents episode reward: [-1.93110163]
Agent gate_2 episode reward: [-1.86783619]
All agents episode reward: [-1.86783619]
Agent gate_2 episode reward: [-2.05149939]
All agents episode reward: [-2.05149939]
Iteration 2:  80%|████████  | 16/20 [00:32<00:07,  1.99s/it, episode=50, norm_ret=-2.036, true_ret=-3834.272, steps=600]
Agent gate_2 episode reward: [-1.99050707]
All agents episode reward: [-1.99050707]
Agent gate_2 episode reward: [-2.1005688]
All agents episode reward: [-2.1005688]
Agent gate_2 episode reward: [-2.08268094]
All agents episode reward: [-2.08268094]
Agent gate_2 episode reward: [-1.97581956]
All agents episode reward: [-1.97581956]
Agent gate_2 episode reward: [-2.04624027]
All agents episode reward: [-2.04624027]
Agent gate_2 episode reward: [-2.02353997]
All agents episode reward: [-2.02353997]
Agent gate_2 episode reward: [-1.98691927]
All agents episode reward: [-1.98691927]
Agent gate_2 episode reward: [-2.06308734]
All agents episode reward: [-2.06308734]
Agent gate_2 episode reward: [-2.04529867]
All agents episode reward: [-2.04529867]
Agent gate_2 episode reward: [-2.04719393]
All agents episode reward: [-2.04719393]
Agent gate_2 episode reward: [-2.08386899]
All agents episode reward: [-2.08386899]
Agent gate_2 episode reward: [-2.17127929]
All agents episode reward: [-2.17127929]
Agent gate_2 episode reward: [-2.07699874]
All agents episode reward: [-2.07699874]
Agent gate_2 episode reward: [-2.10878268]
All agents episode reward: [-2.10878268]
Agent gate_2 episode reward: [-2.19162482]
All agents episode reward: [-2.19162482]
Agent gate_2 episode reward: [-2.15757474]
All agents episode reward: [-2.15757474]
Agent gate_2 episode reward: [-2.12960883]
All agents episode reward: [-2.12960883]
Agent gate_2 episode reward: [-2.27142701]
All agents episode reward: [-2.27142701]
Agent gate_2 episode reward: [-2.38113011]
All agents episode reward: [-2.38113011]
Agent gate_2 episode reward: [-2.3710932]
All agents episode reward: [-2.3710932]
Iteration 3:  80%|████████  | 16/20 [00:32<00:07,  1.85s/it, episode=70, norm_ret=-2.359, true_ret=-3803.358, steps=600]
Agent gate_2 episode reward: [-2.27256443]
All agents episode reward: [-2.27256443]
Agent gate_2 episode reward: [-2.28563704]
All agents episode reward: [-2.28563704]
Agent gate_2 episode reward: [-2.2682811]
All agents episode reward: [-2.2682811]
Agent gate_2 episode reward: [-2.33075942]
All agents episode reward: [-2.33075942]
Agent gate_2 episode reward: [-2.45942463]
All agents episode reward: [-2.45942463]
Agent gate_2 episode reward: [-2.39908082]
All agents episode reward: [-2.39908082]
Agent gate_2 episode reward: [-2.41467464]
All agents episode reward: [-2.41467464]
Agent gate_2 episode reward: [-2.38330777]
All agents episode reward: [-2.38330777]
Agent gate_2 episode reward: [-2.41595682]
All agents episode reward: [-2.41595682]
Agent gate_2 episode reward: [-2.36360206]
All agents episode reward: [-2.36360206]
Agent gate_2 episode reward: [-2.44981459]
All agents episode reward: [-2.44981459]
Agent gate_2 episode reward: [-2.68477758]
All agents episode reward: [-2.68477758]
Agent gate_2 episode reward: [-2.38177236]
All agents episode reward: [-2.38177236]
Agent gate_2 episode reward: [-2.59348144]
All agents episode reward: [-2.59348144]
Agent gate_2 episode reward: [-2.49274761]
All agents episode reward: [-2.49274761]
Agent gate_2 episode reward: [-2.65317538]
All agents episode reward: [-2.65317538]
Agent gate_2 episode reward: [-2.44142574]
All agents episode reward: [-2.44142574]
Agent gate_2 episode reward: [-2.59874425]
All agents episode reward: [-2.59874425]
Agent gate_2 episode reward: [-2.52146349]
All agents episode reward: [-2.52146349]
Agent gate_2 episode reward: [-2.46080991]
All agents episode reward: [-2.46080991]
Iteration 4:  80%|████████  | 16/20 [00:35<00:09,  2.27s/it, episode=90, norm_ret=-2.625, true_ret=-3745.638, steps=600]
Agent gate_2 episode reward: [-2.5887447]
All agents episode reward: [-2.5887447]
Agent gate_2 episode reward: [-2.59007646]
All agents episode reward: [-2.59007646]
Agent gate_2 episode reward: [-2.53294861]
All agents episode reward: [-2.53294861]
Agent gate_2 episode reward: [-2.60647302]
All agents episode reward: [-2.60647302]
Agent gate_2 episode reward: [-2.70749017]
All agents episode reward: [-2.70749017]
Agent gate_2 episode reward: [-2.56511197]
All agents episode reward: [-2.56511197]
Agent gate_2 episode reward: [-2.62913436]
All agents episode reward: [-2.62913436]
Agent gate_2 episode reward: [-2.73467907]
All agents episode reward: [-2.73467907]
Agent gate_2 episode reward: [-2.68512507]
All agents episode reward: [-2.68512507]
Agent gate_2 episode reward: [-2.60530952]
All agents episode reward: [-2.60530952]
Agent gate_2 episode reward: [-2.64865902]
All agents episode reward: [-2.64865902]
Agent gate_2 episode reward: [-2.76315714]
All agents episode reward: [-2.76315714]
Agent gate_2 episode reward: [-2.80220633]
All agents episode reward: [-2.80220633]
Agent gate_2 episode reward: [-2.83959331]
All agents episode reward: [-2.83959331]
Agent gate_2 episode reward: [-2.92787349]
All agents episode reward: [-2.92787349]
Agent gate_2 episode reward: [-2.6761757]
All agents episode reward: [-2.6761757]
Agent gate_2 episode reward: [-2.78292571]
All agents episode reward: [-2.78292571]
Agent gate_2 episode reward: [-2.84589798]
All agents episode reward: [-2.84589798]
Agent gate_2 episode reward: [-2.87659818]
All agents episode reward: [-2.87659818]
Agent gate_2 episode reward: [-3.02896747]
All agents episode reward: [-3.02896747]
Iteration 5:  70%|███████   | 14/20 [00:26<00:10,  1.77s/it, episode=110, norm_ret=-2.952, true_ret=-4159.655, steps=600]
Saved 1 agents to ppo_agents_butterfly_scB
New best average return achieved: -3930.048 at episode 101 (saved all agents to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-2.87762099]
All agents episode reward: [-2.87762099]
Agent gate_2 episode reward: [-2.92404697]
All agents episode reward: [-2.92404697]
Saved 1 agents to ppo_agents_butterfly_scB
New best average return achieved: -3713.720 at episode 103 (saved all agents to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-2.74284502]
All agents episode reward: [-2.74284502]
Agent gate_2 episode reward: [-2.91402904]
All agents episode reward: [-2.91402904]
Agent gate_2 episode reward: [-3.1847304]
All agents episode reward: [-3.1847304]
Agent gate_2 episode reward: [-2.91230913]
All agents episode reward: [-2.91230913]
Agent gate_2 episode reward: [-2.91862998]
All agents episode reward: [-2.91862998]
Agent gate_2 episode reward: [-2.98014876]
All agents episode reward: [-2.98014876]
Agent gate_2 episode reward: [-2.90672259]
All agents episode reward: [-2.90672259]
Agent gate_2 episode reward: [-3.16258097]
All agents episode reward: [-3.16258097]
Agent gate_2 episode reward: [-2.91007442]
All agents episode reward: [-2.91007442]
Agent gate_2 episode reward: [-2.95602067]
All agents episode reward: [-2.95602067]
Agent gate_2 episode reward: [-3.07307671]
All agents episode reward: [-3.07307671]
Agent gate_2 episode reward: [-3.009951]
All agents episode reward: [-3.009951]
Agent gate_2 episode reward: [-3.02882216]
All agents episode reward: [-3.02882216]
Agent gate_2 episode reward: [-2.93128453]
All agents episode reward: [-2.93128453]
Agent gate_2 episode reward: [-3.06819137]
All agents episode reward: [-3.06819137]
Agent gate_2 episode reward: [-3.03469887]
All agents episode reward: [-3.03469887]
Agent gate_2 episode reward: [-2.95405959]
All agents episode reward: [-2.95405959]
Agent gate_2 episode reward: [-3.1877539]
All agents episode reward: [-3.1877539]
Iteration 6:  80%|████████  | 16/20 [00:28<00:07,  1.82s/it, episode=130, norm_ret=-3.123, true_ret=-3902.284, steps=600]
Agent gate_2 episode reward: [-3.05480352]
All agents episode reward: [-3.05480352]
Agent gate_2 episode reward: [-3.10244898]
All agents episode reward: [-3.10244898]
Agent gate_2 episode reward: [-3.15499]
All agents episode reward: [-3.15499]
Agent gate_2 episode reward: [-3.09265551]
All agents episode reward: [-3.09265551]
Agent gate_2 episode reward: [-3.06823119]
All agents episode reward: [-3.06823119]
Agent gate_2 episode reward: [-3.15363799]
All agents episode reward: [-3.15363799]
Agent gate_2 episode reward: [-3.06359544]
All agents episode reward: [-3.06359544]
Agent gate_2 episode reward: [-3.18055169]
All agents episode reward: [-3.18055169]
Agent gate_2 episode reward: [-3.16470651]
All agents episode reward: [-3.16470651]
Agent gate_2 episode reward: [-3.19185536]
All agents episode reward: [-3.19185536]
Agent gate_2 episode reward: [-3.19525973]
All agents episode reward: [-3.19525973]
Agent gate_2 episode reward: [-3.05878106]
All agents episode reward: [-3.05878106]
Agent gate_2 episode reward: [-3.18136756]
All agents episode reward: [-3.18136756]
Agent gate_2 episode reward: [-3.25015717]
All agents episode reward: [-3.25015717]
Agent gate_2 episode reward: [-3.3203641]
All agents episode reward: [-3.3203641]
Agent gate_2 episode reward: [-3.45679468]
All agents episode reward: [-3.45679468]
Agent gate_2 episode reward: [-3.19977763]
All agents episode reward: [-3.19977763]
Saved 1 agents to ppo_agents_butterfly_scB
New best average return achieved: -3700.350 at episode 138 (saved all agents to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-3.10610802]
All agents episode reward: [-3.10610802]
Agent gate_2 episode reward: [-3.1518505]
All agents episode reward: [-3.1518505]
Agent gate_2 episode reward: [-3.49946244]
All agents episode reward: [-3.49946244]
Iteration 7:  75%|███████▌  | 15/20 [00:26<00:09,  1.90s/it, episode=150, norm_ret=-3.345, true_ret=-3868.605, steps=600]
Agent gate_2 episode reward: [-3.2621037]
All agents episode reward: [-3.2621037]
Agent gate_2 episode reward: [-3.43867232]
All agents episode reward: [-3.43867232]
Agent gate_2 episode reward: [-3.430082]
All agents episode reward: [-3.430082]
Agent gate_2 episode reward: [-3.34276754]
All agents episode reward: [-3.34276754]
Agent gate_2 episode reward: [-3.28321223]
All agents episode reward: [-3.28321223]
Agent gate_2 episode reward: [-3.40789631]
All agents episode reward: [-3.40789631]
Agent gate_2 episode reward: [-3.29400892]
All agents episode reward: [-3.29400892]
Agent gate_2 episode reward: [-3.27827307]
All agents episode reward: [-3.27827307]
Agent gate_2 episode reward: [-3.34237627]
All agents episode reward: [-3.34237627]
Agent gate_2 episode reward: [-3.36596699]
All agents episode reward: [-3.36596699]
Agent gate_2 episode reward: [-3.3760303]
All agents episode reward: [-3.3760303]
Agent gate_2 episode reward: [-3.45634261]
All agents episode reward: [-3.45634261]
Agent gate_2 episode reward: [-3.39261511]
All agents episode reward: [-3.39261511]
Agent gate_2 episode reward: [-3.30341911]
All agents episode reward: [-3.30341911]
Saved 1 agents to ppo_agents_butterfly_scB
New best average return achieved: -3666.197 at episode 155 (saved all agents to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-3.23510229]
All agents episode reward: [-3.23510229]
Agent gate_2 episode reward: [-3.30365566]
All agents episode reward: [-3.30365566]
Agent gate_2 episode reward: [-3.35051604]
All agents episode reward: [-3.35051604]
Agent gate_2 episode reward: [-3.46250871]
All agents episode reward: [-3.46250871]
Agent gate_2 episode reward: [-3.45596584]
All agents episode reward: [-3.45596584]
Agent gate_2 episode reward: [-3.56161633]
All agents episode reward: [-3.56161633]
Iteration 8:  75%|███████▌  | 15/20 [00:27<00:07,  1.55s/it, episode=170, norm_ret=-3.595, true_ret=-4032.892, steps=600]
Agent gate_2 episode reward: [-3.59459211]
All agents episode reward: [-3.59459211]
Agent gate_2 episode reward: [-3.79068271]
All agents episode reward: [-3.79068271]
Agent gate_2 episode reward: [-3.54883618]
All agents episode reward: [-3.54883618]
Agent gate_2 episode reward: [-3.53212226]
All agents episode reward: [-3.53212226]
Agent gate_2 episode reward: [-3.77844203]
All agents episode reward: [-3.77844203]
Agent gate_2 episode reward: [-3.53546867]
All agents episode reward: [-3.53546867]
Agent gate_2 episode reward: [-3.64154563]
All agents episode reward: [-3.64154563]
Saved 1 agents to ppo_agents_butterfly_scB
New best average return achieved: -3661.993 at episode 168 (saved all agents to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-3.34342943]
All agents episode reward: [-3.34342943]
Agent gate_2 episode reward: [-3.48648676]
All agents episode reward: [-3.48648676]
Agent gate_2 episode reward: [-3.70049132]
All agents episode reward: [-3.70049132]
Agent gate_2 episode reward: [-3.82951796]
All agents episode reward: [-3.82951796]
Agent gate_2 episode reward: [-3.54534097]
All agents episode reward: [-3.54534097]
Agent gate_2 episode reward: [-3.44827909]
All agents episode reward: [-3.44827909]
Agent gate_2 episode reward: [-3.58407011]
All agents episode reward: [-3.58407011]
Agent gate_2 episode reward: [-3.52895277]
All agents episode reward: [-3.52895277]
Agent gate_2 episode reward: [-3.60759488]
All agents episode reward: [-3.60759488]
Agent gate_2 episode reward: [-3.79141005]
All agents episode reward: [-3.79141005]
Agent gate_2 episode reward: [-3.62815949]
All agents episode reward: [-3.62815949]
Agent gate_2 episode reward: [-3.90242491]
All agents episode reward: [-3.90242491]
Agent gate_2 episode reward: [-3.64590117]
All agents episode reward: [-3.64590117]
Iteration 9:  80%|████████  | 16/20 [00:31<00:07,  1.90s/it, episode=190, norm_ret=-3.705, true_ret=-3948.148, steps=600]
Agent gate_2 episode reward: [-3.70300958]
All agents episode reward: [-3.70300958]
Agent gate_2 episode reward: [-3.53938843]
All agents episode reward: [-3.53938843]
Agent gate_2 episode reward: [-3.72384781]
All agents episode reward: [-3.72384781]
Agent gate_2 episode reward: [-3.66044053]
All agents episode reward: [-3.66044053]
Agent gate_2 episode reward: [-3.56440577]
All agents episode reward: [-3.56440577]
Agent gate_2 episode reward: [-3.74381108]
All agents episode reward: [-3.74381108]
Agent gate_2 episode reward: [-3.63929675]
All agents episode reward: [-3.63929675]
Agent gate_2 episode reward: [-3.83179542]
All agents episode reward: [-3.83179542]
Agent gate_2 episode reward: [-3.85091558]
All agents episode reward: [-3.85091558]
Agent gate_2 episode reward: [-3.79557865]
All agents episode reward: [-3.79557865]
Agent gate_2 episode reward: [-3.95036172]
All agents episode reward: [-3.95036172]
Agent gate_2 episode reward: [-3.95934465]
All agents episode reward: [-3.95934465]
Agent gate_2 episode reward: [-3.74274339]
All agents episode reward: [-3.74274339]
Agent gate_2 episode reward: [-3.93496687]
All agents episode reward: [-3.93496687]
Agent gate_2 episode reward: [-3.69180293]
All agents episode reward: [-3.69180293]
Agent gate_2 episode reward: [-3.68206329]
All agents episode reward: [-3.68206329]
Agent gate_2 episode reward: [-3.64037944]
All agents episode reward: [-3.64037944]
Agent gate_2 episode reward: [-3.8167907]
All agents episode reward: [-3.8167907]
Agent gate_2 episode reward: [-3.81959706]
All agents episode reward: [-3.81959706]
Agent gate_2 episode reward: [-3.81312896]
All agents episode reward: [-3.81312896]
Loaded 1 agents from ppo_agents_butterfly_scB
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scB/ppo_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scB/ppo_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scB/ppo_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scB/ppo_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scB/ppo_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scB/ppo_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scB/ppo_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scB/ppo_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scB/ppo_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scB/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -3863.710 ± 68.479
  Average reward: -3863.710 ± 68.479
  Total reward: -3863.710 ± 68.479
============================================================
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scB/rule_based_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scB/rule_based_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scB/rule_based_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scB/rule_based_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scB/rule_based_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scB/rule_based_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scB/rule_based_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scB/rule_based_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scB/rule_based_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scB/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -3902.054 ± 117.082
  Average reward: -3902.054 ± 117.082
  Total reward: -3902.054 ± 117.082
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Saved run 1 to rl_training/butterfly_scB/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Saved run 2 to rl_training/butterfly_scB/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Saved run 3 to rl_training/butterfly_scB/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Saved run 4 to rl_training/butterfly_scB/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Saved run 5 to rl_training/butterfly_scB/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Saved run 6 to rl_training/butterfly_scB/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Saved run 7 to rl_training/butterfly_scB/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Saved run 8 to rl_training/butterfly_scB/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Saved run 9 to rl_training/butterfly_scB/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Saved run 10 to rl_training/butterfly_scB/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -3945.753 ± 99.390
  Average reward: -3945.753 ± 99.390
  Total reward: -3945.753 ± 99.390
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -3863.710
Rule-based avg reward: -3902.054
No control avg reward: -3945.753
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
