Iteration 0:  80%|████████  | 16/20 [00:30<00:07,  1.89s/it, episode=10, norm_ret=-9.611, true_ret=-5107.848, steps=600]
Agent gate_2 episode reward: [-54.06237635]
All agents episode reward: [-54.06237635]
Agent gate_2 episode reward: [-14.44102615]
All agents episode reward: [-14.44102615]
Agent gate_2 episode reward: [-8.7895746]
All agents episode reward: [-8.7895746]
Agent gate_2 episode reward: [-4.32753953]
All agents episode reward: [-4.32753953]
Agent gate_2 episode reward: [-2.7738272]
All agents episode reward: [-2.7738272]
Agent gate_2 episode reward: [-2.96242421]
All agents episode reward: [-2.96242421]
Agent gate_2 episode reward: [-2.18756156]
All agents episode reward: [-2.18756156]
Agent gate_2 episode reward: [-2.38874509]
All agents episode reward: [-2.38874509]
Agent gate_2 episode reward: [-1.97258496]
All agents episode reward: [-1.97258496]
Agent gate_2 episode reward: [-2.20406768]
All agents episode reward: [-2.20406768]
Agent gate_2 episode reward: [-2.45229183]
All agents episode reward: [-2.45229183]
Agent gate_2 episode reward: [-2.17768769]
All agents episode reward: [-2.17768769]
Agent gate_2 episode reward: [-2.15001326]
All agents episode reward: [-2.15001326]
Agent gate_2 episode reward: [-2.09866155]
All agents episode reward: [-2.09866155]
Agent gate_2 episode reward: [-2.27574558]
All agents episode reward: [-2.27574558]
Agent gate_2 episode reward: [-2.21262856]
All agents episode reward: [-2.21262856]
Agent gate_2 episode reward: [-2.76516209]
All agents episode reward: [-2.76516209]
Agent gate_2 episode reward: [-2.38292554]
All agents episode reward: [-2.38292554]
Agent gate_2 episode reward: [-2.29285003]
All agents episode reward: [-2.29285003]
Agent gate_2 episode reward: [-2.32206318]
All agents episode reward: [-2.32206318]
Iteration 1:  80%|████████  | 16/20 [00:30<00:07,  1.92s/it, episode=30, norm_ret=-2.686, true_ret=-4320.998, steps=600]
Agent gate_2 episode reward: [-2.35260385]
All agents episode reward: [-2.35260385]
Agent gate_2 episode reward: [-2.6133457]
All agents episode reward: [-2.6133457]
Agent gate_2 episode reward: [-2.57692593]
All agents episode reward: [-2.57692593]
Agent gate_2 episode reward: [-2.64243955]
All agents episode reward: [-2.64243955]
Agent gate_2 episode reward: [-2.52606862]
All agents episode reward: [-2.52606862]
Agent gate_2 episode reward: [-2.76708279]
All agents episode reward: [-2.76708279]
Agent gate_2 episode reward: [-3.01313267]
All agents episode reward: [-3.01313267]
Agent gate_2 episode reward: [-2.70682319]
All agents episode reward: [-2.70682319]
Agent gate_2 episode reward: [-2.82768087]
All agents episode reward: [-2.82768087]
Agent gate_2 episode reward: [-2.83299534]
All agents episode reward: [-2.83299534]
Agent gate_2 episode reward: [-2.76534326]
All agents episode reward: [-2.76534326]
Agent gate_2 episode reward: [-2.8698417]
All agents episode reward: [-2.8698417]
Agent gate_2 episode reward: [-3.19994977]
All agents episode reward: [-3.19994977]
Agent gate_2 episode reward: [-2.91172803]
All agents episode reward: [-2.91172803]
Agent gate_2 episode reward: [-3.14085763]
All agents episode reward: [-3.14085763]
Agent gate_2 episode reward: [-3.90457166]
All agents episode reward: [-3.90457166]
Agent gate_2 episode reward: [-3.11818707]
All agents episode reward: [-3.11818707]
Agent gate_2 episode reward: [-4.37740202]
All agents episode reward: [-4.37740202]
Agent gate_2 episode reward: [-3.77361772]
All agents episode reward: [-3.77361772]
Agent gate_2 episode reward: [-5.36826841]
All agents episode reward: [-5.36826841]
Iteration 2:  80%|████████  | 16/20 [00:30<00:07,  1.91s/it, episode=50, norm_ret=-3.620, true_ret=-4333.695, steps=600]
Agent gate_2 episode reward: [-3.51696307]
All agents episode reward: [-3.51696307]
Agent gate_2 episode reward: [-3.60988543]
All agents episode reward: [-3.60988543]
Agent gate_2 episode reward: [-3.61163776]
All agents episode reward: [-3.61163776]
Agent gate_2 episode reward: [-3.26575441]
All agents episode reward: [-3.26575441]
Agent gate_2 episode reward: [-3.87213256]
All agents episode reward: [-3.87213256]
Agent gate_2 episode reward: [-3.59374677]
All agents episode reward: [-3.59374677]
Agent gate_2 episode reward: [-3.65551444]
All agents episode reward: [-3.65551444]
Agent gate_2 episode reward: [-3.56306941]
All agents episode reward: [-3.56306941]
Agent gate_2 episode reward: [-4.0132471]
All agents episode reward: [-4.0132471]
Agent gate_2 episode reward: [-3.49789068]
All agents episode reward: [-3.49789068]
Agent gate_2 episode reward: [-3.47132217]
All agents episode reward: [-3.47132217]
Agent gate_2 episode reward: [-3.76395747]
All agents episode reward: [-3.76395747]
Agent gate_2 episode reward: [-3.61338249]
All agents episode reward: [-3.61338249]
Agent gate_2 episode reward: [-3.68642467]
All agents episode reward: [-3.68642467]
Agent gate_2 episode reward: [-3.43496533]
All agents episode reward: [-3.43496533]
Agent gate_2 episode reward: [-3.5447383]
All agents episode reward: [-3.5447383]
Agent gate_2 episode reward: [-3.79762803]
All agents episode reward: [-3.79762803]
Agent gate_2 episode reward: [-3.67976987]
All agents episode reward: [-3.67976987]
Agent gate_2 episode reward: [-3.68003871]
All agents episode reward: [-3.68003871]
Agent gate_2 episode reward: [-4.18763972]
All agents episode reward: [-4.18763972]
Iteration 3:  80%|████████  | 16/20 [00:31<00:07,  1.96s/it, episode=70, norm_ret=-5.038, true_ret=-4976.744, steps=600]
Agent gate_2 episode reward: [-4.09514646]
All agents episode reward: [-4.09514646]
Agent gate_2 episode reward: [-4.20469413]
All agents episode reward: [-4.20469413]
Agent gate_2 episode reward: [-4.76723941]
All agents episode reward: [-4.76723941]
Agent gate_2 episode reward: [-4.78781598]
All agents episode reward: [-4.78781598]
Agent gate_2 episode reward: [-7.11995736]
All agents episode reward: [-7.11995736]
Agent gate_2 episode reward: [-7.22785826]
All agents episode reward: [-7.22785826]
Agent gate_2 episode reward: [-4.51788621]
All agents episode reward: [-4.51788621]
Agent gate_2 episode reward: [-4.34838484]
All agents episode reward: [-4.34838484]
Agent gate_2 episode reward: [-4.74385574]
All agents episode reward: [-4.74385574]
Agent gate_2 episode reward: [-4.56300467]
All agents episode reward: [-4.56300467]
Agent gate_2 episode reward: [-4.60807163]
All agents episode reward: [-4.60807163]
Agent gate_2 episode reward: [-4.81069224]
All agents episode reward: [-4.81069224]
Agent gate_2 episode reward: [-4.11625416]
All agents episode reward: [-4.11625416]
Agent gate_2 episode reward: [-4.64300528]
All agents episode reward: [-4.64300528]
Agent gate_2 episode reward: [-4.29539146]
All agents episode reward: [-4.29539146]
Agent gate_2 episode reward: [-4.19517382]
All agents episode reward: [-4.19517382]
Agent gate_2 episode reward: [-4.30269085]
All agents episode reward: [-4.30269085]
Agent gate_2 episode reward: [-4.47550677]
All agents episode reward: [-4.47550677]
Agent gate_2 episode reward: [-4.85377303]
All agents episode reward: [-4.85377303]
Agent gate_2 episode reward: [-5.41487344]
All agents episode reward: [-5.41487344]
Iteration 4:  80%|████████  | 16/20 [00:30<00:07,  1.91s/it, episode=90, norm_ret=-5.214, true_ret=-4947.257, steps=600]
Agent gate_2 episode reward: [-7.25939355]
All agents episode reward: [-7.25939355]
Agent gate_2 episode reward: [-4.82905442]
All agents episode reward: [-4.82905442]
Agent gate_2 episode reward: [-4.3741407]
All agents episode reward: [-4.3741407]
Agent gate_2 episode reward: [-4.46597689]
All agents episode reward: [-4.46597689]
Agent gate_2 episode reward: [-4.73575974]
All agents episode reward: [-4.73575974]
Agent gate_2 episode reward: [-5.13467031]
All agents episode reward: [-5.13467031]
Agent gate_2 episode reward: [-4.4172658]
All agents episode reward: [-4.4172658]
Agent gate_2 episode reward: [-5.00394087]
All agents episode reward: [-5.00394087]
Agent gate_2 episode reward: [-6.95816474]
All agents episode reward: [-6.95816474]
Agent gate_2 episode reward: [-4.96167785]
All agents episode reward: [-4.96167785]
Agent gate_2 episode reward: [-5.28851447]
All agents episode reward: [-5.28851447]
Agent gate_2 episode reward: [-4.39500176]
All agents episode reward: [-4.39500176]
Agent gate_2 episode reward: [-4.66856024]
All agents episode reward: [-4.66856024]
Agent gate_2 episode reward: [-4.70231668]
All agents episode reward: [-4.70231668]
Agent gate_2 episode reward: [-4.53775324]
All agents episode reward: [-4.53775324]
Agent gate_2 episode reward: [-4.28265203]
All agents episode reward: [-4.28265203]
Agent gate_2 episode reward: [-4.15390412]
All agents episode reward: [-4.15390412]
Agent gate_2 episode reward: [-4.32970144]
All agents episode reward: [-4.32970144]
Agent gate_2 episode reward: [-4.72557208]
All agents episode reward: [-4.72557208]
Agent gate_2 episode reward: [-4.24329134]
All agents episode reward: [-4.24329134]
Iteration 5:  70%|███████   | 14/20 [00:27<00:12,  2.03s/it, episode=110, norm_ret=-4.143, true_ret=-3899.333, steps=600]
Saved 1 agents to ppo_agents_butterfly_scB
New best average return achieved: -3920.438 at episode 101 (saved all agents to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-4.10319982]
All agents episode reward: [-4.10319982]
Agent gate_2 episode reward: [-4.49014895]
All agents episode reward: [-4.49014895]
Agent gate_2 episode reward: [-4.22150607]
All agents episode reward: [-4.22150607]
Saved 1 agents to ppo_agents_butterfly_scB
New best average return achieved: -3731.643 at episode 104 (saved all agents to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-3.94878464]
All agents episode reward: [-3.94878464]
Agent gate_2 episode reward: [-4.02133251]
All agents episode reward: [-4.02133251]
Agent gate_2 episode reward: [-4.0362372]
All agents episode reward: [-4.0362372]
Agent gate_2 episode reward: [-4.14990293]
All agents episode reward: [-4.14990293]
Agent gate_2 episode reward: [-4.22169271]
All agents episode reward: [-4.22169271]
Agent gate_2 episode reward: [-4.01929885]
All agents episode reward: [-4.01929885]
Agent gate_2 episode reward: [-4.21345974]
All agents episode reward: [-4.21345974]
Agent gate_2 episode reward: [-4.05638185]
All agents episode reward: [-4.05638185]
Agent gate_2 episode reward: [-4.16769045]
All agents episode reward: [-4.16769045]
Agent gate_2 episode reward: [-4.32109922]
All agents episode reward: [-4.32109922]
Agent gate_2 episode reward: [-4.23599835]
All agents episode reward: [-4.23599835]
Agent gate_2 episode reward: [-4.24581673]
All agents episode reward: [-4.24581673]
Agent gate_2 episode reward: [-4.21885422]
All agents episode reward: [-4.21885422]
Agent gate_2 episode reward: [-4.21905258]
All agents episode reward: [-4.21905258]
Agent gate_2 episode reward: [-4.31465525]
All agents episode reward: [-4.31465525]
Agent gate_2 episode reward: [-4.36696755]
All agents episode reward: [-4.36696755]
Agent gate_2 episode reward: [-4.20330803]
All agents episode reward: [-4.20330803]
Iteration 6:  75%|███████▌  | 15/20 [00:28<00:09,  1.91s/it, episode=130, norm_ret=-4.428, true_ret=-3832.535, steps=600]
Agent gate_2 episode reward: [-4.61089513]
All agents episode reward: [-4.61089513]
Agent gate_2 episode reward: [-4.336768]
All agents episode reward: [-4.336768]
Agent gate_2 episode reward: [-4.39419561]
All agents episode reward: [-4.39419561]
Agent gate_2 episode reward: [-4.43623856]
All agents episode reward: [-4.43623856]
Agent gate_2 episode reward: [-4.43606195]
All agents episode reward: [-4.43606195]
Agent gate_2 episode reward: [-4.48317263]
All agents episode reward: [-4.48317263]
Agent gate_2 episode reward: [-4.26078582]
All agents episode reward: [-4.26078582]
Agent gate_2 episode reward: [-4.60325903]
All agents episode reward: [-4.60325903]
Agent gate_2 episode reward: [-4.31383196]
All agents episode reward: [-4.31383196]
Agent gate_2 episode reward: [-4.40296138]
All agents episode reward: [-4.40296138]
Agent gate_2 episode reward: [-4.58391593]
All agents episode reward: [-4.58391593]
Agent gate_2 episode reward: [-4.53603833]
All agents episode reward: [-4.53603833]
Agent gate_2 episode reward: [-4.46695042]
All agents episode reward: [-4.46695042]
Agent gate_2 episode reward: [-4.46639729]
All agents episode reward: [-4.46639729]
Saved 1 agents to ppo_agents_butterfly_scB
New best average return achieved: -3713.517 at episode 135 (saved all agents to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-4.32454192]
All agents episode reward: [-4.32454192]
Agent gate_2 episode reward: [-4.46984551]
All agents episode reward: [-4.46984551]
Agent gate_2 episode reward: [-4.5169477]
All agents episode reward: [-4.5169477]
Agent gate_2 episode reward: [-4.48787331]
All agents episode reward: [-4.48787331]
Agent gate_2 episode reward: [-4.60555068]
All agents episode reward: [-4.60555068]
Agent gate_2 episode reward: [-4.66291106]
All agents episode reward: [-4.66291106]
Iteration 7:  75%|███████▌  | 15/20 [00:29<00:09,  1.95s/it, episode=150, norm_ret=-4.648, true_ret=-3840.023, steps=600]
Agent gate_2 episode reward: [-4.49599443]
All agents episode reward: [-4.49599443]
Agent gate_2 episode reward: [-4.43697573]
All agents episode reward: [-4.43697573]
Agent gate_2 episode reward: [-5.00027687]
All agents episode reward: [-5.00027687]
Saved 1 agents to ppo_agents_butterfly_scB
New best average return achieved: -3542.824 at episode 144 (saved all agents to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-4.22233857]
All agents episode reward: [-4.22233857]
Agent gate_2 episode reward: [-4.53284272]
All agents episode reward: [-4.53284272]
Agent gate_2 episode reward: [-4.97564902]
All agents episode reward: [-4.97564902]
Agent gate_2 episode reward: [-4.50381781]
All agents episode reward: [-4.50381781]
Agent gate_2 episode reward: [-5.07396877]
All agents episode reward: [-5.07396877]
Agent gate_2 episode reward: [-4.5942331]
All agents episode reward: [-4.5942331]
Agent gate_2 episode reward: [-4.64373683]
All agents episode reward: [-4.64373683]
Agent gate_2 episode reward: [-4.81477648]
All agents episode reward: [-4.81477648]
Agent gate_2 episode reward: [-5.08705566]
All agents episode reward: [-5.08705566]
Agent gate_2 episode reward: [-4.72357122]
All agents episode reward: [-4.72357122]
Agent gate_2 episode reward: [-5.08185545]
All agents episode reward: [-5.08185545]
Agent gate_2 episode reward: [-4.86090019]
All agents episode reward: [-4.86090019]
Agent gate_2 episode reward: [-4.61786881]
All agents episode reward: [-4.61786881]
Agent gate_2 episode reward: [-4.96154566]
All agents episode reward: [-4.96154566]
Agent gate_2 episode reward: [-4.68587557]
All agents episode reward: [-4.68587557]
Agent gate_2 episode reward: [-4.84565943]
All agents episode reward: [-4.84565943]
Agent gate_2 episode reward: [-5.04146328]
All agents episode reward: [-5.04146328]
Iteration 8:  80%|████████  | 16/20 [00:30<00:07,  1.92s/it, episode=170, norm_ret=-4.948, true_ret=-4351.678, steps=600]
Agent gate_2 episode reward: [-4.85320381]
All agents episode reward: [-4.85320381]
Agent gate_2 episode reward: [-4.80161863]
All agents episode reward: [-4.80161863]
Agent gate_2 episode reward: [-4.65426282]
All agents episode reward: [-4.65426282]
Agent gate_2 episode reward: [-5.23223522]
All agents episode reward: [-5.23223522]
Agent gate_2 episode reward: [-4.74981935]
All agents episode reward: [-4.74981935]
Agent gate_2 episode reward: [-4.88687477]
All agents episode reward: [-4.88687477]
Agent gate_2 episode reward: [-5.01184477]
All agents episode reward: [-5.01184477]
Agent gate_2 episode reward: [-4.9333183]
All agents episode reward: [-4.9333183]
Agent gate_2 episode reward: [-4.8626541]
All agents episode reward: [-4.8626541]
Agent gate_2 episode reward: [-5.49807236]
All agents episode reward: [-5.49807236]
Agent gate_2 episode reward: [-4.71214234]
All agents episode reward: [-4.71214234]
Agent gate_2 episode reward: [-4.81578573]
All agents episode reward: [-4.81578573]
Agent gate_2 episode reward: [-5.03228384]
All agents episode reward: [-5.03228384]
Agent gate_2 episode reward: [-5.36618419]
All agents episode reward: [-5.36618419]
Agent gate_2 episode reward: [-4.92031701]
All agents episode reward: [-4.92031701]
Agent gate_2 episode reward: [-4.95332955]
All agents episode reward: [-4.95332955]
Agent gate_2 episode reward: [-5.43766809]
All agents episode reward: [-5.43766809]
Agent gate_2 episode reward: [-5.02539342]
All agents episode reward: [-5.02539342]
Agent gate_2 episode reward: [-4.8851172]
All agents episode reward: [-4.8851172]
Agent gate_2 episode reward: [-4.87316604]
All agents episode reward: [-4.87316604]
Iteration 9:  80%|████████  | 16/20 [00:30<00:07,  1.91s/it, episode=190, norm_ret=-5.111, true_ret=-3832.523, steps=600]
Agent gate_2 episode reward: [-4.88069155]
All agents episode reward: [-4.88069155]
Agent gate_2 episode reward: [-5.45128699]
All agents episode reward: [-5.45128699]
Agent gate_2 episode reward: [-5.00110601]
All agents episode reward: [-5.00110601]
Agent gate_2 episode reward: [-4.91570906]
All agents episode reward: [-4.91570906]
Agent gate_2 episode reward: [-5.09091524]
All agents episode reward: [-5.09091524]
Agent gate_2 episode reward: [-4.90805903]
All agents episode reward: [-4.90805903]
Agent gate_2 episode reward: [-5.28234074]
All agents episode reward: [-5.28234074]
Agent gate_2 episode reward: [-5.32467142]
All agents episode reward: [-5.32467142]
Agent gate_2 episode reward: [-5.22880596]
All agents episode reward: [-5.22880596]
Agent gate_2 episode reward: [-5.02969041]
All agents episode reward: [-5.02969041]
Agent gate_2 episode reward: [-4.99224245]
All agents episode reward: [-4.99224245]
Agent gate_2 episode reward: [-4.98092112]
All agents episode reward: [-4.98092112]
Agent gate_2 episode reward: [-5.361053]
All agents episode reward: [-5.361053]
Agent gate_2 episode reward: [-5.14013381]
All agents episode reward: [-5.14013381]
Agent gate_2 episode reward: [-4.91638999]
All agents episode reward: [-4.91638999]
Agent gate_2 episode reward: [-5.14620737]
All agents episode reward: [-5.14620737]
Agent gate_2 episode reward: [-5.09341993]
All agents episode reward: [-5.09341993]
Agent gate_2 episode reward: [-5.03518691]
All agents episode reward: [-5.03518691]
Agent gate_2 episode reward: [-5.18695716]
All agents episode reward: [-5.18695716]
Agent gate_2 episode reward: [-5.32738826]
All agents episode reward: [-5.32738826]
Loaded 1 agents from ppo_agents_butterfly_scB
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scB/ppo_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scB/ppo_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scB/ppo_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scB/ppo_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scB/ppo_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scB/ppo_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scB/ppo_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scB/ppo_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scB/ppo_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scB/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -3944.595 ± 109.130
  Average reward: -3944.595 ± 109.130
  Total reward: -3944.595 ± 109.130
============================================================
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scB/rule_based_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scB/rule_based_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scB/rule_based_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scB/rule_based_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scB/rule_based_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scB/rule_based_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scB/rule_based_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scB/rule_based_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scB/rule_based_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scB/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -3929.356 ± 93.171
  Average reward: -3929.356 ± 93.171
  Total reward: -3929.356 ± 93.171
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Saved run 1 to rl_training/butterfly_scB/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Saved run 2 to rl_training/butterfly_scB/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Saved run 3 to rl_training/butterfly_scB/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Saved run 4 to rl_training/butterfly_scB/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Saved run 5 to rl_training/butterfly_scB/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Saved run 6 to rl_training/butterfly_scB/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Saved run 7 to rl_training/butterfly_scB/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Saved run 8 to rl_training/butterfly_scB/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Saved run 9 to rl_training/butterfly_scB/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Saved run 10 to rl_training/butterfly_scB/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -3963.653 ± 162.312
  Average reward: -3963.653 ± 162.312
  Total reward: -3963.653 ± 162.312
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -3944.595
Rule-based avg reward: -3929.356
No control avg reward: -3963.653
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
