Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=10, norm_ret=-139075.281, true_ret=-12645.901, steps=600]
Agent gate_2 episode reward: -393264.03125
All agents episode reward: -393264.03125
Agent gate_2 episode reward: -308267.96875
All agents episode reward: -308267.96875
Agent gate_2 episode reward: -270568.5625
All agents episode reward: -270568.5625
Agent gate_2 episode reward: -211311.78125
All agents episode reward: -211311.78125
Agent gate_2 episode reward: -54966.71875
All agents episode reward: -54966.71875
Agent gate_2 episode reward: -14940.384765625
All agents episode reward: -14940.384765625
Agent gate_2 episode reward: -98491.28125
All agents episode reward: -98491.28125
Agent gate_2 episode reward: -17047.060546875
All agents episode reward: -17047.060546875
Agent gate_2 episode reward: -9249.1220703125
All agents episode reward: -9249.1220703125
Agent gate_2 episode reward: -12645.9013671875
All agents episode reward: -12645.9013671875
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it, episode=20, norm_ret=-8650.127, true_ret=-8392.325, steps=600]
Agent gate_2 episode reward: -11061.8642578125
All agents episode reward: -11061.8642578125
Agent gate_2 episode reward: -8077.1591796875
All agents episode reward: -8077.1591796875
Agent gate_2 episode reward: -9867.4384765625
All agents episode reward: -9867.4384765625
Agent gate_2 episode reward: -7971.390625
All agents episode reward: -7971.390625
Agent gate_2 episode reward: -8668.5263671875
All agents episode reward: -8668.5263671875
Agent gate_2 episode reward: -8210.7763671875
All agents episode reward: -8210.7763671875
Agent gate_2 episode reward: -8145.888671875
All agents episode reward: -8145.888671875
Agent gate_2 episode reward: -8212.162109375
All agents episode reward: -8212.162109375
Agent gate_2 episode reward: -7893.734375
All agents episode reward: -7893.734375
Agent gate_2 episode reward: -8392.3251953125
All agents episode reward: -8392.3251953125
Iteration 2: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it, episode=30, norm_ret=-7990.831, true_ret=-7415.458, steps=600]
Agent gate_2 episode reward: -7897.42041015625
All agents episode reward: -7897.42041015625
Agent gate_2 episode reward: -8245.673828125
All agents episode reward: -8245.673828125
Agent gate_2 episode reward: -7781.4970703125
All agents episode reward: -7781.4970703125
Agent gate_2 episode reward: -7762.56298828125
All agents episode reward: -7762.56298828125
Agent gate_2 episode reward: -8295.0400390625
All agents episode reward: -8295.0400390625
Agent gate_2 episode reward: -8106.75244140625
All agents episode reward: -8106.75244140625
Agent gate_2 episode reward: -8009.5849609375
All agents episode reward: -8009.5849609375
Agent gate_2 episode reward: -7868.92138671875
All agents episode reward: -7868.92138671875
Agent gate_2 episode reward: -8525.3955078125
All agents episode reward: -8525.3955078125
Agent gate_2 episode reward: -7415.45751953125
All agents episode reward: -7415.45751953125
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.23s/it, episode=40, norm_ret=-20551.645, true_ret=-7561.073, steps=600]
Agent gate_2 episode reward: -8661.423828125
All agents episode reward: -8661.423828125
Agent gate_2 episode reward: -8468.390625
All agents episode reward: -8468.390625
Agent gate_2 episode reward: -43482.8359375
All agents episode reward: -43482.8359375
Agent gate_2 episode reward: -93427.453125
All agents episode reward: -93427.453125
Agent gate_2 episode reward: -8781.224609375
All agents episode reward: -8781.224609375
Agent gate_2 episode reward: -10633.3984375
All agents episode reward: -10633.3984375
Agent gate_2 episode reward: -8302.8671875
All agents episode reward: -8302.8671875
Agent gate_2 episode reward: -8372.6337890625
All agents episode reward: -8372.6337890625
Agent gate_2 episode reward: -7825.16259765625
All agents episode reward: -7825.16259765625
Agent gate_2 episode reward: -7561.0732421875
All agents episode reward: -7561.0732421875
Iteration 4: 100%|██████████| 10/10 [00:22<00:00,  2.27s/it, episode=50, norm_ret=-9420.294, true_ret=-8151.919, steps=600]
Agent gate_2 episode reward: -8655.244140625
All agents episode reward: -8655.244140625
Agent gate_2 episode reward: -8086.3154296875
All agents episode reward: -8086.3154296875
Agent gate_2 episode reward: -7653.91650390625
All agents episode reward: -7653.91650390625
Agent gate_2 episode reward: -8133.798828125
All agents episode reward: -8133.798828125
Agent gate_2 episode reward: -8331.25390625
All agents episode reward: -8331.25390625
Agent gate_2 episode reward: -15426.4931640625
All agents episode reward: -15426.4931640625
Agent gate_2 episode reward: -7304.3837890625
All agents episode reward: -7304.3837890625
Agent gate_2 episode reward: -13314.2216796875
All agents episode reward: -13314.2216796875
Agent gate_2 episode reward: -9145.39453125
All agents episode reward: -9145.39453125
Agent gate_2 episode reward: -8151.91943359375
All agents episode reward: -8151.91943359375
Iteration 5: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it, episode=60, norm_ret=-8026.944, true_ret=-7707.665, steps=600]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -7073.744 at episode 51 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: -7073.74365234375
All agents episode reward: -7073.74365234375
Agent gate_2 episode reward: -8375.111328125
All agents episode reward: -8375.111328125
Agent gate_2 episode reward: -8239.62890625
All agents episode reward: -8239.62890625
Agent gate_2 episode reward: -8294.0302734375
All agents episode reward: -8294.0302734375
Agent gate_2 episode reward: -8025.47607421875
All agents episode reward: -8025.47607421875
Agent gate_2 episode reward: -7787.42724609375
All agents episode reward: -7787.42724609375
Agent gate_2 episode reward: -8186.39990234375
All agents episode reward: -8186.39990234375
Agent gate_2 episode reward: -8388.953125
All agents episode reward: -8388.953125
Agent gate_2 episode reward: -8191.00341796875
All agents episode reward: -8191.00341796875
Agent gate_2 episode reward: -7707.66455078125
All agents episode reward: -7707.66455078125
Iteration 6: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it, episode=70, norm_ret=-8079.201, true_ret=-7667.391, steps=600]
Agent gate_2 episode reward: -8090.845703125
All agents episode reward: -8090.845703125
Agent gate_2 episode reward: -7732.73388671875
All agents episode reward: -7732.73388671875
Agent gate_2 episode reward: -8017.3623046875
All agents episode reward: -8017.3623046875
Agent gate_2 episode reward: -8118.876953125
All agents episode reward: -8118.876953125
Agent gate_2 episode reward: -9193.6279296875
All agents episode reward: -9193.6279296875
Agent gate_2 episode reward: -8166.482421875
All agents episode reward: -8166.482421875
Agent gate_2 episode reward: -8373.9013671875
All agents episode reward: -8373.9013671875
Agent gate_2 episode reward: -8167.69482421875
All agents episode reward: -8167.69482421875
Agent gate_2 episode reward: -7263.09228515625
All agents episode reward: -7263.09228515625
Agent gate_2 episode reward: -7667.39111328125
All agents episode reward: -7667.39111328125
Iteration 7: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it, episode=80, norm_ret=-8193.433, true_ret=-8508.363, steps=600]
Agent gate_2 episode reward: -8113.4482421875
All agents episode reward: -8113.4482421875
Agent gate_2 episode reward: -8073.37060546875
All agents episode reward: -8073.37060546875
Agent gate_2 episode reward: -7924.0888671875
All agents episode reward: -7924.0888671875
Agent gate_2 episode reward: -7578.81640625
All agents episode reward: -7578.81640625
Agent gate_2 episode reward: -8826.744140625
All agents episode reward: -8826.744140625
Agent gate_2 episode reward: -7662.69921875
All agents episode reward: -7662.69921875
Agent gate_2 episode reward: -8574.3291015625
All agents episode reward: -8574.3291015625
Agent gate_2 episode reward: -8731.3115234375
All agents episode reward: -8731.3115234375
Agent gate_2 episode reward: -7941.15234375
All agents episode reward: -7941.15234375
Agent gate_2 episode reward: -8508.36328125
All agents episode reward: -8508.36328125
Iteration 8: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=90, norm_ret=-8062.882, true_ret=-8410.889, steps=600]
Agent gate_2 episode reward: -7784.78466796875
All agents episode reward: -7784.78466796875
Agent gate_2 episode reward: -8050.97705078125
All agents episode reward: -8050.97705078125
Agent gate_2 episode reward: -8050.97607421875
All agents episode reward: -8050.97607421875
Agent gate_2 episode reward: -8180.34619140625
All agents episode reward: -8180.34619140625
Agent gate_2 episode reward: -8210.6552734375
All agents episode reward: -8210.6552734375
Agent gate_2 episode reward: -8595.267578125
All agents episode reward: -8595.267578125
Agent gate_2 episode reward: -7679.05224609375
All agents episode reward: -7679.05224609375
Agent gate_2 episode reward: -8103.95751953125
All agents episode reward: -8103.95751953125
Agent gate_2 episode reward: -7561.91552734375
All agents episode reward: -7561.91552734375
Agent gate_2 episode reward: -8410.888671875
All agents episode reward: -8410.888671875
Iteration 9: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=100, norm_ret=-8070.693, true_ret=-8362.017, steps=600]
Agent gate_2 episode reward: -7839.6083984375
All agents episode reward: -7839.6083984375
Agent gate_2 episode reward: -8229.130859375
All agents episode reward: -8229.130859375
Agent gate_2 episode reward: -7958.79931640625
All agents episode reward: -7958.79931640625
Agent gate_2 episode reward: -7705.14404296875
All agents episode reward: -7705.14404296875
Agent gate_2 episode reward: -7816.6630859375
All agents episode reward: -7816.6630859375
Agent gate_2 episode reward: -7663.234375
All agents episode reward: -7663.234375
Agent gate_2 episode reward: -9392.705078125
All agents episode reward: -9392.705078125
Agent gate_2 episode reward: -7954.72900390625
All agents episode reward: -7954.72900390625
Agent gate_2 episode reward: -7784.89697265625
All agents episode reward: -7784.89697265625
Agent gate_2 episode reward: -8362.0166015625
All agents episode reward: -8362.0166015625
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -53484.727 ± 24557.117
  Average reward: -53484.727 ± 24557.117
  Total reward: -53484.727 ± 24557.117
============================================================
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -8259.959 ± 365.042
  Average reward: -8259.959 ± 365.042
  Total reward: -8259.959 ± 365.042
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -8195.445 ± 395.701
  Average reward: -8195.445 ± 395.701
  Total reward: -8195.445 ± 395.701
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -53484.727
Rule-based avg reward: -8259.959
No control avg reward: -8195.445
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
