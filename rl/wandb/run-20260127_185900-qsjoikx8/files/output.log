Iteration 0: 100%|██████████| 10/10 [00:19<00:00,  1.97s/it, episode=10, norm_ret=-21456.584, true_ret=-8113.531, steps=600]
Agent gate_2 episode reward: -32103.77734375
All agents episode reward: -32103.77734375
Agent gate_2 episode reward: -14331.70703125
All agents episode reward: -14331.70703125
Agent gate_2 episode reward: -38299.90234375
All agents episode reward: -38299.90234375
Agent gate_2 episode reward: -60211.33203125
All agents episode reward: -60211.33203125
Agent gate_2 episode reward: -9188.8994140625
All agents episode reward: -9188.8994140625
Agent gate_2 episode reward: -21957.34765625
All agents episode reward: -21957.34765625
Agent gate_2 episode reward: -14354.998046875
All agents episode reward: -14354.998046875
Agent gate_2 episode reward: -8079.58984375
All agents episode reward: -8079.58984375
Agent gate_2 episode reward: -7924.7451171875
All agents episode reward: -7924.7451171875
Agent gate_2 episode reward: -8113.53076171875
All agents episode reward: -8113.53076171875
Iteration 1: 100%|██████████| 10/10 [00:19<00:00,  1.94s/it, episode=20, norm_ret=-9645.312, true_ret=-18985.391, steps=600]
Agent gate_2 episode reward: -7900.11962890625
All agents episode reward: -7900.11962890625
Agent gate_2 episode reward: -9793.5732421875
All agents episode reward: -9793.5732421875
Agent gate_2 episode reward: -12368.7509765625
All agents episode reward: -12368.7509765625
Agent gate_2 episode reward: -8292.2197265625
All agents episode reward: -8292.2197265625
Agent gate_2 episode reward: -8109.9033203125
All agents episode reward: -8109.9033203125
Agent gate_2 episode reward: -8081.515625
All agents episode reward: -8081.515625
Agent gate_2 episode reward: -8215.0244140625
All agents episode reward: -8215.0244140625
Agent gate_2 episode reward: -7097.97998046875
All agents episode reward: -7097.97998046875
Agent gate_2 episode reward: -7608.6416015625
All agents episode reward: -7608.6416015625
Agent gate_2 episode reward: -18985.390625
All agents episode reward: -18985.390625
Iteration 2: 100%|██████████| 10/10 [00:19<00:00,  1.96s/it, episode=30, norm_ret=-9222.389, true_ret=-8072.862, steps=600]
Agent gate_2 episode reward: -9508.4765625
All agents episode reward: -9508.4765625
Agent gate_2 episode reward: -15314.5107421875
All agents episode reward: -15314.5107421875
Agent gate_2 episode reward: -9415.548828125
All agents episode reward: -9415.548828125
Agent gate_2 episode reward: -9124.4912109375
All agents episode reward: -9124.4912109375
Agent gate_2 episode reward: -7661.72509765625
All agents episode reward: -7661.72509765625
Agent gate_2 episode reward: -8426.1650390625
All agents episode reward: -8426.1650390625
Agent gate_2 episode reward: -8402.197265625
All agents episode reward: -8402.197265625
Agent gate_2 episode reward: -8379.5927734375
All agents episode reward: -8379.5927734375
Agent gate_2 episode reward: -7918.32958984375
All agents episode reward: -7918.32958984375
Agent gate_2 episode reward: -8072.86181640625
All agents episode reward: -8072.86181640625
Iteration 3: 100%|██████████| 10/10 [00:19<00:00,  1.90s/it, episode=40, norm_ret=-24736.418, true_ret=-25146.250, steps=600]
Agent gate_2 episode reward: -7651.95556640625
All agents episode reward: -7651.95556640625
Agent gate_2 episode reward: -9255.4541015625
All agents episode reward: -9255.4541015625
Agent gate_2 episode reward: -12290.169921875
All agents episode reward: -12290.169921875
Agent gate_2 episode reward: -11230.28125
All agents episode reward: -11230.28125
Agent gate_2 episode reward: -13465.8466796875
All agents episode reward: -13465.8466796875
Agent gate_2 episode reward: -13310.6865234375
All agents episode reward: -13310.6865234375
Agent gate_2 episode reward: -14125.6611328125
All agents episode reward: -14125.6611328125
Agent gate_2 episode reward: -105599.5625
All agents episode reward: -105599.5625
Agent gate_2 episode reward: -35288.3046875
All agents episode reward: -35288.3046875
Agent gate_2 episode reward: -25146.25
All agents episode reward: -25146.25
Iteration 4: 100%|██████████| 10/10 [00:18<00:00,  1.85s/it, episode=50, norm_ret=-8163.213, true_ret=-8602.243, steps=600]
Agent gate_2 episode reward: -7715.5869140625
All agents episode reward: -7715.5869140625
Agent gate_2 episode reward: -8582.96875
All agents episode reward: -8582.96875
Agent gate_2 episode reward: -7933.97412109375
All agents episode reward: -7933.97412109375
Agent gate_2 episode reward: -7784.21728515625
All agents episode reward: -7784.21728515625
Agent gate_2 episode reward: -8017.79638671875
All agents episode reward: -8017.79638671875
Agent gate_2 episode reward: -7693.65966796875
All agents episode reward: -7693.65966796875
Agent gate_2 episode reward: -8330.4580078125
All agents episode reward: -8330.4580078125
Agent gate_2 episode reward: -8711.390625
All agents episode reward: -8711.390625
Agent gate_2 episode reward: -8259.837890625
All agents episode reward: -8259.837890625
Agent gate_2 episode reward: -8602.2431640625
All agents episode reward: -8602.2431640625
Iteration 5: 100%|██████████| 10/10 [00:19<00:00,  1.94s/it, episode=60, norm_ret=-8151.259, true_ret=-7799.571, steps=600]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -8775.624 at episode 51 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: -8775.6240234375
All agents episode reward: -8775.6240234375
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -8658.437 at episode 52 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: -8658.4365234375
All agents episode reward: -8658.4365234375
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -8259.887 at episode 53 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: -8259.88671875
All agents episode reward: -8259.88671875
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -7404.564 at episode 54 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: -7404.56396484375
All agents episode reward: -7404.56396484375
Agent gate_2 episode reward: -7917.21240234375
All agents episode reward: -7917.21240234375
Agent gate_2 episode reward: -7758.09033203125
All agents episode reward: -7758.09033203125
Agent gate_2 episode reward: -7454.6240234375
All agents episode reward: -7454.6240234375
Agent gate_2 episode reward: -8132.10546875
All agents episode reward: -8132.10546875
Agent gate_2 episode reward: -9352.4833984375
All agents episode reward: -9352.4833984375
Agent gate_2 episode reward: -7799.5712890625
All agents episode reward: -7799.5712890625
Iteration 6: 100%|██████████| 10/10 [00:19<00:00,  1.96s/it, episode=70, norm_ret=-12812.994, true_ret=-23100.873, steps=600]
Agent gate_2 episode reward: -7562.5126953125
All agents episode reward: -7562.5126953125
Agent gate_2 episode reward: -8284.8916015625
All agents episode reward: -8284.8916015625
Agent gate_2 episode reward: -8528.1611328125
All agents episode reward: -8528.1611328125
Agent gate_2 episode reward: -12248.7978515625
All agents episode reward: -12248.7978515625
Agent gate_2 episode reward: -10087.669921875
All agents episode reward: -10087.669921875
Agent gate_2 episode reward: -15395.736328125
All agents episode reward: -15395.736328125
Agent gate_2 episode reward: -17093.53515625
All agents episode reward: -17093.53515625
Agent gate_2 episode reward: -16815.166015625
All agents episode reward: -16815.166015625
Agent gate_2 episode reward: -9012.603515625
All agents episode reward: -9012.603515625
Agent gate_2 episode reward: -23100.873046875
All agents episode reward: -23100.873046875
Iteration 7: 100%|██████████| 10/10 [00:19<00:00,  1.93s/it, episode=80, norm_ret=-19348.328, true_ret=-10265.048, steps=600]
Agent gate_2 episode reward: -20149.6328125
All agents episode reward: -20149.6328125
Agent gate_2 episode reward: -9792.306640625
All agents episode reward: -9792.306640625
Agent gate_2 episode reward: -13214.775390625
All agents episode reward: -13214.775390625
Agent gate_2 episode reward: -15118.30859375
All agents episode reward: -15118.30859375
Agent gate_2 episode reward: -31450.515625
All agents episode reward: -31450.515625
Agent gate_2 episode reward: -47811.9609375
All agents episode reward: -47811.9609375
Agent gate_2 episode reward: -12386.6357421875
All agents episode reward: -12386.6357421875
Agent gate_2 episode reward: -24276.953125
All agents episode reward: -24276.953125
Agent gate_2 episode reward: -9017.134765625
All agents episode reward: -9017.134765625
Agent gate_2 episode reward: -10265.0478515625
All agents episode reward: -10265.0478515625
Iteration 8: 100%|██████████| 10/10 [00:19<00:00,  1.98s/it, episode=90, norm_ret=-15636.781, true_ret=-9190.240, steps=600]
Agent gate_2 episode reward: -14575.2822265625
All agents episode reward: -14575.2822265625
Agent gate_2 episode reward: -40613.27734375
All agents episode reward: -40613.27734375
Agent gate_2 episode reward: -23458.98046875
All agents episode reward: -23458.98046875
Agent gate_2 episode reward: -15136.2197265625
All agents episode reward: -15136.2197265625
Agent gate_2 episode reward: -8765.2314453125
All agents episode reward: -8765.2314453125
Agent gate_2 episode reward: -16220.990234375
All agents episode reward: -16220.990234375
Agent gate_2 episode reward: -10617.4677734375
All agents episode reward: -10617.4677734375
Agent gate_2 episode reward: -9487.12109375
All agents episode reward: -9487.12109375
Agent gate_2 episode reward: -8303.013671875
All agents episode reward: -8303.013671875
Agent gate_2 episode reward: -9190.240234375
All agents episode reward: -9190.240234375
Iteration 9: 100%|██████████| 10/10 [00:19<00:00,  1.90s/it, episode=100, norm_ret=-13853.936, true_ret=-15381.789, steps=600]
Agent gate_2 episode reward: -10362.7958984375
All agents episode reward: -10362.7958984375
Agent gate_2 episode reward: -14287.6728515625
All agents episode reward: -14287.6728515625
Agent gate_2 episode reward: -10335.59375
All agents episode reward: -10335.59375
Agent gate_2 episode reward: -9176.509765625
All agents episode reward: -9176.509765625
Agent gate_2 episode reward: -11001.5263671875
All agents episode reward: -11001.5263671875
Agent gate_2 episode reward: -18223.306640625
All agents episode reward: -18223.306640625
Agent gate_2 episode reward: -21175.6875
All agents episode reward: -21175.6875
Agent gate_2 episode reward: -8250.224609375
All agents episode reward: -8250.224609375
Agent gate_2 episode reward: -20344.2578125
All agents episode reward: -20344.2578125
Agent gate_2 episode reward: -15381.7890625
All agents episode reward: -15381.7890625
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -8072.990 ± 328.387
  Average reward: -8072.990 ± 328.387
  Total reward: -8072.990 ± 328.387
============================================================
Running 10 evaluation runs...
  Run 1/10... Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -8313.524 ± 491.624
  Average reward: -8313.524 ± 491.624
  Total reward: -8313.524 ± 491.624
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -8196.756 ± 260.918
  Average reward: -8196.756 ± 260.918
  Total reward: -8196.756 ± 260.918
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -8072.990
Rule-based avg reward: -8313.524
No control avg reward: -8196.756
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
