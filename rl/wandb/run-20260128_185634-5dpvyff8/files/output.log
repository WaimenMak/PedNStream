Iteration 0: 100%|██████████| 10/10 [00:19<00:00,  1.95s/it, episode=10, norm_ret=-14.011, true_ret=-165366096.000, steps=600]
Agent gate_2 episode reward: [-74.24645198]
All agents episode reward: [-74.24645198]
Agent gate_2 episode reward: [-0.03188499]
All agents episode reward: [-0.03188499]
Agent gate_2 episode reward: [-8.20428868]
All agents episode reward: [-8.20428868]
Agent gate_2 episode reward: [-7.99148608]
All agents episode reward: [-7.99148608]
Agent gate_2 episode reward: [-10.2207063]
All agents episode reward: [-10.2207063]
Agent gate_2 episode reward: [-6.51697885]
All agents episode reward: [-6.51697885]
Agent gate_2 episode reward: [-12.36102274]
All agents episode reward: [-12.36102274]
Agent gate_2 episode reward: [-6.28870608]
All agents episode reward: [-6.28870608]
Agent gate_2 episode reward: [-7.0769822]
All agents episode reward: [-7.0769822]
Agent gate_2 episode reward: [-7.17345147]
All agents episode reward: [-7.17345147]
Iteration 1: 100%|██████████| 10/10 [00:19<00:00,  1.96s/it, episode=20, norm_ret=-6.468, true_ret=-193813312.000, steps=600]
Agent gate_2 episode reward: [-20.68573088]
All agents episode reward: [-20.68573088]
Agent gate_2 episode reward: [-3.91866251]
All agents episode reward: [-3.91866251]
Agent gate_2 episode reward: [-3.9774958]
All agents episode reward: [-3.9774958]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-4.1834496]
All agents episode reward: [-4.1834496]
Agent gate_2 episode reward: [-11.60343725]
All agents episode reward: [-11.60343725]
Agent gate_2 episode reward: [-6.33470099]
All agents episode reward: [-6.33470099]
Agent gate_2 episode reward: [-8.06486651]
All agents episode reward: [-8.06486651]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-5.91327588]
All agents episode reward: [-5.91327588]
Iteration 2: 100%|██████████| 10/10 [00:18<00:00,  1.89s/it, episode=30, norm_ret=-5.175, true_ret=-152493632.000, steps=600]
Agent gate_2 episode reward: [-3.15311816]
All agents episode reward: [-3.15311816]
Agent gate_2 episode reward: [-3.99573263]
All agents episode reward: [-3.99573263]
Agent gate_2 episode reward: [-4.91790493]
All agents episode reward: [-4.91790493]
Agent gate_2 episode reward: [-2.59296578]
All agents episode reward: [-2.59296578]
Agent gate_2 episode reward: [-7.50206996]
All agents episode reward: [-7.50206996]
Agent gate_2 episode reward: [-5.39776565]
All agents episode reward: [-5.39776565]
Agent gate_2 episode reward: [-8.64965468]
All agents episode reward: [-8.64965468]
Agent gate_2 episode reward: [-2.19988647]
All agents episode reward: [-2.19988647]
Agent gate_2 episode reward: [-8.06163914]
All agents episode reward: [-8.06163914]
Agent gate_2 episode reward: [-5.28268137]
All agents episode reward: [-5.28268137]
Iteration 3: 100%|██████████| 10/10 [00:18<00:00,  1.88s/it, episode=40, norm_ret=-6.348, true_ret=-180535024.000, steps=600]
Agent gate_2 episode reward: [-7.85409615]
All agents episode reward: [-7.85409615]
Agent gate_2 episode reward: [-7.42693194]
All agents episode reward: [-7.42693194]
Agent gate_2 episode reward: [-7.95787341]
All agents episode reward: [-7.95787341]
Agent gate_2 episode reward: [-6.99257705]
All agents episode reward: [-6.99257705]
Agent gate_2 episode reward: [-0.00032488]
All agents episode reward: [-0.00032488]
Agent gate_2 episode reward: [-8.12316722]
All agents episode reward: [-8.12316722]
Agent gate_2 episode reward: [-8.84847735]
All agents episode reward: [-8.84847735]
Agent gate_2 episode reward: [-3.74839456]
All agents episode reward: [-3.74839456]
Agent gate_2 episode reward: [-5.84387221]
All agents episode reward: [-5.84387221]
Agent gate_2 episode reward: [-6.67981541]
All agents episode reward: [-6.67981541]
Iteration 4: 100%|██████████| 10/10 [00:19<00:00,  1.94s/it, episode=50, norm_ret=-7.085, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [-9.31202965]
All agents episode reward: [-9.31202965]
Agent gate_2 episode reward: [-9.05399452]
All agents episode reward: [-9.05399452]
Agent gate_2 episode reward: [-12.61905298]
All agents episode reward: [-12.61905298]
Agent gate_2 episode reward: [-3.91653622]
All agents episode reward: [-3.91653622]
Agent gate_2 episode reward: [-11.07229097]
All agents episode reward: [-11.07229097]
Agent gate_2 episode reward: [-9.64776266]
All agents episode reward: [-9.64776266]
Agent gate_2 episode reward: [-9.21114501]
All agents episode reward: [-9.21114501]
Agent gate_2 episode reward: [-6.02133239]
All agents episode reward: [-6.02133239]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Iteration 5: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it, episode=60, norm_ret=-6.450, true_ret=-342023200.000, steps=600]
Agent gate_2 episode reward: [-2.34901662]
All agents episode reward: [-2.34901662]
Agent gate_2 episode reward: [-10.59813668]
All agents episode reward: [-10.59813668]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-5.28988377]
All agents episode reward: [-5.28988377]
Agent gate_2 episode reward: [-10.37213808]
All agents episode reward: [-10.37213808]
Agent gate_2 episode reward: [-8.10475581]
All agents episode reward: [-8.10475581]
Agent gate_2 episode reward: [-6.07285864]
All agents episode reward: [-6.07285864]
Agent gate_2 episode reward: [-8.63610563]
All agents episode reward: [-8.63610563]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -123089456.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-13.07703091]
All agents episode reward: [-13.07703091]
Iteration 6: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=70, norm_ret=-6.990, true_ret=-204889328.000, steps=600]
Agent gate_2 episode reward: [-8.1145443]
All agents episode reward: [-8.1145443]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-8.02001225]
All agents episode reward: [-8.02001225]
Agent gate_2 episode reward: [-11.10973342]
All agents episode reward: [-11.10973342]
Agent gate_2 episode reward: [-9.11422845]
All agents episode reward: [-9.11422845]
Agent gate_2 episode reward: [-7.33865066]
All agents episode reward: [-7.33865066]
Agent gate_2 episode reward: [-8.65849609]
All agents episode reward: [-8.65849609]
Agent gate_2 episode reward: [-4.36141883]
All agents episode reward: [-4.36141883]
Agent gate_2 episode reward: [-5.12669946]
All agents episode reward: [-5.12669946]
Agent gate_2 episode reward: [-8.0561707]
All agents episode reward: [-8.0561707]
Iteration 7: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it, episode=80, norm_ret=-8.224, true_ret=-202445584.000, steps=600]
Agent gate_2 episode reward: [-7.62720696]
All agents episode reward: [-7.62720696]
Agent gate_2 episode reward: [-7.99790272]
All agents episode reward: [-7.99790272]
Agent gate_2 episode reward: [-6.02012002]
All agents episode reward: [-6.02012002]
Agent gate_2 episode reward: [-11.98845963]
All agents episode reward: [-11.98845963]
Agent gate_2 episode reward: [-10.72084154]
All agents episode reward: [-10.72084154]
Agent gate_2 episode reward: [-9.28876072]
All agents episode reward: [-9.28876072]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-9.17919173]
All agents episode reward: [-9.17919173]
Agent gate_2 episode reward: [-11.32388766]
All agents episode reward: [-11.32388766]
Agent gate_2 episode reward: [-8.09434187]
All agents episode reward: [-8.09434187]
Iteration 8: 100%|██████████| 10/10 [00:22<00:00,  2.24s/it, episode=90, norm_ret=-3.328, true_ret=-235719312.000, steps=600]
Agent gate_2 episode reward: [-6.4534386]
All agents episode reward: [-6.4534386]
Agent gate_2 episode reward: [-4.74926712]
All agents episode reward: [-4.74926712]
Agent gate_2 episode reward: [-3.46371296]
All agents episode reward: [-3.46371296]
Agent gate_2 episode reward: [-0.01508219]
All agents episode reward: [-0.01508219]
Agent gate_2 episode reward: [-1.02425745]
All agents episode reward: [-1.02425745]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-6.34310352]
All agents episode reward: [-6.34310352]
Agent gate_2 episode reward: [-1.60720524]
All agents episode reward: [-1.60720524]
Agent gate_2 episode reward: [-9.62009805]
All agents episode reward: [-9.62009805]
Iteration 9: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it, episode=100, norm_ret=-8.774, true_ret=-341632000.000, steps=600]
Agent gate_2 episode reward: [-6.62532846]
All agents episode reward: [-6.62532846]
Agent gate_2 episode reward: [-15.28616241]
All agents episode reward: [-15.28616241]
Agent gate_2 episode reward: [-7.26756888]
All agents episode reward: [-7.26756888]
Agent gate_2 episode reward: [-9.67741649]
All agents episode reward: [-9.67741649]
Agent gate_2 episode reward: [-13.17721339]
All agents episode reward: [-13.17721339]
Agent gate_2 episode reward: [-7.88629214]
All agents episode reward: [-7.88629214]
Agent gate_2 episode reward: [-0.49909963]
All agents episode reward: [-0.49909963]
Agent gate_2 episode reward: [-10.20451804]
All agents episode reward: [-10.20451804]
Agent gate_2 episode reward: [-3.26519267]
All agents episode reward: [-3.26519267]
Agent gate_2 episode reward: [-13.85551263]
All agents episode reward: [-13.85551263]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -291086400.000 | Total reward: -291086400.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -164033200.000 | Total reward: -164033200.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -354488160.000 | Total reward: -354488160.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -252756176.000 | Total reward: -252756176.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -243748384.000 | Total reward: -243748384.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -299674400.000 | Total reward: -299674400.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -242105808.000 | Total reward: -242105808.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -114556288.000 | Total reward: -114556288.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -25291514.000 | Total reward: -25291514.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -198774032.000 ± 112991416.000
  Average reward: -198774032.000 ± 112991416.000
  Total reward: -198774032.000 ± 112991416.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -315835424.000 | Total reward: -315835424.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -172199552.000 | Total reward: -172199552.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -323387712.000 | Total reward: -323387712.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -232400640.000 | Total reward: -232400640.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -224555808.000 | Total reward: -224555808.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -302417344.000 | Total reward: -302417344.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -256239168.000 | Total reward: -256239168.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -113925280.000 | Total reward: -113925280.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -32739990.000 | Total reward: -32739990.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -197370080.000 ± 109560848.000
  Average reward: -197370080.000 ± 109560848.000
  Total reward: -197370080.000 ± 109560848.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -300936416.000 | Total reward: -300936416.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -174771904.000 | Total reward: -174771904.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -355659008.000 | Total reward: -355659008.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -255033648.000 | Total reward: -255033648.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -230781648.000 | Total reward: -230781648.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -281791168.000 | Total reward: -281791168.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -247154176.000 | Total reward: -247154176.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -122851216.000 | Total reward: -122851216.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -39542724.000 | Total reward: -39542724.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -200852192.000 ± 109377824.000
  Average reward: -200852192.000 ± 109377824.000
  Total reward: -200852192.000 ± 109377824.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -198774032.000
Rule-based avg reward: -197370080.000
No control avg reward: -200852192.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
