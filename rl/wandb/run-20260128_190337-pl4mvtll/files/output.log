Iteration 0:  80%|████████  | 16/20 [00:38<00:10,  2.52s/it, episode=10, norm_ret=-10.050, true_ret=-196049856.000, steps=600]
Agent gate_2 episode reward: [-68.430451]
All agents episode reward: [-68.430451]
Agent gate_2 episode reward: [-0.2155434]
All agents episode reward: [-0.2155434]
Agent gate_2 episode reward: [-8.81832342]
All agents episode reward: [-8.81832342]
Agent gate_2 episode reward: [-7.39177484]
All agents episode reward: [-7.39177484]
Agent gate_2 episode reward: [-4.89723785]
All agents episode reward: [-4.89723785]
Agent gate_2 episode reward: [-2.2212682]
All agents episode reward: [-2.2212682]
Agent gate_2 episode reward: [-0.52721432]
All agents episode reward: [-0.52721432]
Agent gate_2 episode reward: [-1.8015925]
All agents episode reward: [-1.8015925]
Agent gate_2 episode reward: [-2.7276994]
All agents episode reward: [-2.7276994]
Agent gate_2 episode reward: [-3.4710186]
All agents episode reward: [-3.4710186]
Agent gate_2 episode reward: [-2.4382335]
All agents episode reward: [-2.4382335]
Agent gate_2 episode reward: [-3.42929817]
All agents episode reward: [-3.42929817]
Agent gate_2 episode reward: [-4.00306747]
All agents episode reward: [-4.00306747]
Agent gate_2 episode reward: [-3.02859196]
All agents episode reward: [-3.02859196]
Agent gate_2 episode reward: [-1.14647277]
All agents episode reward: [-1.14647277]
Agent gate_2 episode reward: [-5.0888635]
All agents episode reward: [-5.0888635]
Agent gate_2 episode reward: [-12.36344329]
All agents episode reward: [-12.36344329]
Agent gate_2 episode reward: [-4.03691646]
All agents episode reward: [-4.03691646]
Agent gate_2 episode reward: [-9.24295624]
All agents episode reward: [-9.24295624]
Agent gate_2 episode reward: [-2.29984177]
All agents episode reward: [-2.29984177]
Iteration 1:  80%|████████  | 16/20 [00:38<00:09,  2.47s/it, episode=30, norm_ret=-4.807, true_ret=-220903376.000, steps=600]
Agent gate_2 episode reward: [-6.23866598]
All agents episode reward: [-6.23866598]
Agent gate_2 episode reward: [-2.44874673]
All agents episode reward: [-2.44874673]
Agent gate_2 episode reward: [-5.6742085]
All agents episode reward: [-5.6742085]
Agent gate_2 episode reward: [-3.33528401]
All agents episode reward: [-3.33528401]
Agent gate_2 episode reward: [-3.33606885]
All agents episode reward: [-3.33606885]
Agent gate_2 episode reward: [-6.06113794]
All agents episode reward: [-6.06113794]
Agent gate_2 episode reward: [-4.9103113]
All agents episode reward: [-4.9103113]
Agent gate_2 episode reward: [-6.10301164]
All agents episode reward: [-6.10301164]
Agent gate_2 episode reward: [-4.65465294]
All agents episode reward: [-4.65465294]
Agent gate_2 episode reward: [-5.30517341]
All agents episode reward: [-5.30517341]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-8.72241724]
All agents episode reward: [-8.72241724]
Agent gate_2 episode reward: [-5.26394367]
All agents episode reward: [-5.26394367]
Agent gate_2 episode reward: [-5.15964485]
All agents episode reward: [-5.15964485]
Agent gate_2 episode reward: [-8.29933743]
All agents episode reward: [-8.29933743]
Agent gate_2 episode reward: [-5.3922461]
All agents episode reward: [-5.3922461]
Agent gate_2 episode reward: [-7.22478616]
All agents episode reward: [-7.22478616]
Agent gate_2 episode reward: [-7.3135135]
All agents episode reward: [-7.3135135]
Agent gate_2 episode reward: [-5.3400481]
All agents episode reward: [-5.3400481]
Agent gate_2 episode reward: [-2.18403547]
All agents episode reward: [-2.18403547]
Iteration 2:  80%|████████  | 16/20 [00:39<00:09,  2.39s/it, episode=50, norm_ret=-3.406, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [-6.72622419]
All agents episode reward: [-6.72622419]
Agent gate_2 episode reward: [-5.7462888]
All agents episode reward: [-5.7462888]
Agent gate_2 episode reward: [-0.55098167]
All agents episode reward: [-0.55098167]
Agent gate_2 episode reward: [-4.53383656]
All agents episode reward: [-4.53383656]
Agent gate_2 episode reward: [-5.12221528]
All agents episode reward: [-5.12221528]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-5.8388688]
All agents episode reward: [-5.8388688]
Agent gate_2 episode reward: [-5.54190744]
All agents episode reward: [-5.54190744]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-2.77555507]
All agents episode reward: [-2.77555507]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-2.63644912]
All agents episode reward: [-2.63644912]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-5.40230945]
All agents episode reward: [-5.40230945]
Agent gate_2 episode reward: [-7.75653336]
All agents episode reward: [-7.75653336]
Agent gate_2 episode reward: [-3.82101505]
All agents episode reward: [-3.82101505]
Iteration 3:  80%|████████  | 16/20 [00:38<00:09,  2.36s/it, episode=70, norm_ret=-6.373, true_ret=-282701856.000, steps=600]
Agent gate_2 episode reward: [-10.04773967]
All agents episode reward: [-10.04773967]
Agent gate_2 episode reward: [-9.59747949]
All agents episode reward: [-9.59747949]
Agent gate_2 episode reward: [-10.31004728]
All agents episode reward: [-10.31004728]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-0.87936215]
All agents episode reward: [-0.87936215]
Agent gate_2 episode reward: [-8.24211316]
All agents episode reward: [-8.24211316]
Agent gate_2 episode reward: [-7.39545291]
All agents episode reward: [-7.39545291]
Agent gate_2 episode reward: [-8.80260841]
All agents episode reward: [-8.80260841]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-8.45753604]
All agents episode reward: [-8.45753604]
Agent gate_2 episode reward: [-2.23625066]
All agents episode reward: [-2.23625066]
Agent gate_2 episode reward: [-4.93617886]
All agents episode reward: [-4.93617886]
Agent gate_2 episode reward: [-8.04906058]
All agents episode reward: [-8.04906058]
Agent gate_2 episode reward: [-9.74611884]
All agents episode reward: [-9.74611884]
Agent gate_2 episode reward: [-6.68115975]
All agents episode reward: [-6.68115975]
Agent gate_2 episode reward: [-6.31589952]
All agents episode reward: [-6.31589952]
Agent gate_2 episode reward: [-9.64986921]
All agents episode reward: [-9.64986921]
Agent gate_2 episode reward: [-5.85825914]
All agents episode reward: [-5.85825914]
Agent gate_2 episode reward: [-9.02688405]
All agents episode reward: [-9.02688405]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Iteration 4:  80%|████████  | 16/20 [00:39<00:09,  2.34s/it, episode=90, norm_ret=-4.923, true_ret=-43383304.000, steps=600]
Agent gate_2 episode reward: [-9.1325573]
All agents episode reward: [-9.1325573]
Agent gate_2 episode reward: [-8.93956222]
All agents episode reward: [-8.93956222]
Agent gate_2 episode reward: [-6.70229616]
All agents episode reward: [-6.70229616]
Agent gate_2 episode reward: [-7.72527004]
All agents episode reward: [-7.72527004]
Agent gate_2 episode reward: [-0.95895062]
All agents episode reward: [-0.95895062]
Agent gate_2 episode reward: [-3.92646878]
All agents episode reward: [-3.92646878]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-2.08049813]
All agents episode reward: [-2.08049813]
Agent gate_2 episode reward: [-8.39916916]
All agents episode reward: [-8.39916916]
Agent gate_2 episode reward: [-1.36927157]
All agents episode reward: [-1.36927157]
Agent gate_2 episode reward: [-6.77708582]
All agents episode reward: [-6.77708582]
Agent gate_2 episode reward: [-6.53260402]
All agents episode reward: [-6.53260402]
Agent gate_2 episode reward: [-3.84663603]
All agents episode reward: [-3.84663603]
Agent gate_2 episode reward: [-5.48868242]
All agents episode reward: [-5.48868242]
Agent gate_2 episode reward: [-8.46453477]
All agents episode reward: [-8.46453477]
Agent gate_2 episode reward: [-8.28618831]
All agents episode reward: [-8.28618831]
Agent gate_2 episode reward: [-3.77930682]
All agents episode reward: [-3.77930682]
Agent gate_2 episode reward: [-8.30914075]
All agents episode reward: [-8.30914075]
Agent gate_2 episode reward: [-5.57036906]
All agents episode reward: [-5.57036906]
Agent gate_2 episode reward: [-4.84054871]
All agents episode reward: [-4.84054871]
Iteration 5:  75%|███████▌  | 15/20 [00:41<00:15,  3.00s/it, episode=110, norm_ret=-7.840, true_ret=-278397504.000, steps=600]
Agent gate_2 episode reward: [-9.61647727]
All agents episode reward: [-9.61647727]
Agent gate_2 episode reward: [-9.28248266]
All agents episode reward: [-9.28248266]
Agent gate_2 episode reward: [-9.1373617]
All agents episode reward: [-9.1373617]
Agent gate_2 episode reward: [-10.41648848]
All agents episode reward: [-10.41648848]
Agent gate_2 episode reward: [-5.6137841]
All agents episode reward: [-5.6137841]
Agent gate_2 episode reward: [-9.51505339]
All agents episode reward: [-9.51505339]
Agent gate_2 episode reward: [-5.92136019]
All agents episode reward: [-5.92136019]
Agent gate_2 episode reward: [-4.5982853]
All agents episode reward: [-4.5982853]
Agent gate_2 episode reward: [-5.10821667]
All agents episode reward: [-5.10821667]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -176594544.000 at episode 110 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-9.18944892]
All agents episode reward: [-9.18944892]
Agent gate_2 episode reward: [-8.41385334]
All agents episode reward: [-8.41385334]
Agent gate_2 episode reward: [-5.55159143]
All agents episode reward: [-5.55159143]
Agent gate_2 episode reward: [-8.10498293]
All agents episode reward: [-8.10498293]
Agent gate_2 episode reward: [-7.28140269]
All agents episode reward: [-7.28140269]
Agent gate_2 episode reward: [-3.82420691]
All agents episode reward: [-3.82420691]
Agent gate_2 episode reward: [-6.97140225]
All agents episode reward: [-6.97140225]
Agent gate_2 episode reward: [-3.80355907]
All agents episode reward: [-3.80355907]
Agent gate_2 episode reward: [-2.7373768]
All agents episode reward: [-2.7373768]
Agent gate_2 episode reward: [-9.47372918]
All agents episode reward: [-9.47372918]
Agent gate_2 episode reward: [-5.12344307]
All agents episode reward: [-5.12344307]
Iteration 6:  75%|███████▌  | 15/20 [00:39<00:12,  2.53s/it, episode=130, norm_ret=-6.130, true_ret=-215016896.000, steps=600]
Agent gate_2 episode reward: [-5.85674604]
All agents episode reward: [-5.85674604]
Agent gate_2 episode reward: [-7.399036]
All agents episode reward: [-7.399036]
Agent gate_2 episode reward: [-8.20438966]
All agents episode reward: [-8.20438966]
Agent gate_2 episode reward: [-3.21656122]
All agents episode reward: [-3.21656122]
Agent gate_2 episode reward: [-8.12065617]
All agents episode reward: [-8.12065617]
Agent gate_2 episode reward: [-5.85643886]
All agents episode reward: [-5.85643886]
Agent gate_2 episode reward: [-7.24083738]
All agents episode reward: [-7.24083738]
Agent gate_2 episode reward: [-7.36554633]
All agents episode reward: [-7.36554633]
Agent gate_2 episode reward: [-0.54127002]
All agents episode reward: [-0.54127002]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -163937184.000 at episode 130 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-7.50256496]
All agents episode reward: [-7.50256496]
Agent gate_2 episode reward: [-8.29080549]
All agents episode reward: [-8.29080549]
Agent gate_2 episode reward: [-6.07560801]
All agents episode reward: [-6.07560801]
Agent gate_2 episode reward: [-4.94988388]
All agents episode reward: [-4.94988388]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-2.70788849]
All agents episode reward: [-2.70788849]
Agent gate_2 episode reward: [-8.00875622]
All agents episode reward: [-8.00875622]
Agent gate_2 episode reward: [-3.47184807]
All agents episode reward: [-3.47184807]
Agent gate_2 episode reward: [-12.88237727]
All agents episode reward: [-12.88237727]
Agent gate_2 episode reward: [-7.57440777]
All agents episode reward: [-7.57440777]
Agent gate_2 episode reward: [-8.60260809]
All agents episode reward: [-8.60260809]
Iteration 7:  80%|████████  | 16/20 [00:44<00:11,  2.83s/it, episode=150, norm_ret=-5.464, true_ret=-122813080.000, steps=600]
Agent gate_2 episode reward: [-8.50497173]
All agents episode reward: [-8.50497173]
Agent gate_2 episode reward: [-6.43088746]
All agents episode reward: [-6.43088746]
Agent gate_2 episode reward: [-10.28326688]
All agents episode reward: [-10.28326688]
Agent gate_2 episode reward: [-3.53524162]
All agents episode reward: [-3.53524162]
Agent gate_2 episode reward: [-6.13889262]
All agents episode reward: [-6.13889262]
Agent gate_2 episode reward: [-2.22762343]
All agents episode reward: [-2.22762343]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-8.82605093]
All agents episode reward: [-8.82605093]
Agent gate_2 episode reward: [-4.26696696]
All agents episode reward: [-4.26696696]
Agent gate_2 episode reward: [-4.42387492]
All agents episode reward: [-4.42387492]
Agent gate_2 episode reward: [-8.22621235]
All agents episode reward: [-8.22621235]
Agent gate_2 episode reward: [-6.90746082]
All agents episode reward: [-6.90746082]
Agent gate_2 episode reward: [-6.96086459]
All agents episode reward: [-6.96086459]
Agent gate_2 episode reward: [-11.00979474]
All agents episode reward: [-11.00979474]
Agent gate_2 episode reward: [-7.70450204]
All agents episode reward: [-7.70450204]
Agent gate_2 episode reward: [-1.84681547]
All agents episode reward: [-1.84681547]
Agent gate_2 episode reward: [-2.12084802]
All agents episode reward: [-2.12084802]
Agent gate_2 episode reward: [-5.70099301]
All agents episode reward: [-5.70099301]
Agent gate_2 episode reward: [-8.77770988]
All agents episode reward: [-8.77770988]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -100082304.000 at episode 160 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-11.08111473]
All agents episode reward: [-11.08111473]
Iteration 8:  80%|████████  | 16/20 [00:44<00:09,  2.49s/it, episode=170, norm_ret=-7.577, true_ret=-108516832.000, steps=600]
Agent gate_2 episode reward: [-6.93436094]
All agents episode reward: [-6.93436094]
Agent gate_2 episode reward: [-9.13445805]
All agents episode reward: [-9.13445805]
Agent gate_2 episode reward: [-6.67770987]
All agents episode reward: [-6.67770987]
Agent gate_2 episode reward: [-12.98284187]
All agents episode reward: [-12.98284187]
Agent gate_2 episode reward: [-9.5751246]
All agents episode reward: [-9.5751246]
Agent gate_2 episode reward: [-3.76723747]
All agents episode reward: [-3.76723747]
Agent gate_2 episode reward: [-9.69409638]
All agents episode reward: [-9.69409638]
Agent gate_2 episode reward: [-6.39992777]
All agents episode reward: [-6.39992777]
Agent gate_2 episode reward: [-6.62089717]
All agents episode reward: [-6.62089717]
Agent gate_2 episode reward: [-3.97927148]
All agents episode reward: [-3.97927148]
Agent gate_2 episode reward: [-6.51037006]
All agents episode reward: [-6.51037006]
Agent gate_2 episode reward: [-8.62059984]
All agents episode reward: [-8.62059984]
Agent gate_2 episode reward: [-6.50150303]
All agents episode reward: [-6.50150303]
Agent gate_2 episode reward: [-2.64878895]
All agents episode reward: [-2.64878895]
Agent gate_2 episode reward: [-3.3583317]
All agents episode reward: [-3.3583317]
Agent gate_2 episode reward: [-9.92252778]
All agents episode reward: [-9.92252778]
Agent gate_2 episode reward: [-6.91424524]
All agents episode reward: [-6.91424524]
Agent gate_2 episode reward: [-6.60752499]
All agents episode reward: [-6.60752499]
Agent gate_2 episode reward: [-6.35550442]
All agents episode reward: [-6.35550442]
Agent gate_2 episode reward: [-9.63434429]
All agents episode reward: [-9.63434429]
Iteration 9:  80%|████████  | 16/20 [00:44<00:10,  2.58s/it, episode=190, norm_ret=-6.661, true_ret=-288663744.000, steps=600]
Agent gate_2 episode reward: [-5.43401807]
All agents episode reward: [-5.43401807]
Agent gate_2 episode reward: [-5.48757511]
All agents episode reward: [-5.48757511]
Agent gate_2 episode reward: [-7.56413643]
All agents episode reward: [-7.56413643]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-6.82353787]
All agents episode reward: [-6.82353787]
Agent gate_2 episode reward: [-11.2671458]
All agents episode reward: [-11.2671458]
Agent gate_2 episode reward: [-4.9070854]
All agents episode reward: [-4.9070854]
Agent gate_2 episode reward: [-3.97656526]
All agents episode reward: [-3.97656526]
Agent gate_2 episode reward: [-10.2943602]
All agents episode reward: [-10.2943602]
Agent gate_2 episode reward: [-10.85072954]
All agents episode reward: [-10.85072954]
Agent gate_2 episode reward: [-6.78520146]
All agents episode reward: [-6.78520146]
Agent gate_2 episode reward: [-0.08823416]
All agents episode reward: [-0.08823416]
Agent gate_2 episode reward: [-4.74864707]
All agents episode reward: [-4.74864707]
Agent gate_2 episode reward: [-11.34184211]
All agents episode reward: [-11.34184211]
Agent gate_2 episode reward: [-2.07377866]
All agents episode reward: [-2.07377866]
Agent gate_2 episode reward: [-3.57803147]
All agents episode reward: [-3.57803147]
Agent gate_2 episode reward: [-8.08588039]
All agents episode reward: [-8.08588039]
Agent gate_2 episode reward: [-5.52716477]
All agents episode reward: [-5.52716477]
Agent gate_2 episode reward: [-12.26808247]
All agents episode reward: [-12.26808247]
Agent gate_2 episode reward: [-6.718038]
All agents episode reward: [-6.718038]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -303535296.000 | Total reward: -303535296.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -213600720.000 | Total reward: -213600720.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -500623584.000 | Total reward: -500623584.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -230505296.000 | Total reward: -230505296.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -315446944.000 | Total reward: -315446944.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -285946560.000 | Total reward: -285946560.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -459777920.000 | Total reward: -459777920.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -116269352.000 | Total reward: -116269352.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -19724276.000 | Total reward: -19724276.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -244543008.000 ± 158138672.000
  Average reward: -244543008.000 ± 158138672.000
  Total reward: -244543008.000 ± 158138672.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -318551936.000 | Total reward: -318551936.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -158026992.000 | Total reward: -158026992.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -355033344.000 | Total reward: -355033344.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -251233248.000 | Total reward: -251233248.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -235837440.000 | Total reward: -235837440.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -285735424.000 | Total reward: -285735424.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -243207952.000 | Total reward: -243207952.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -126130312.000 | Total reward: -126130312.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -29657576.000 | Total reward: -29657576.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -200341424.000 ± 112893928.000
  Average reward: -200341424.000 ± 112893928.000
  Total reward: -200341424.000 ± 112893928.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -308150464.000 | Total reward: -308150464.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -173089616.000 | Total reward: -173089616.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -338748160.000 | Total reward: -338748160.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -257910560.000 | Total reward: -257910560.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -211503760.000 | Total reward: -211503760.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -292335776.000 | Total reward: -292335776.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -244372080.000 | Total reward: -244372080.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -112059328.000 | Total reward: -112059328.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -30561522.000 | Total reward: -30561522.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -196873136.000 ± 110452560.000
  Average reward: -196873136.000 ± 110452560.000
  Total reward: -196873136.000 ± 110452560.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -244543008.000
Rule-based avg reward: -200341424.000
No control avg reward: -196873136.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
