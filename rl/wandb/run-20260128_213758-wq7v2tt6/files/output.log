Iteration 0:  80%|████████  | 16/20 [00:35<00:08,  2.15s/it, episode=10, norm_ret=-9.068, true_ret=-172639456.000, steps=600]
Agent gate_2 episode reward: [-70.15509744]
All agents episode reward: [-70.15509744]
Agent gate_2 episode reward: [-4.38911725]
All agents episode reward: [-4.38911725]
Agent gate_2 episode reward: [-4.79710028]
All agents episode reward: [-4.79710028]
Agent gate_2 episode reward: [-1.33581425]
All agents episode reward: [-1.33581425]
Agent gate_2 episode reward: [-3.29560502]
All agents episode reward: [-3.29560502]
Agent gate_2 episode reward: [-1.06166807]
All agents episode reward: [-1.06166807]
Agent gate_2 episode reward: [-1.30193785]
All agents episode reward: [-1.30193785]
Agent gate_2 episode reward: [-1.35643649]
All agents episode reward: [-1.35643649]
Agent gate_2 episode reward: [-1.45769404]
All agents episode reward: [-1.45769404]
Agent gate_2 episode reward: [-1.52503798]
All agents episode reward: [-1.52503798]
Agent gate_2 episode reward: [-1.6008042]
All agents episode reward: [-1.6008042]
Agent gate_2 episode reward: [-1.66973017]
All agents episode reward: [-1.66973017]
Agent gate_2 episode reward: [-1.72225774]
All agents episode reward: [-1.72225774]
Agent gate_2 episode reward: [-1.76494189]
All agents episode reward: [-1.76494189]
Agent gate_2 episode reward: [-1.86482633]
All agents episode reward: [-1.86482633]
Agent gate_2 episode reward: [-1.96186168]
All agents episode reward: [-1.96186168]
Agent gate_2 episode reward: [-1.89265908]
All agents episode reward: [-1.89265908]
Agent gate_2 episode reward: [-2.00114871]
All agents episode reward: [-2.00114871]
Agent gate_2 episode reward: [-2.0150738]
All agents episode reward: [-2.0150738]
Agent gate_2 episode reward: [-2.09680726]
All agents episode reward: [-2.09680726]
Iteration 1:  80%|████████  | 16/20 [00:34<00:08,  2.21s/it, episode=30, norm_ret=-2.310, true_ret=-175496816.000, steps=600]
Agent gate_2 episode reward: [-2.114526]
All agents episode reward: [-2.114526]
Agent gate_2 episode reward: [-2.10881941]
All agents episode reward: [-2.10881941]
Agent gate_2 episode reward: [-2.22978516]
All agents episode reward: [-2.22978516]
Agent gate_2 episode reward: [-2.24368718]
All agents episode reward: [-2.24368718]
Agent gate_2 episode reward: [-2.29218983]
All agents episode reward: [-2.29218983]
Agent gate_2 episode reward: [-2.36237496]
All agents episode reward: [-2.36237496]
Agent gate_2 episode reward: [-2.41437685]
All agents episode reward: [-2.41437685]
Agent gate_2 episode reward: [-2.31806408]
All agents episode reward: [-2.31806408]
Agent gate_2 episode reward: [-2.48238388]
All agents episode reward: [-2.48238388]
Agent gate_2 episode reward: [-2.53722072]
All agents episode reward: [-2.53722072]
Agent gate_2 episode reward: [-2.44524996]
All agents episode reward: [-2.44524996]
Agent gate_2 episode reward: [-2.40725031]
All agents episode reward: [-2.40725031]
Agent gate_2 episode reward: [-2.62797542]
All agents episode reward: [-2.62797542]
Agent gate_2 episode reward: [-2.68348463]
All agents episode reward: [-2.68348463]
Agent gate_2 episode reward: [-2.70832603]
All agents episode reward: [-2.70832603]
Agent gate_2 episode reward: [-2.78619872]
All agents episode reward: [-2.78619872]
Agent gate_2 episode reward: [-2.53656184]
All agents episode reward: [-2.53656184]
Agent gate_2 episode reward: [-2.73347082]
All agents episode reward: [-2.73347082]
Agent gate_2 episode reward: [-2.76431928]
All agents episode reward: [-2.76431928]
Agent gate_2 episode reward: [-2.22763029]
All agents episode reward: [-2.22763029]
Iteration 2:  80%|████████  | 16/20 [00:34<00:08,  2.16s/it, episode=50, norm_ret=-3.020, true_ret=-173112464.000, steps=600]
Agent gate_2 episode reward: [-2.50128764]
All agents episode reward: [-2.50128764]
Agent gate_2 episode reward: [-2.94063588]
All agents episode reward: [-2.94063588]
Agent gate_2 episode reward: [-3.01325984]
All agents episode reward: [-3.01325984]
Agent gate_2 episode reward: [-2.95687727]
All agents episode reward: [-2.95687727]
Agent gate_2 episode reward: [-3.23452018]
All agents episode reward: [-3.23452018]
Agent gate_2 episode reward: [-3.0501282]
All agents episode reward: [-3.0501282]
Agent gate_2 episode reward: [-3.10417165]
All agents episode reward: [-3.10417165]
Agent gate_2 episode reward: [-3.11642286]
All agents episode reward: [-3.11642286]
Agent gate_2 episode reward: [-3.12120992]
All agents episode reward: [-3.12120992]
Agent gate_2 episode reward: [-3.16111512]
All agents episode reward: [-3.16111512]
Agent gate_2 episode reward: [-3.20597617]
All agents episode reward: [-3.20597617]
Agent gate_2 episode reward: [-3.23873104]
All agents episode reward: [-3.23873104]
Agent gate_2 episode reward: [-3.26101385]
All agents episode reward: [-3.26101385]
Agent gate_2 episode reward: [-3.27305198]
All agents episode reward: [-3.27305198]
Agent gate_2 episode reward: [-3.31805056]
All agents episode reward: [-3.31805056]
Agent gate_2 episode reward: [-3.41213653]
All agents episode reward: [-3.41213653]
Agent gate_2 episode reward: [-3.38782947]
All agents episode reward: [-3.38782947]
Agent gate_2 episode reward: [-3.41939149]
All agents episode reward: [-3.41939149]
Agent gate_2 episode reward: [-3.44245985]
All agents episode reward: [-3.44245985]
Agent gate_2 episode reward: [-3.45750367]
All agents episode reward: [-3.45750367]
Iteration 3:  80%|████████  | 16/20 [00:34<00:08,  2.14s/it, episode=70, norm_ret=-3.593, true_ret=-169363600.000, steps=600]
Agent gate_2 episode reward: [-3.47285317]
All agents episode reward: [-3.47285317]
Agent gate_2 episode reward: [-3.48165489]
All agents episode reward: [-3.48165489]
Agent gate_2 episode reward: [-3.56178352]
All agents episode reward: [-3.56178352]
Agent gate_2 episode reward: [-3.55808804]
All agents episode reward: [-3.55808804]
Agent gate_2 episode reward: [-3.63717422]
All agents episode reward: [-3.63717422]
Agent gate_2 episode reward: [-3.62311584]
All agents episode reward: [-3.62311584]
Agent gate_2 episode reward: [-3.63106848]
All agents episode reward: [-3.63106848]
Agent gate_2 episode reward: [-3.67458798]
All agents episode reward: [-3.67458798]
Agent gate_2 episode reward: [-3.68992827]
All agents episode reward: [-3.68992827]
Agent gate_2 episode reward: [-3.5980503]
All agents episode reward: [-3.5980503]
Agent gate_2 episode reward: [-3.76598452]
All agents episode reward: [-3.76598452]
Agent gate_2 episode reward: [-3.73410561]
All agents episode reward: [-3.73410561]
Agent gate_2 episode reward: [-3.79697124]
All agents episode reward: [-3.79697124]
Agent gate_2 episode reward: [-3.81494137]
All agents episode reward: [-3.81494137]
Agent gate_2 episode reward: [-3.8501162]
All agents episode reward: [-3.8501162]
Agent gate_2 episode reward: [-3.81257972]
All agents episode reward: [-3.81257972]
Agent gate_2 episode reward: [-3.87826448]
All agents episode reward: [-3.87826448]
Agent gate_2 episode reward: [-3.85362147]
All agents episode reward: [-3.85362147]
Agent gate_2 episode reward: [-3.87640668]
All agents episode reward: [-3.87640668]
Agent gate_2 episode reward: [-3.90167182]
All agents episode reward: [-3.90167182]
Iteration 4:  80%|████████  | 16/20 [00:35<00:08,  2.19s/it, episode=90, norm_ret=-4.060, true_ret=-174206368.000, steps=600]
Agent gate_2 episode reward: [-3.97050377]
All agents episode reward: [-3.97050377]
Agent gate_2 episode reward: [-3.95333874]
All agents episode reward: [-3.95333874]
Agent gate_2 episode reward: [-4.01047669]
All agents episode reward: [-4.01047669]
Agent gate_2 episode reward: [-4.02143569]
All agents episode reward: [-4.02143569]
Agent gate_2 episode reward: [-4.06409926]
All agents episode reward: [-4.06409926]
Agent gate_2 episode reward: [-4.08640175]
All agents episode reward: [-4.08640175]
Agent gate_2 episode reward: [-4.11584572]
All agents episode reward: [-4.11584572]
Agent gate_2 episode reward: [-4.11763841]
All agents episode reward: [-4.11763841]
Agent gate_2 episode reward: [-4.12538875]
All agents episode reward: [-4.12538875]
Agent gate_2 episode reward: [-4.13368917]
All agents episode reward: [-4.13368917]
Agent gate_2 episode reward: [-4.17966075]
All agents episode reward: [-4.17966075]
Agent gate_2 episode reward: [-4.17223244]
All agents episode reward: [-4.17223244]
Agent gate_2 episode reward: [-4.1598937]
All agents episode reward: [-4.1598937]
Agent gate_2 episode reward: [-4.21600232]
All agents episode reward: [-4.21600232]
Agent gate_2 episode reward: [-4.21155387]
All agents episode reward: [-4.21155387]
Agent gate_2 episode reward: [-4.21488761]
All agents episode reward: [-4.21488761]
Agent gate_2 episode reward: [-4.25975539]
All agents episode reward: [-4.25975539]
Agent gate_2 episode reward: [-4.32076704]
All agents episode reward: [-4.32076704]
Agent gate_2 episode reward: [-4.34275935]
All agents episode reward: [-4.34275935]
Agent gate_2 episode reward: [-4.30503304]
All agents episode reward: [-4.30503304]
Iteration 5:  75%|███████▌  | 15/20 [00:36<00:12,  2.42s/it, episode=110, norm_ret=-4.455, true_ret=-172753216.000, steps=600]
Agent gate_2 episode reward: [-4.37379925]
All agents episode reward: [-4.37379925]
Agent gate_2 episode reward: [-4.32157245]
All agents episode reward: [-4.32157245]
Agent gate_2 episode reward: [-4.39400046]
All agents episode reward: [-4.39400046]
Agent gate_2 episode reward: [-4.46437639]
All agents episode reward: [-4.46437639]
Agent gate_2 episode reward: [-4.48254576]
All agents episode reward: [-4.48254576]
Agent gate_2 episode reward: [-4.50030949]
All agents episode reward: [-4.50030949]
Agent gate_2 episode reward: [-4.51863468]
All agents episode reward: [-4.51863468]
Agent gate_2 episode reward: [-4.50160658]
All agents episode reward: [-4.50160658]
Agent gate_2 episode reward: [-4.52618149]
All agents episode reward: [-4.52618149]
Saved 1 agents to ppo_agents_butterfly_scA
[Validation] New best avg return: -176780880.000 at episode 110 (over 5 val episodes, saved to ppo_agents_butterfly_scA)
Agent gate_2 episode reward: [-4.46777016]
All agents episode reward: [-4.46777016]
Agent gate_2 episode reward: [-4.68902763]
All agents episode reward: [-4.68902763]
Agent gate_2 episode reward: [-4.69193917]
All agents episode reward: [-4.69193917]
Agent gate_2 episode reward: [-4.70893692]
All agents episode reward: [-4.70893692]
Agent gate_2 episode reward: [-4.62695372]
All agents episode reward: [-4.62695372]
Agent gate_2 episode reward: [-4.6965224]
All agents episode reward: [-4.6965224]
Agent gate_2 episode reward: [-4.7586906]
All agents episode reward: [-4.7586906]
Agent gate_2 episode reward: [-4.73508322]
All agents episode reward: [-4.73508322]
Agent gate_2 episode reward: [-4.71673441]
All agents episode reward: [-4.71673441]
Agent gate_2 episode reward: [-4.80744662]
All agents episode reward: [-4.80744662]
Agent gate_2 episode reward: [-4.82348306]
All agents episode reward: [-4.82348306]
Iteration 6:  80%|████████  | 16/20 [00:37<00:09,  2.26s/it, episode=130, norm_ret=-4.947, true_ret=-175887552.000, steps=600]
Agent gate_2 episode reward: [-4.92080418]
All agents episode reward: [-4.92080418]
Agent gate_2 episode reward: [-4.83048178]
All agents episode reward: [-4.83048178]
Agent gate_2 episode reward: [-4.93554126]
All agents episode reward: [-4.93554126]
Agent gate_2 episode reward: [-4.96371363]
All agents episode reward: [-4.96371363]
Agent gate_2 episode reward: [-4.95845446]
All agents episode reward: [-4.95845446]
Agent gate_2 episode reward: [-4.93848515]
All agents episode reward: [-4.93848515]
Agent gate_2 episode reward: [-4.92408464]
All agents episode reward: [-4.92408464]
Agent gate_2 episode reward: [-4.95378439]
All agents episode reward: [-4.95378439]
Agent gate_2 episode reward: [-5.01296071]
All agents episode reward: [-5.01296071]
Agent gate_2 episode reward: [-5.02785712]
All agents episode reward: [-5.02785712]
Agent gate_2 episode reward: [-5.10542771]
All agents episode reward: [-5.10542771]
Agent gate_2 episode reward: [-5.13819098]
All agents episode reward: [-5.13819098]
Agent gate_2 episode reward: [-5.15893061]
All agents episode reward: [-5.15893061]
Agent gate_2 episode reward: [-5.10178852]
All agents episode reward: [-5.10178852]
Agent gate_2 episode reward: [-5.12692868]
All agents episode reward: [-5.12692868]
Agent gate_2 episode reward: [-5.16046674]
All agents episode reward: [-5.16046674]
Agent gate_2 episode reward: [-5.14877929]
All agents episode reward: [-5.14877929]
Agent gate_2 episode reward: [-5.17070738]
All agents episode reward: [-5.17070738]
Agent gate_2 episode reward: [-5.1549156]
All agents episode reward: [-5.1549156]
Agent gate_2 episode reward: [-5.20577335]
All agents episode reward: [-5.20577335]
Iteration 7:  80%|████████  | 16/20 [00:37<00:08,  2.25s/it, episode=150, norm_ret=-5.349, true_ret=-174981888.000, steps=600]
Agent gate_2 episode reward: [-5.29811921]
All agents episode reward: [-5.29811921]
Agent gate_2 episode reward: [-5.31736362]
All agents episode reward: [-5.31736362]
Agent gate_2 episode reward: [-5.32851427]
All agents episode reward: [-5.32851427]
Agent gate_2 episode reward: [-5.30099051]
All agents episode reward: [-5.30099051]
Agent gate_2 episode reward: [-5.28511318]
All agents episode reward: [-5.28511318]
Agent gate_2 episode reward: [-5.35310752]
All agents episode reward: [-5.35310752]
Agent gate_2 episode reward: [-5.40353498]
All agents episode reward: [-5.40353498]
Agent gate_2 episode reward: [-5.39555938]
All agents episode reward: [-5.39555938]
Agent gate_2 episode reward: [-5.40436519]
All agents episode reward: [-5.40436519]
Agent gate_2 episode reward: [-5.40628961]
All agents episode reward: [-5.40628961]
Agent gate_2 episode reward: [-5.45737815]
All agents episode reward: [-5.45737815]
Agent gate_2 episode reward: [-5.50956751]
All agents episode reward: [-5.50956751]
Agent gate_2 episode reward: [-5.52595087]
All agents episode reward: [-5.52595087]
Agent gate_2 episode reward: [-5.45509943]
All agents episode reward: [-5.45509943]
Agent gate_2 episode reward: [-5.58514859]
All agents episode reward: [-5.58514859]
Agent gate_2 episode reward: [-5.47793021]
All agents episode reward: [-5.47793021]
Agent gate_2 episode reward: [-5.56165575]
All agents episode reward: [-5.56165575]
Agent gate_2 episode reward: [-5.62114033]
All agents episode reward: [-5.62114033]
Agent gate_2 episode reward: [-5.51788622]
All agents episode reward: [-5.51788622]
Agent gate_2 episode reward: [-5.63786701]
All agents episode reward: [-5.63786701]
Iteration 8:  80%|████████  | 16/20 [00:38<00:09,  2.36s/it, episode=170, norm_ret=-5.736, true_ret=-176780880.000, steps=600]
Agent gate_2 episode reward: [-5.66564623]
All agents episode reward: [-5.66564623]
Agent gate_2 episode reward: [-5.72579739]
All agents episode reward: [-5.72579739]
Agent gate_2 episode reward: [-5.68823242]
All agents episode reward: [-5.68823242]
Agent gate_2 episode reward: [-5.74945016]
All agents episode reward: [-5.74945016]
Agent gate_2 episode reward: [-5.759768]
All agents episode reward: [-5.759768]
Agent gate_2 episode reward: [-5.63205817]
All agents episode reward: [-5.63205817]
Agent gate_2 episode reward: [-5.72409902]
All agents episode reward: [-5.72409902]
Agent gate_2 episode reward: [-5.79342212]
All agents episode reward: [-5.79342212]
Agent gate_2 episode reward: [-5.80429962]
All agents episode reward: [-5.80429962]
Agent gate_2 episode reward: [-5.81548836]
All agents episode reward: [-5.81548836]
Agent gate_2 episode reward: [-5.88056569]
All agents episode reward: [-5.88056569]
Agent gate_2 episode reward: [-5.89125198]
All agents episode reward: [-5.89125198]
Agent gate_2 episode reward: [-5.90189349]
All agents episode reward: [-5.90189349]
Agent gate_2 episode reward: [-5.91249055]
All agents episode reward: [-5.91249055]
Agent gate_2 episode reward: [-5.92304348]
All agents episode reward: [-5.92304348]
Agent gate_2 episode reward: [-5.93355262]
All agents episode reward: [-5.93355262]
Agent gate_2 episode reward: [-5.94401829]
All agents episode reward: [-5.94401829]
Agent gate_2 episode reward: [-5.95444079]
All agents episode reward: [-5.95444079]
Agent gate_2 episode reward: [-5.96482045]
All agents episode reward: [-5.96482045]
Agent gate_2 episode reward: [-5.97515758]
All agents episode reward: [-5.97515758]
Iteration 9:  80%|████████  | 16/20 [00:37<00:08,  2.25s/it, episode=190, norm_ret=-6.081, true_ret=-176780880.000, steps=600]
Agent gate_2 episode reward: [-6.03630409]
All agents episode reward: [-6.03630409]
Agent gate_2 episode reward: [-6.0463519]
All agents episode reward: [-6.0463519]
Agent gate_2 episode reward: [-6.05635953]
All agents episode reward: [-6.05635953]
Agent gate_2 episode reward: [-6.06632727]
All agents episode reward: [-6.06632727]
Agent gate_2 episode reward: [-6.07625541]
All agents episode reward: [-6.07625541]
Agent gate_2 episode reward: [-6.0861442]
All agents episode reward: [-6.0861442]
Agent gate_2 episode reward: [-6.09599394]
All agents episode reward: [-6.09599394]
Agent gate_2 episode reward: [-6.10580488]
All agents episode reward: [-6.10580488]
Agent gate_2 episode reward: [-6.1155773]
All agents episode reward: [-6.1155773]
Agent gate_2 episode reward: [-6.12531145]
All agents episode reward: [-6.12531145]
Agent gate_2 episode reward: [-6.18292726]
All agents episode reward: [-6.18292726]
Agent gate_2 episode reward: [-6.19240073]
All agents episode reward: [-6.19240073]
Agent gate_2 episode reward: [-6.20183795]
All agents episode reward: [-6.20183795]
Agent gate_2 episode reward: [-6.21123916]
All agents episode reward: [-6.21123916]
Agent gate_2 episode reward: [-6.22060459]
All agents episode reward: [-6.22060459]
Agent gate_2 episode reward: [-6.16940827]
All agents episode reward: [-6.16940827]
Agent gate_2 episode reward: [-6.23924949]
All agents episode reward: [-6.23924949]
Agent gate_2 episode reward: [-6.24850908]
All agents episode reward: [-6.24850908]
Agent gate_2 episode reward: [-6.25773382]
All agents episode reward: [-6.25773382]
Agent gate_2 episode reward: [-6.26692394]
All agents episode reward: [-6.26692394]
Loaded 1 agents from ppo_agents_butterfly_scA
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -176780880.000 | Total reward: -176780880.000
Saved run 1 to rl_training/butterfly_scA/ppo_run1
  Run 2/10... Avg agent reward (episode): -181913984.000 | Total reward: -181913984.000
Saved run 2 to rl_training/butterfly_scA/ppo_run2
  Run 3/10... Avg agent reward (episode): -181939680.000 | Total reward: -181939680.000
Saved run 3 to rl_training/butterfly_scA/ppo_run3
  Run 4/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 4 to rl_training/butterfly_scA/ppo_run4
  Run 5/10... Avg agent reward (episode): -176364000.000 | Total reward: -176364000.000
Saved run 5 to rl_training/butterfly_scA/ppo_run5
  Run 6/10... Avg agent reward (episode): -165656032.000 | Total reward: -165656032.000
Saved run 6 to rl_training/butterfly_scA/ppo_run6
  Run 7/10... Avg agent reward (episode): -119667832.000 | Total reward: -119667832.000
Saved run 7 to rl_training/butterfly_scA/ppo_run7
  Run 8/10... Avg agent reward (episode): -92511352.000 | Total reward: -92511352.000
Saved run 8 to rl_training/butterfly_scA/ppo_run8
  Run 9/10... Avg agent reward (episode): -177468160.000 | Total reward: -177468160.000
Saved run 9 to rl_training/butterfly_scA/ppo_run9
  Run 10/10... Avg agent reward (episode): -169731024.000 | Total reward: -169731024.000
Saved run 10 to rl_training/butterfly_scA/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -144203296.000 ± 55882744.000
  Average reward: -144203296.000 ± 55882744.000
  Total reward: -144203296.000 ± 55882744.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -176780880.000 | Total reward: -176780880.000
Saved run 1 to rl_training/butterfly_scA/rule_based_run1
  Run 2/10... Avg agent reward (episode): -181913984.000 | Total reward: -181913984.000
Saved run 2 to rl_training/butterfly_scA/rule_based_run2
  Run 3/10... Avg agent reward (episode): -181939680.000 | Total reward: -181939680.000
Saved run 3 to rl_training/butterfly_scA/rule_based_run3
  Run 4/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 4 to rl_training/butterfly_scA/rule_based_run4
  Run 5/10... Avg agent reward (episode): -176364000.000 | Total reward: -176364000.000
Saved run 5 to rl_training/butterfly_scA/rule_based_run5
  Run 6/10... Avg agent reward (episode): -165656032.000 | Total reward: -165656032.000
Saved run 6 to rl_training/butterfly_scA/rule_based_run6
  Run 7/10... Avg agent reward (episode): -119667832.000 | Total reward: -119667832.000
Saved run 7 to rl_training/butterfly_scA/rule_based_run7
  Run 8/10... Avg agent reward (episode): -92511352.000 | Total reward: -92511352.000
Saved run 8 to rl_training/butterfly_scA/rule_based_run8
  Run 9/10... Avg agent reward (episode): -177468160.000 | Total reward: -177468160.000
Saved run 9 to rl_training/butterfly_scA/rule_based_run9
  Run 10/10... Avg agent reward (episode): -169731024.000 | Total reward: -169731024.000
Saved run 10 to rl_training/butterfly_scA/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -144203296.000 ± 55882744.000
  Average reward: -144203296.000 ± 55882744.000
  Total reward: -144203296.000 ± 55882744.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -176780880.000 | Total reward: -176780880.000
Saved run 1 to rl_training/butterfly_scA/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -181913984.000 | Total reward: -181913984.000
Saved run 2 to rl_training/butterfly_scA/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -181939680.000 | Total reward: -181939680.000
Saved run 3 to rl_training/butterfly_scA/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 4 to rl_training/butterfly_scA/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -176364000.000 | Total reward: -176364000.000
Saved run 5 to rl_training/butterfly_scA/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -165656032.000 | Total reward: -165656032.000
Saved run 6 to rl_training/butterfly_scA/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -119667832.000 | Total reward: -119667832.000
Saved run 7 to rl_training/butterfly_scA/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -92511352.000 | Total reward: -92511352.000
Saved run 8 to rl_training/butterfly_scA/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -177468160.000 | Total reward: -177468160.000
Saved run 9 to rl_training/butterfly_scA/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -169731024.000 | Total reward: -169731024.000
Saved run 10 to rl_training/butterfly_scA/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -144203296.000 ± 55882744.000
  Average reward: -144203296.000 ± 55882744.000
  Total reward: -144203296.000 ± 55882744.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -144203296.000
Rule-based avg reward: -144203296.000
No control avg reward: -144203296.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
