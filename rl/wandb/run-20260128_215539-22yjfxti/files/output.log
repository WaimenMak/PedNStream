Iteration 0: 100%|██████████| 10/10 [00:23<00:00,  2.33s/it, episode=10, norm_ret=-5.318, true_ret=-1820122.000, steps=600]
Agent gate_2 episode reward: [-47.66646749]
All agents episode reward: [-47.66646749]
Agent gate_2 episode reward: [-1.60512515]
All agents episode reward: [-1.60512515]
Agent gate_2 episode reward: [-1.70130004]
All agents episode reward: [-1.70130004]
Agent gate_2 episode reward: [-1.17857849]
All agents episode reward: [-1.17857849]
Agent gate_2 episode reward: [-0.13236685]
All agents episode reward: [-0.13236685]
Agent gate_2 episode reward: [-0.18628535]
All agents episode reward: [-0.18628535]
Agent gate_2 episode reward: [-0.06258741]
All agents episode reward: [-0.06258741]
Agent gate_2 episode reward: [-0.3823774]
All agents episode reward: [-0.3823774]
Agent gate_2 episode reward: [-0.21830025]
All agents episode reward: [-0.21830025]
Agent gate_2 episode reward: [-0.05103836]
All agents episode reward: [-0.05103836]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=20, norm_ret=-0.009, true_ret=-354082.688, steps=600]
Agent gate_2 episode reward: [0.00024492]
All agents episode reward: [0.00024492]
Agent gate_2 episode reward: [-0.00386355]
All agents episode reward: [-0.00386355]
Agent gate_2 episode reward: [-0.00327419]
All agents episode reward: [-0.00327419]
Agent gate_2 episode reward: [-0.01161879]
All agents episode reward: [-0.01161879]
Agent gate_2 episode reward: [-0.00412753]
All agents episode reward: [-0.00412753]
Agent gate_2 episode reward: [-0.00829364]
All agents episode reward: [-0.00829364]
Agent gate_2 episode reward: [-0.01360434]
All agents episode reward: [-0.01360434]
Agent gate_2 episode reward: [-0.01325998]
All agents episode reward: [-0.01325998]
Agent gate_2 episode reward: [-0.01425652]
All agents episode reward: [-0.01425652]
Agent gate_2 episode reward: [-0.01409567]
All agents episode reward: [-0.01409567]
Iteration 2: 100%|██████████| 10/10 [00:21<00:00,  2.17s/it, episode=30, norm_ret=-0.016, true_ret=-356590.094, steps=600]
Agent gate_2 episode reward: [-0.01448252]
All agents episode reward: [-0.01448252]
Agent gate_2 episode reward: [-0.01474553]
All agents episode reward: [-0.01474553]
Agent gate_2 episode reward: [-0.01518538]
All agents episode reward: [-0.01518538]
Agent gate_2 episode reward: [-0.01539262]
All agents episode reward: [-0.01539262]
Agent gate_2 episode reward: [-0.01638141]
All agents episode reward: [-0.01638141]
Agent gate_2 episode reward: [-0.01618553]
All agents episode reward: [-0.01618553]
Agent gate_2 episode reward: [-0.01707687]
All agents episode reward: [-0.01707687]
Agent gate_2 episode reward: [-0.01666917]
All agents episode reward: [-0.01666917]
Agent gate_2 episode reward: [-0.01779661]
All agents episode reward: [-0.01779661]
Agent gate_2 episode reward: [-0.01750478]
All agents episode reward: [-0.01750478]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it, episode=40, norm_ret=-0.019, true_ret=-354951.938, steps=600]
Agent gate_2 episode reward: [-0.0175083]
All agents episode reward: [-0.0175083]
Agent gate_2 episode reward: [-0.01859835]
All agents episode reward: [-0.01859835]
Agent gate_2 episode reward: [-0.0181283]
All agents episode reward: [-0.0181283]
Agent gate_2 episode reward: [-0.01857261]
All agents episode reward: [-0.01857261]
Agent gate_2 episode reward: [-0.01868534]
All agents episode reward: [-0.01868534]
Agent gate_2 episode reward: [-0.0194201]
All agents episode reward: [-0.0194201]
Agent gate_2 episode reward: [-0.01931341]
All agents episode reward: [-0.01931341]
Agent gate_2 episode reward: [-0.02044141]
All agents episode reward: [-0.02044141]
Agent gate_2 episode reward: [-0.02057463]
All agents episode reward: [-0.02057463]
Agent gate_2 episode reward: [-0.02018285]
All agents episode reward: [-0.02018285]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it, episode=50, norm_ret=-0.022, true_ret=-369028.656, steps=600]
Agent gate_2 episode reward: [-0.02044332]
All agents episode reward: [-0.02044332]
Agent gate_2 episode reward: [-0.02054878]
All agents episode reward: [-0.02054878]
Agent gate_2 episode reward: [-0.02093884]
All agents episode reward: [-0.02093884]
Agent gate_2 episode reward: [-0.02187996]
All agents episode reward: [-0.02187996]
Agent gate_2 episode reward: [-0.02213662]
All agents episode reward: [-0.02213662]
Agent gate_2 episode reward: [-0.02161771]
All agents episode reward: [-0.02161771]
Agent gate_2 episode reward: [-0.0227784]
All agents episode reward: [-0.0227784]
Agent gate_2 episode reward: [-0.02214453]
All agents episode reward: [-0.02214453]
Agent gate_2 episode reward: [-0.02227978]
All agents episode reward: [-0.02227978]
Agent gate_2 episode reward: [-0.02351656]
All agents episode reward: [-0.02351656]
Iteration 5: 100%|██████████| 10/10 [00:27<00:00,  2.79s/it, episode=60, norm_ret=-0.024, true_ret=-355111.938, steps=600]
Agent gate_2 episode reward: [-0.0231011]
All agents episode reward: [-0.0231011]
Agent gate_2 episode reward: [-0.02306776]
All agents episode reward: [-0.02306776]
Agent gate_2 episode reward: [-0.02328421]
All agents episode reward: [-0.02328421]
Agent gate_2 episode reward: [-0.02335302]
All agents episode reward: [-0.02335302]
Agent gate_2 episode reward: [-0.02373098]
All agents episode reward: [-0.02373098]
Agent gate_2 episode reward: [-0.02377366]
All agents episode reward: [-0.02377366]
Agent gate_2 episode reward: [-0.02415809]
All agents episode reward: [-0.02415809]
Agent gate_2 episode reward: [-0.02437585]
All agents episode reward: [-0.02437585]
Agent gate_2 episode reward: [-0.02539682]
All agents episode reward: [-0.02539682]
Saved 1 agents to ppo_agents_butterfly_scA
[Validation] New best avg return: -352376.250 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scA)
Agent gate_2 episode reward: [-0.02481281]
All agents episode reward: [-0.02481281]
Iteration 6: 100%|██████████| 10/10 [00:26<00:00,  2.65s/it, episode=70, norm_ret=-0.027, true_ret=-366459.938, steps=600]
Agent gate_2 episode reward: [-0.0258506]
All agents episode reward: [-0.0258506]
Agent gate_2 episode reward: [-0.02611424]
All agents episode reward: [-0.02611424]
Agent gate_2 episode reward: [-0.02642723]
All agents episode reward: [-0.02642723]
Agent gate_2 episode reward: [-0.02768747]
All agents episode reward: [-0.02768747]
Agent gate_2 episode reward: [-0.02680988]
All agents episode reward: [-0.02680988]
Agent gate_2 episode reward: [-0.02701336]
All agents episode reward: [-0.02701336]
Agent gate_2 episode reward: [-0.02732591]
All agents episode reward: [-0.02732591]
Agent gate_2 episode reward: [-0.02720148]
All agents episode reward: [-0.02720148]
Agent gate_2 episode reward: [-0.02758323]
All agents episode reward: [-0.02758323]
Agent gate_2 episode reward: [-0.02867364]
All agents episode reward: [-0.02867364]
Iteration 7: 100%|██████████| 10/10 [00:26<00:00,  2.61s/it, episode=80, norm_ret=-0.030, true_ret=-361866.688, steps=600]
Agent gate_2 episode reward: [-0.02901123]
All agents episode reward: [-0.02901123]
Agent gate_2 episode reward: [-0.02884336]
All agents episode reward: [-0.02884336]
Agent gate_2 episode reward: [-0.02901006]
All agents episode reward: [-0.02901006]
Agent gate_2 episode reward: [-0.02997957]
All agents episode reward: [-0.02997957]
Agent gate_2 episode reward: [-0.03055758]
All agents episode reward: [-0.03055758]
Agent gate_2 episode reward: [-0.03093677]
All agents episode reward: [-0.03093677]
Agent gate_2 episode reward: [-0.03112609]
All agents episode reward: [-0.03112609]
Agent gate_2 episode reward: [-0.0302474]
All agents episode reward: [-0.0302474]
Agent gate_2 episode reward: [-0.03005443]
All agents episode reward: [-0.03005443]
Agent gate_2 episode reward: [-0.03104242]
All agents episode reward: [-0.03104242]
Iteration 8: 100%|██████████| 10/10 [00:26<00:00,  2.64s/it, episode=90, norm_ret=-0.032, true_ret=-354981.938, steps=600]
Agent gate_2 episode reward: [-0.0327131]
All agents episode reward: [-0.0327131]
Agent gate_2 episode reward: [-0.03140212]
All agents episode reward: [-0.03140212]
Agent gate_2 episode reward: [-0.03193609]
All agents episode reward: [-0.03193609]
Agent gate_2 episode reward: [-0.03111337]
All agents episode reward: [-0.03111337]
Agent gate_2 episode reward: [-0.03187925]
All agents episode reward: [-0.03187925]
Agent gate_2 episode reward: [-0.03354143]
All agents episode reward: [-0.03354143]
Agent gate_2 episode reward: [-0.03259321]
All agents episode reward: [-0.03259321]
Agent gate_2 episode reward: [-0.03258819]
All agents episode reward: [-0.03258819]
Agent gate_2 episode reward: [-0.03290292]
All agents episode reward: [-0.03290292]
Agent gate_2 episode reward: [-0.03290799]
All agents episode reward: [-0.03290799]
Iteration 9: 100%|██████████| 10/10 [00:25<00:00,  2.56s/it, episode=100, norm_ret=-0.035, true_ret=-366483.000, steps=600]
Agent gate_2 episode reward: [-0.03383371]
All agents episode reward: [-0.03383371]
Agent gate_2 episode reward: [-0.03374559]
All agents episode reward: [-0.03374559]
Agent gate_2 episode reward: [-0.03413727]
All agents episode reward: [-0.03413727]
Agent gate_2 episode reward: [-0.03404199]
All agents episode reward: [-0.03404199]
Agent gate_2 episode reward: [-0.0343562]
All agents episode reward: [-0.0343562]
Agent gate_2 episode reward: [-0.03572589]
All agents episode reward: [-0.03572589]
Agent gate_2 episode reward: [-0.03474826]
All agents episode reward: [-0.03474826]
Agent gate_2 episode reward: [-0.03465726]
All agents episode reward: [-0.03465726]
Agent gate_2 episode reward: [-0.03463999]
All agents episode reward: [-0.03463999]
Agent gate_2 episode reward: [-0.03634288]
All agents episode reward: [-0.03634288]
Loaded 1 agents from ppo_agents_butterfly_scA
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -352376.250 | Total reward: -352376.250
Saved run 1 to rl_training/butterfly_scA/ppo_run1
  Run 2/10... Avg agent reward (episode): -387243.500 | Total reward: -387243.500
Saved run 2 to rl_training/butterfly_scA/ppo_run2
  Run 3/10... Avg agent reward (episode): -379737.688 | Total reward: -379737.688
Saved run 3 to rl_training/butterfly_scA/ppo_run3
  Run 4/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 4 to rl_training/butterfly_scA/ppo_run4
  Run 5/10... Avg agent reward (episode): -347008.750 | Total reward: -347008.750
Saved run 5 to rl_training/butterfly_scA/ppo_run5
  Run 6/10... Avg agent reward (episode): -353969.406 | Total reward: -353969.406
Saved run 6 to rl_training/butterfly_scA/ppo_run6
  Run 7/10... Avg agent reward (episode): -170923.828 | Total reward: -170923.828
Saved run 7 to rl_training/butterfly_scA/ppo_run7
  Run 8/10... Avg agent reward (episode): -108525.141 | Total reward: -108525.141
Saved run 8 to rl_training/butterfly_scA/ppo_run8
  Run 9/10... Avg agent reward (episode): -372845.031 | Total reward: -372845.031
Saved run 9 to rl_training/butterfly_scA/ppo_run9
  Run 10/10... Avg agent reward (episode): -350632.500 | Total reward: -350632.500
Saved run 10 to rl_training/butterfly_scA/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -282326.188 ± 130347.617
  Average reward: -282326.188 ± 130347.617
  Total reward: -282326.188 ± 130347.617
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -352376.250 | Total reward: -352376.250
Saved run 1 to rl_training/butterfly_scA/rule_based_run1
  Run 2/10... Avg agent reward (episode): -387243.500 | Total reward: -387243.500
Saved run 2 to rl_training/butterfly_scA/rule_based_run2
  Run 3/10... Avg agent reward (episode): -379737.688 | Total reward: -379737.688
Saved run 3 to rl_training/butterfly_scA/rule_based_run3
  Run 4/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 4 to rl_training/butterfly_scA/rule_based_run4
  Run 5/10... Avg agent reward (episode): -347008.750 | Total reward: -347008.750
Saved run 5 to rl_training/butterfly_scA/rule_based_run5
  Run 6/10... Avg agent reward (episode): -353969.406 | Total reward: -353969.406
Saved run 6 to rl_training/butterfly_scA/rule_based_run6
  Run 7/10... Avg agent reward (episode): -170923.828 | Total reward: -170923.828
Saved run 7 to rl_training/butterfly_scA/rule_based_run7
  Run 8/10... Avg agent reward (episode): -108525.141 | Total reward: -108525.141
Saved run 8 to rl_training/butterfly_scA/rule_based_run8
  Run 9/10... Avg agent reward (episode): -372845.031 | Total reward: -372845.031
Saved run 9 to rl_training/butterfly_scA/rule_based_run9
  Run 10/10... Avg agent reward (episode): -350632.500 | Total reward: -350632.500
Saved run 10 to rl_training/butterfly_scA/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -282326.188 ± 130347.617
  Average reward: -282326.188 ± 130347.617
  Total reward: -282326.188 ± 130347.617
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -352376.250 | Total reward: -352376.250
Saved run 1 to rl_training/butterfly_scA/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -387243.500 | Total reward: -387243.500
Saved run 2 to rl_training/butterfly_scA/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -379737.688 | Total reward: -379737.688
Saved run 3 to rl_training/butterfly_scA/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 4 to rl_training/butterfly_scA/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -347008.750 | Total reward: -347008.750
Saved run 5 to rl_training/butterfly_scA/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -353969.406 | Total reward: -353969.406
Saved run 6 to rl_training/butterfly_scA/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -170923.828 | Total reward: -170923.828
Saved run 7 to rl_training/butterfly_scA/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -108525.141 | Total reward: -108525.141
Saved run 8 to rl_training/butterfly_scA/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -372845.031 | Total reward: -372845.031
Saved run 9 to rl_training/butterfly_scA/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -350632.500 | Total reward: -350632.500
Saved run 10 to rl_training/butterfly_scA/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -282326.188 ± 130347.617
  Average reward: -282326.188 ± 130347.617
  Total reward: -282326.188 ± 130347.617
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -282326.188
Rule-based avg reward: -282326.188
No control avg reward: -282326.188
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
