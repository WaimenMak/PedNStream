Iteration 0: 100%|██████████| 10/10 [00:19<00:00,  1.95s/it, episode=10, norm_ret=-12.154, true_ret=-167290848.000, steps=600]
Agent gate_2 episode reward: [-110.45005062]
All agents episode reward: [-110.45005062]
Agent gate_2 episode reward: [-8.70010951]
All agents episode reward: [-8.70010951]
Agent gate_2 episode reward: [-0.60772112]
All agents episode reward: [-0.60772112]
Agent gate_2 episode reward: [-0.67131287]
All agents episode reward: [-0.67131287]
Agent gate_2 episode reward: [-0.14203738]
All agents episode reward: [-0.14203738]
Agent gate_2 episode reward: [-0.13745095]
All agents episode reward: [-0.13745095]
Agent gate_2 episode reward: [-0.19616038]
All agents episode reward: [-0.19616038]
Agent gate_2 episode reward: [-0.19517975]
All agents episode reward: [-0.19517975]
Agent gate_2 episode reward: [-0.18295447]
All agents episode reward: [-0.18295447]
Agent gate_2 episode reward: [-0.25636328]
All agents episode reward: [-0.25636328]
Iteration 1: 100%|██████████| 10/10 [00:20<00:00,  2.06s/it, episode=20, norm_ret=-0.276, true_ret=-145575520.000, steps=600]
Agent gate_2 episode reward: [-0.24311878]
All agents episode reward: [-0.24311878]
Agent gate_2 episode reward: [-0.25192378]
All agents episode reward: [-0.25192378]
Agent gate_2 episode reward: [-0.2545433]
All agents episode reward: [-0.2545433]
Agent gate_2 episode reward: [-0.26079023]
All agents episode reward: [-0.26079023]
Agent gate_2 episode reward: [-0.30753006]
All agents episode reward: [-0.30753006]
Agent gate_2 episode reward: [-0.22980744]
All agents episode reward: [-0.22980744]
Agent gate_2 episode reward: [-0.29217333]
All agents episode reward: [-0.29217333]
Agent gate_2 episode reward: [-0.305026]
All agents episode reward: [-0.305026]
Agent gate_2 episode reward: [-0.31026445]
All agents episode reward: [-0.31026445]
Agent gate_2 episode reward: [-0.30645269]
All agents episode reward: [-0.30645269]
Iteration 2: 100%|██████████| 10/10 [00:19<00:00,  1.97s/it, episode=30, norm_ret=-0.354, true_ret=-143013456.000, steps=600]
Agent gate_2 episode reward: [-0.32001729]
All agents episode reward: [-0.32001729]
Agent gate_2 episode reward: [-0.32891687]
All agents episode reward: [-0.32891687]
Agent gate_2 episode reward: [-0.34869956]
All agents episode reward: [-0.34869956]
Agent gate_2 episode reward: [-0.36014356]
All agents episode reward: [-0.36014356]
Agent gate_2 episode reward: [-0.33341029]
All agents episode reward: [-0.33341029]
Agent gate_2 episode reward: [-0.34922832]
All agents episode reward: [-0.34922832]
Agent gate_2 episode reward: [-0.38890446]
All agents episode reward: [-0.38890446]
Agent gate_2 episode reward: [-0.35355274]
All agents episode reward: [-0.35355274]
Agent gate_2 episode reward: [-0.38976588]
All agents episode reward: [-0.38976588]
Agent gate_2 episode reward: [-0.36561678]
All agents episode reward: [-0.36561678]
Iteration 3: 100%|██████████| 10/10 [00:19<00:00,  1.99s/it, episode=40, norm_ret=-0.415, true_ret=-152795792.000, steps=600]
Agent gate_2 episode reward: [-0.38457619]
All agents episode reward: [-0.38457619]
Agent gate_2 episode reward: [-0.42462606]
All agents episode reward: [-0.42462606]
Agent gate_2 episode reward: [-0.40401428]
All agents episode reward: [-0.40401428]
Agent gate_2 episode reward: [-0.40180334]
All agents episode reward: [-0.40180334]
Agent gate_2 episode reward: [-0.41256269]
All agents episode reward: [-0.41256269]
Agent gate_2 episode reward: [-0.35585095]
All agents episode reward: [-0.35585095]
Agent gate_2 episode reward: [-0.43539289]
All agents episode reward: [-0.43539289]
Agent gate_2 episode reward: [-0.43583919]
All agents episode reward: [-0.43583919]
Agent gate_2 episode reward: [-0.44394168]
All agents episode reward: [-0.44394168]
Agent gate_2 episode reward: [-0.44895124]
All agents episode reward: [-0.44895124]
Iteration 4: 100%|██████████| 10/10 [00:21<00:00,  2.11s/it, episode=50, norm_ret=-0.482, true_ret=-149221600.000, steps=600]
Agent gate_2 episode reward: [-0.44611319]
All agents episode reward: [-0.44611319]
Agent gate_2 episode reward: [-0.46660451]
All agents episode reward: [-0.46660451]
Agent gate_2 episode reward: [-0.46133571]
All agents episode reward: [-0.46133571]
Agent gate_2 episode reward: [-0.47705356]
All agents episode reward: [-0.47705356]
Agent gate_2 episode reward: [-0.47354941]
All agents episode reward: [-0.47354941]
Agent gate_2 episode reward: [-0.48511017]
All agents episode reward: [-0.48511017]
Agent gate_2 episode reward: [-0.4939018]
All agents episode reward: [-0.4939018]
Agent gate_2 episode reward: [-0.4878625]
All agents episode reward: [-0.4878625]
Agent gate_2 episode reward: [-0.54109222]
All agents episode reward: [-0.54109222]
Agent gate_2 episode reward: [-0.4889527]
All agents episode reward: [-0.4889527]
Iteration 5: 100%|██████████| 10/10 [00:24<00:00,  2.49s/it, episode=60, norm_ret=-0.530, true_ret=-148899936.000, steps=600]
Agent gate_2 episode reward: [-0.49997669]
All agents episode reward: [-0.49997669]
Agent gate_2 episode reward: [-0.51646951]
All agents episode reward: [-0.51646951]
Agent gate_2 episode reward: [-0.52968062]
All agents episode reward: [-0.52968062]
Agent gate_2 episode reward: [-0.55059496]
All agents episode reward: [-0.55059496]
Agent gate_2 episode reward: [-0.52279487]
All agents episode reward: [-0.52279487]
Agent gate_2 episode reward: [-0.53825643]
All agents episode reward: [-0.53825643]
Agent gate_2 episode reward: [-0.52438431]
All agents episode reward: [-0.52438431]
Agent gate_2 episode reward: [-0.545461]
All agents episode reward: [-0.545461]
Agent gate_2 episode reward: [-0.53785471]
All agents episode reward: [-0.53785471]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -151503808.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.5335018]
All agents episode reward: [-0.5335018]
Iteration 6: 100%|██████████| 10/10 [00:25<00:00,  2.51s/it, episode=70, norm_ret=-0.591, true_ret=-152362528.000, steps=600]
Agent gate_2 episode reward: [-0.57122868]
All agents episode reward: [-0.57122868]
Agent gate_2 episode reward: [-0.56092805]
All agents episode reward: [-0.56092805]
Agent gate_2 episode reward: [-0.59003359]
All agents episode reward: [-0.59003359]
Agent gate_2 episode reward: [-0.5972093]
All agents episode reward: [-0.5972093]
Agent gate_2 episode reward: [-0.60929179]
All agents episode reward: [-0.60929179]
Agent gate_2 episode reward: [-0.59924557]
All agents episode reward: [-0.59924557]
Agent gate_2 episode reward: [-0.57294188]
All agents episode reward: [-0.57294188]
Agent gate_2 episode reward: [-0.59624497]
All agents episode reward: [-0.59624497]
Agent gate_2 episode reward: [-0.60056754]
All agents episode reward: [-0.60056754]
Agent gate_2 episode reward: [-0.60919039]
All agents episode reward: [-0.60919039]
Iteration 7: 100%|██████████| 10/10 [00:25<00:00,  2.58s/it, episode=80, norm_ret=-0.646, true_ret=-151632768.000, steps=600]
Agent gate_2 episode reward: [-0.65923446]
All agents episode reward: [-0.65923446]
Agent gate_2 episode reward: [-0.6195129]
All agents episode reward: [-0.6195129]
Agent gate_2 episode reward: [-0.64324492]
All agents episode reward: [-0.64324492]
Agent gate_2 episode reward: [-0.63390869]
All agents episode reward: [-0.63390869]
Agent gate_2 episode reward: [-0.64871949]
All agents episode reward: [-0.64871949]
Agent gate_2 episode reward: [-0.63931923]
All agents episode reward: [-0.63931923]
Agent gate_2 episode reward: [-0.65229186]
All agents episode reward: [-0.65229186]
Agent gate_2 episode reward: [-0.64830034]
All agents episode reward: [-0.64830034]
Agent gate_2 episode reward: [-0.65159418]
All agents episode reward: [-0.65159418]
Agent gate_2 episode reward: [-0.66320804]
All agents episode reward: [-0.66320804]
Iteration 8: 100%|██████████| 10/10 [00:25<00:00,  2.52s/it, episode=90, norm_ret=-0.695, true_ret=-149775824.000, steps=600]
Agent gate_2 episode reward: [-0.67898908]
All agents episode reward: [-0.67898908]
Agent gate_2 episode reward: [-0.68659852]
All agents episode reward: [-0.68659852]
Agent gate_2 episode reward: [-0.68260634]
All agents episode reward: [-0.68260634]
Agent gate_2 episode reward: [-0.6965477]
All agents episode reward: [-0.6965477]
Agent gate_2 episode reward: [-0.68172604]
All agents episode reward: [-0.68172604]
Agent gate_2 episode reward: [-0.69306939]
All agents episode reward: [-0.69306939]
Agent gate_2 episode reward: [-0.71644741]
All agents episode reward: [-0.71644741]
Agent gate_2 episode reward: [-0.69980905]
All agents episode reward: [-0.69980905]
Agent gate_2 episode reward: [-0.70314878]
All agents episode reward: [-0.70314878]
Agent gate_2 episode reward: [-0.70679169]
All agents episode reward: [-0.70679169]
Iteration 9: 100%|██████████| 10/10 [00:25<00:00,  2.50s/it, episode=100, norm_ret=-0.740, true_ret=-149708240.000, steps=600]
Agent gate_2 episode reward: [-0.72636134]
All agents episode reward: [-0.72636134]
Agent gate_2 episode reward: [-0.72931161]
All agents episode reward: [-0.72931161]
Agent gate_2 episode reward: [-0.73251398]
All agents episode reward: [-0.73251398]
Agent gate_2 episode reward: [-0.73569935]
All agents episode reward: [-0.73569935]
Agent gate_2 episode reward: [-0.73887613]
All agents episode reward: [-0.73887613]
Agent gate_2 episode reward: [-0.74203628]
All agents episode reward: [-0.74203628]
Agent gate_2 episode reward: [-0.74518271]
All agents episode reward: [-0.74518271]
Agent gate_2 episode reward: [-0.7483156]
All agents episode reward: [-0.7483156]
Agent gate_2 episode reward: [-0.75143511]
All agents episode reward: [-0.75143511]
Agent gate_2 episode reward: [-0.75454141]
All agents episode reward: [-0.75454141]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -151503808.000 | Total reward: -151503808.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -279867200.000 | Total reward: -279867200.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -231715536.000 | Total reward: -231715536.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -365330976.000 | Total reward: -365330976.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -331542272.000 | Total reward: -331542272.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -273393568.000 | Total reward: -273393568.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -295271808.000 | Total reward: -295271808.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -238991392.000 | Total reward: -238991392.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -317697440.000 | Total reward: -317697440.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -174570816.000 | Total reward: -174570816.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -265988480.000 ± 64274740.000
  Average reward: -265988480.000 ± 64274740.000
  Total reward: -265988480.000 ± 64274740.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -151503808.000 | Total reward: -151503808.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -279867200.000 | Total reward: -279867200.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -231715536.000 | Total reward: -231715536.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -365330976.000 | Total reward: -365330976.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -331542272.000 | Total reward: -331542272.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -273393568.000 | Total reward: -273393568.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -295271808.000 | Total reward: -295271808.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -238991392.000 | Total reward: -238991392.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -317697440.000 | Total reward: -317697440.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -174570816.000 | Total reward: -174570816.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -265988480.000 ± 64274740.000
  Average reward: -265988480.000 ± 64274740.000
  Total reward: -265988480.000 ± 64274740.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -151503808.000 | Total reward: -151503808.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -279867200.000 | Total reward: -279867200.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -231715536.000 | Total reward: -231715536.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -365330976.000 | Total reward: -365330976.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -331542272.000 | Total reward: -331542272.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -273393568.000 | Total reward: -273393568.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -295271808.000 | Total reward: -295271808.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -238991392.000 | Total reward: -238991392.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -317697440.000 | Total reward: -317697440.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -174570816.000 | Total reward: -174570816.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -265988480.000 ± 64274740.000
  Average reward: -265988480.000 ± 64274740.000
  Total reward: -265988480.000 ± 64274740.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -265988480.000
Rule-based avg reward: -265988480.000
No control avg reward: -265988480.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
