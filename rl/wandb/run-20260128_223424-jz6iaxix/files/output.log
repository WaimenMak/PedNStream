Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=10, norm_ret=-8.777, true_ret=-381092352.000, steps=600]
Agent gate_2 episode reward: [-76.18810333]
All agents episode reward: [-76.18810333]
Agent gate_2 episode reward: [-7.81159945]
All agents episode reward: [-7.81159945]
Agent gate_2 episode reward: [-1.09088509]
All agents episode reward: [-1.09088509]
Agent gate_2 episode reward: [-0.67120658]
All agents episode reward: [-0.67120658]
Agent gate_2 episode reward: [-0.36527569]
All agents episode reward: [-0.36527569]
Agent gate_2 episode reward: [-0.26292018]
All agents episode reward: [-0.26292018]
Agent gate_2 episode reward: [-0.31266042]
All agents episode reward: [-0.31266042]
Agent gate_2 episode reward: [-0.31149733]
All agents episode reward: [-0.31149733]
Agent gate_2 episode reward: [-0.30715916]
All agents episode reward: [-0.30715916]
Agent gate_2 episode reward: [-0.44694643]
All agents episode reward: [-0.44694643]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.29s/it, episode=20, norm_ret=-0.455, true_ret=-307755776.000, steps=600]
Agent gate_2 episode reward: [-0.38853737]
All agents episode reward: [-0.38853737]
Agent gate_2 episode reward: [-0.36368004]
All agents episode reward: [-0.36368004]
Agent gate_2 episode reward: [-0.72535993]
All agents episode reward: [-0.72535993]
Agent gate_2 episode reward: [-0.39097695]
All agents episode reward: [-0.39097695]
Agent gate_2 episode reward: [-0.41519822]
All agents episode reward: [-0.41519822]
Agent gate_2 episode reward: [-0.3672416]
All agents episode reward: [-0.3672416]
Agent gate_2 episode reward: [-0.44034323]
All agents episode reward: [-0.44034323]
Agent gate_2 episode reward: [-0.43887542]
All agents episode reward: [-0.43887542]
Agent gate_2 episode reward: [-0.52280366]
All agents episode reward: [-0.52280366]
Agent gate_2 episode reward: [-0.49608915]
All agents episode reward: [-0.49608915]
Iteration 2: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=30, norm_ret=-0.540, true_ret=-290033312.000, steps=600]
Agent gate_2 episode reward: [-0.4716453]
All agents episode reward: [-0.4716453]
Agent gate_2 episode reward: [-0.5249127]
All agents episode reward: [-0.5249127]
Agent gate_2 episode reward: [-0.54797236]
All agents episode reward: [-0.54797236]
Agent gate_2 episode reward: [-0.52819539]
All agents episode reward: [-0.52819539]
Agent gate_2 episode reward: [-0.5122252]
All agents episode reward: [-0.5122252]
Agent gate_2 episode reward: [-0.55839363]
All agents episode reward: [-0.55839363]
Agent gate_2 episode reward: [-0.53706569]
All agents episode reward: [-0.53706569]
Agent gate_2 episode reward: [-0.59765132]
All agents episode reward: [-0.59765132]
Agent gate_2 episode reward: [-0.55926104]
All agents episode reward: [-0.55926104]
Agent gate_2 episode reward: [-0.5661782]
All agents episode reward: [-0.5661782]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.24s/it, episode=40, norm_ret=-0.606, true_ret=-270444512.000, steps=600]
Agent gate_2 episode reward: [-0.5890987]
All agents episode reward: [-0.5890987]
Agent gate_2 episode reward: [-0.57076827]
All agents episode reward: [-0.57076827]
Agent gate_2 episode reward: [-0.66183061]
All agents episode reward: [-0.66183061]
Agent gate_2 episode reward: [-0.59960689]
All agents episode reward: [-0.59960689]
Agent gate_2 episode reward: [-0.61370282]
All agents episode reward: [-0.61370282]
Agent gate_2 episode reward: [-0.64717629]
All agents episode reward: [-0.64717629]
Agent gate_2 episode reward: [-0.60921694]
All agents episode reward: [-0.60921694]
Agent gate_2 episode reward: [-0.59515129]
All agents episode reward: [-0.59515129]
Agent gate_2 episode reward: [-0.56481805]
All agents episode reward: [-0.56481805]
Agent gate_2 episode reward: [-0.60619573]
All agents episode reward: [-0.60619573]
Iteration 4: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it, episode=50, norm_ret=-0.678, true_ret=-279670848.000, steps=600]
Agent gate_2 episode reward: [-0.68243779]
All agents episode reward: [-0.68243779]
Agent gate_2 episode reward: [-0.68215734]
All agents episode reward: [-0.68215734]
Agent gate_2 episode reward: [-0.66886291]
All agents episode reward: [-0.66886291]
Agent gate_2 episode reward: [-0.66835673]
All agents episode reward: [-0.66835673]
Agent gate_2 episode reward: [-0.66478468]
All agents episode reward: [-0.66478468]
Agent gate_2 episode reward: [-0.69354109]
All agents episode reward: [-0.69354109]
Agent gate_2 episode reward: [-0.66826906]
All agents episode reward: [-0.66826906]
Agent gate_2 episode reward: [-0.71650364]
All agents episode reward: [-0.71650364]
Agent gate_2 episode reward: [-0.64038468]
All agents episode reward: [-0.64038468]
Agent gate_2 episode reward: [-0.69837728]
All agents episode reward: [-0.69837728]
Iteration 5: 100%|██████████| 10/10 [00:28<00:00,  2.83s/it, episode=60, norm_ret=-0.736, true_ret=-295795040.000, steps=600]
Agent gate_2 episode reward: [-0.70130679]
All agents episode reward: [-0.70130679]
Agent gate_2 episode reward: [-0.7846169]
All agents episode reward: [-0.7846169]
Agent gate_2 episode reward: [-0.58732118]
All agents episode reward: [-0.58732118]
Agent gate_2 episode reward: [-0.73962871]
All agents episode reward: [-0.73962871]
Agent gate_2 episode reward: [-0.68087282]
All agents episode reward: [-0.68087282]
Agent gate_2 episode reward: [-0.76716683]
All agents episode reward: [-0.76716683]
Agent gate_2 episode reward: [-0.76672699]
All agents episode reward: [-0.76672699]
Agent gate_2 episode reward: [-0.76307727]
All agents episode reward: [-0.76307727]
Agent gate_2 episode reward: [-0.75964867]
All agents episode reward: [-0.75964867]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -768431360.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.80703441]
All agents episode reward: [-0.80703441]
Iteration 6: 100%|██████████| 10/10 [00:28<00:00,  2.85s/it, episode=70, norm_ret=-0.797, true_ret=-303477472.000, steps=600]
Agent gate_2 episode reward: [-0.63209168]
All agents episode reward: [-0.63209168]
Agent gate_2 episode reward: [-0.6646468]
All agents episode reward: [-0.6646468]
Agent gate_2 episode reward: [-0.88789584]
All agents episode reward: [-0.88789584]
Agent gate_2 episode reward: [-0.77590386]
All agents episode reward: [-0.77590386]
Agent gate_2 episode reward: [-0.81504209]
All agents episode reward: [-0.81504209]
Agent gate_2 episode reward: [-0.7087796]
All agents episode reward: [-0.7087796]
Agent gate_2 episode reward: [-0.73180294]
All agents episode reward: [-0.73180294]
Agent gate_2 episode reward: [-0.91686262]
All agents episode reward: [-0.91686262]
Agent gate_2 episode reward: [-0.91044829]
All agents episode reward: [-0.91044829]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -248557472.000 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.92281064]
All agents episode reward: [-0.92281064]
Iteration 7: 100%|██████████| 10/10 [00:28<00:00,  2.84s/it, episode=80, norm_ret=-0.886, true_ret=-283892416.000, steps=600]
Agent gate_2 episode reward: [-0.92676052]
All agents episode reward: [-0.92676052]
Agent gate_2 episode reward: [-0.8873898]
All agents episode reward: [-0.8873898]
Agent gate_2 episode reward: [-0.8002572]
All agents episode reward: [-0.8002572]
Agent gate_2 episode reward: [-0.81586655]
All agents episode reward: [-0.81586655]
Agent gate_2 episode reward: [-0.80150032]
All agents episode reward: [-0.80150032]
Agent gate_2 episode reward: [-0.92382958]
All agents episode reward: [-0.92382958]
Agent gate_2 episode reward: [-0.8313276]
All agents episode reward: [-0.8313276]
Agent gate_2 episode reward: [-0.91977237]
All agents episode reward: [-0.91977237]
Agent gate_2 episode reward: [-1.01416659]
All agents episode reward: [-1.01416659]
Agent gate_2 episode reward: [-0.94331032]
All agents episode reward: [-0.94331032]
Iteration 8: 100%|██████████| 10/10 [00:29<00:00,  2.92s/it, episode=90, norm_ret=-1.013, true_ret=-298781792.000, steps=600]
Agent gate_2 episode reward: [-0.99557131]
All agents episode reward: [-0.99557131]
Agent gate_2 episode reward: [-1.02024874]
All agents episode reward: [-1.02024874]
Agent gate_2 episode reward: [-1.02314209]
All agents episode reward: [-1.02314209]
Agent gate_2 episode reward: [-1.01243194]
All agents episode reward: [-1.01243194]
Agent gate_2 episode reward: [-1.01784826]
All agents episode reward: [-1.01784826]
Agent gate_2 episode reward: [-0.94674997]
All agents episode reward: [-0.94674997]
Agent gate_2 episode reward: [-1.03149534]
All agents episode reward: [-1.03149534]
Agent gate_2 episode reward: [-1.00270749]
All agents episode reward: [-1.00270749]
Agent gate_2 episode reward: [-1.00577571]
All agents episode reward: [-1.00577571]
Agent gate_2 episode reward: [-1.07042064]
All agents episode reward: [-1.07042064]
Iteration 9: 100%|██████████| 10/10 [00:29<00:00,  2.92s/it, episode=100, norm_ret=-0.945, true_ret=-231520592.000, steps=600]
Agent gate_2 episode reward: [-1.00278062]
All agents episode reward: [-1.00278062]
Agent gate_2 episode reward: [-0.93951802]
All agents episode reward: [-0.93951802]
Agent gate_2 episode reward: [-0.92859472]
All agents episode reward: [-0.92859472]
Agent gate_2 episode reward: [-0.98024937]
All agents episode reward: [-0.98024937]
Agent gate_2 episode reward: [-0.84137241]
All agents episode reward: [-0.84137241]
Agent gate_2 episode reward: [-0.99465497]
All agents episode reward: [-0.99465497]
Agent gate_2 episode reward: [-0.88575575]
All agents episode reward: [-0.88575575]
Agent gate_2 episode reward: [-0.9102683]
All agents episode reward: [-0.9102683]
Agent gate_2 episode reward: [-1.0835624]
All agents episode reward: [-1.0835624]
Agent gate_2 episode reward: [-0.88537994]
All agents episode reward: [-0.88537994]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -147638832.000 | Total reward: -147638832.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -203143968.000 | Total reward: -203143968.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -229930144.000 | Total reward: -229930144.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -286239776.000 | Total reward: -286239776.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -229581152.000 | Total reward: -229581152.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -276057120.000 | Total reward: -276057120.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -208892912.000 | Total reward: -208892912.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -191429904.000 | Total reward: -191429904.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -267351424.000 | Total reward: -267351424.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -174552288.000 | Total reward: -174552288.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -221481760.000 ± 42972192.000
  Average reward: -221481760.000 ± 42972192.000
  Total reward: -221481760.000 ± 42972192.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -151503808.000 | Total reward: -151503808.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -279867200.000 | Total reward: -279867200.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -231715536.000 | Total reward: -231715536.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -365330976.000 | Total reward: -365330976.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -331542272.000 | Total reward: -331542272.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -273393568.000 | Total reward: -273393568.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -295271808.000 | Total reward: -295271808.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -238991392.000 | Total reward: -238991392.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -317697440.000 | Total reward: -317697440.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -174570816.000 | Total reward: -174570816.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -265988480.000 ± 64274740.000
  Average reward: -265988480.000 ± 64274740.000
  Total reward: -265988480.000 ± 64274740.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -151503808.000 | Total reward: -151503808.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -279867200.000 | Total reward: -279867200.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -231715536.000 | Total reward: -231715536.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -365330976.000 | Total reward: -365330976.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -331542272.000 | Total reward: -331542272.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -273393568.000 | Total reward: -273393568.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -295271808.000 | Total reward: -295271808.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -238991392.000 | Total reward: -238991392.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -317697440.000 | Total reward: -317697440.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -174570816.000 | Total reward: -174570816.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -265988480.000 ± 64274740.000
  Average reward: -265988480.000 ± 64274740.000
  Total reward: -265988480.000 ± 64274740.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -221481760.000
Rule-based avg reward: -265988480.000
No control avg reward: -265988480.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
