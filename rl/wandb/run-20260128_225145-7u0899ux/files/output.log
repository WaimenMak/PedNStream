Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it, episode=10, norm_ret=-17.127, true_ret=-220544000.000, steps=600]
Agent gate_2 episode reward: [-90.68385611]
All agents episode reward: [-90.68385611]
Agent gate_2 episode reward: [-16.13545723]
All agents episode reward: [-16.13545723]
Agent gate_2 episode reward: [-7.35063934]
All agents episode reward: [-7.35063934]
Agent gate_2 episode reward: [-13.45898609]
All agents episode reward: [-13.45898609]
Agent gate_2 episode reward: [-12.01187956]
All agents episode reward: [-12.01187956]
Agent gate_2 episode reward: [-6.31379939]
All agents episode reward: [-6.31379939]
Agent gate_2 episode reward: [-7.41453269]
All agents episode reward: [-7.41453269]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-11.48945672]
All agents episode reward: [-11.48945672]
Agent gate_2 episode reward: [-6.41493878]
All agents episode reward: [-6.41493878]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=20, norm_ret=-9.813, true_ret=-205887488.000, steps=600]
Agent gate_2 episode reward: [-11.20723211]
All agents episode reward: [-11.20723211]
Agent gate_2 episode reward: [-4.83220646]
All agents episode reward: [-4.83220646]
Agent gate_2 episode reward: [-13.16925435]
All agents episode reward: [-13.16925435]
Agent gate_2 episode reward: [-14.95727948]
All agents episode reward: [-14.95727948]
Agent gate_2 episode reward: [-9.28856447]
All agents episode reward: [-9.28856447]
Agent gate_2 episode reward: [-13.94688078]
All agents episode reward: [-13.94688078]
Agent gate_2 episode reward: [-20.99374724]
All agents episode reward: [-20.99374724]
Agent gate_2 episode reward: [-5.28762746]
All agents episode reward: [-5.28762746]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-4.44993477]
All agents episode reward: [-4.44993477]
Iteration 2: 100%|██████████| 10/10 [00:22<00:00,  2.22s/it, episode=30, norm_ret=-8.674, true_ret=-535192480.000, steps=600]
Agent gate_2 episode reward: [-6.29836963]
All agents episode reward: [-6.29836963]
Agent gate_2 episode reward: [-4.14350661]
All agents episode reward: [-4.14350661]
Agent gate_2 episode reward: [-9.0318936]
All agents episode reward: [-9.0318936]
Agent gate_2 episode reward: [-6.48066472]
All agents episode reward: [-6.48066472]
Agent gate_2 episode reward: [-10.85324732]
All agents episode reward: [-10.85324732]
Agent gate_2 episode reward: [-8.55412725]
All agents episode reward: [-8.55412725]
Agent gate_2 episode reward: [-11.25700683]
All agents episode reward: [-11.25700683]
Agent gate_2 episode reward: [-10.55265843]
All agents episode reward: [-10.55265843]
Agent gate_2 episode reward: [-7.09841489]
All agents episode reward: [-7.09841489]
Agent gate_2 episode reward: [-12.47289475]
All agents episode reward: [-12.47289475]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.22s/it, episode=40, norm_ret=-9.211, true_ret=-348448416.000, steps=600]
Agent gate_2 episode reward: [-10.60518937]
All agents episode reward: [-10.60518937]
Agent gate_2 episode reward: [-4.53325216]
All agents episode reward: [-4.53325216]
Agent gate_2 episode reward: [-6.88935563]
All agents episode reward: [-6.88935563]
Agent gate_2 episode reward: [-7.56516273]
All agents episode reward: [-7.56516273]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-5.53621856]
All agents episode reward: [-5.53621856]
Agent gate_2 episode reward: [-14.50889746]
All agents episode reward: [-14.50889746]
Agent gate_2 episode reward: [-29.54186893]
All agents episode reward: [-29.54186893]
Agent gate_2 episode reward: [-7.29954827]
All agents episode reward: [-7.29954827]
Agent gate_2 episode reward: [-5.62605166]
All agents episode reward: [-5.62605166]
Iteration 4: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it, episode=50, norm_ret=-6.389, true_ret=-1262495744.000, steps=600]
Agent gate_2 episode reward: [-4.27692445]
All agents episode reward: [-4.27692445]
Agent gate_2 episode reward: [-5.19292795]
All agents episode reward: [-5.19292795]
Agent gate_2 episode reward: [-3.12956645]
All agents episode reward: [-3.12956645]
Agent gate_2 episode reward: [-5.67676431]
All agents episode reward: [-5.67676431]
Agent gate_2 episode reward: [-3.12548263]
All agents episode reward: [-3.12548263]
Agent gate_2 episode reward: [-4.47580269]
All agents episode reward: [-4.47580269]
Agent gate_2 episode reward: [-6.24138693]
All agents episode reward: [-6.24138693]
Agent gate_2 episode reward: [-2.77910698]
All agents episode reward: [-2.77910698]
Agent gate_2 episode reward: [-7.15227188]
All agents episode reward: [-7.15227188]
Agent gate_2 episode reward: [-21.84057366]
All agents episode reward: [-21.84057366]
Iteration 5: 100%|██████████| 10/10 [00:28<00:00,  2.86s/it, episode=60, norm_ret=-5.349, true_ret=-172758864.000, steps=600]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-7.11574675]
All agents episode reward: [-7.11574675]
Agent gate_2 episode reward: [-8.39465525]
All agents episode reward: [-8.39465525]
Agent gate_2 episode reward: [-5.36151163]
All agents episode reward: [-5.36151163]
Agent gate_2 episode reward: [-7.25128121]
All agents episode reward: [-7.25128121]
Agent gate_2 episode reward: [-7.29835559]
All agents episode reward: [-7.29835559]
Agent gate_2 episode reward: [-4.12320163]
All agents episode reward: [-4.12320163]
Agent gate_2 episode reward: [-6.53351196]
All agents episode reward: [-6.53351196]
Agent gate_2 episode reward: [-4.51920087]
All agents episode reward: [-4.51920087]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -300650464.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.88868244]
All agents episode reward: [-2.88868244]
Iteration 6: 100%|██████████| 10/10 [00:29<00:00,  2.92s/it, episode=70, norm_ret=-5.608, true_ret=-377053888.000, steps=600]
Agent gate_2 episode reward: [-8.20996027]
All agents episode reward: [-8.20996027]
Agent gate_2 episode reward: [-4.83067194]
All agents episode reward: [-4.83067194]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-1.99130229]
All agents episode reward: [-1.99130229]
Agent gate_2 episode reward: [-6.25344351]
All agents episode reward: [-6.25344351]
Agent gate_2 episode reward: [-6.41350619]
All agents episode reward: [-6.41350619]
Agent gate_2 episode reward: [-7.7672422]
All agents episode reward: [-7.7672422]
Agent gate_2 episode reward: [-6.43912688]
All agents episode reward: [-6.43912688]
Agent gate_2 episode reward: [-7.43241368]
All agents episode reward: [-7.43241368]
Agent gate_2 episode reward: [-6.74648694]
All agents episode reward: [-6.74648694]
Iteration 7: 100%|██████████| 10/10 [00:28<00:00,  2.81s/it, episode=80, norm_ret=-7.304, true_ret=-332565824.000, steps=600]
Agent gate_2 episode reward: [-10.66638196]
All agents episode reward: [-10.66638196]
Agent gate_2 episode reward: [-5.89427812]
All agents episode reward: [-5.89427812]
Agent gate_2 episode reward: [-4.07793704]
All agents episode reward: [-4.07793704]
Agent gate_2 episode reward: [-6.33492782]
All agents episode reward: [-6.33492782]
Agent gate_2 episode reward: [-8.87045646]
All agents episode reward: [-8.87045646]
Agent gate_2 episode reward: [-9.06413576]
All agents episode reward: [-9.06413576]
Agent gate_2 episode reward: [-8.242445]
All agents episode reward: [-8.242445]
Agent gate_2 episode reward: [-5.33028213]
All agents episode reward: [-5.33028213]
Agent gate_2 episode reward: [-8.3271387]
All agents episode reward: [-8.3271387]
Agent gate_2 episode reward: [-6.23310051]
All agents episode reward: [-6.23310051]
Iteration 8: 100%|██████████| 10/10 [00:28<00:00,  2.82s/it, episode=90, norm_ret=-5.568, true_ret=-174770912.000, steps=600]
Agent gate_2 episode reward: [-4.27168415]
All agents episode reward: [-4.27168415]
Agent gate_2 episode reward: [-8.61690262]
All agents episode reward: [-8.61690262]
Agent gate_2 episode reward: [-4.19239372]
All agents episode reward: [-4.19239372]
Agent gate_2 episode reward: [-6.31687659]
All agents episode reward: [-6.31687659]
Agent gate_2 episode reward: [-4.30889925]
All agents episode reward: [-4.30889925]
Agent gate_2 episode reward: [-5.44424412]
All agents episode reward: [-5.44424412]
Agent gate_2 episode reward: [-5.17579125]
All agents episode reward: [-5.17579125]
Agent gate_2 episode reward: [-6.4906198]
All agents episode reward: [-6.4906198]
Agent gate_2 episode reward: [-7.45162799]
All agents episode reward: [-7.45162799]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -233572832.000 at episode 90 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-3.41299114]
All agents episode reward: [-3.41299114]
Iteration 9: 100%|██████████| 10/10 [00:27<00:00,  2.75s/it, episode=100, norm_ret=-5.294, true_ret=-291180544.000, steps=600]
Agent gate_2 episode reward: [-5.66414658]
All agents episode reward: [-5.66414658]
Agent gate_2 episode reward: [-3.80862729]
All agents episode reward: [-3.80862729]
Agent gate_2 episode reward: [-8.49161143]
All agents episode reward: [-8.49161143]
Agent gate_2 episode reward: [-5.96355724]
All agents episode reward: [-5.96355724]
Agent gate_2 episode reward: [-4.6837133]
All agents episode reward: [-4.6837133]
Agent gate_2 episode reward: [-7.43775112]
All agents episode reward: [-7.43775112]
Agent gate_2 episode reward: [-3.96087462]
All agents episode reward: [-3.96087462]
Agent gate_2 episode reward: [-3.98354637]
All agents episode reward: [-3.98354637]
Agent gate_2 episode reward: [-3.02316324]
All agents episode reward: [-3.02316324]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -157414144.000 at episode 100 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-5.92362809]
All agents episode reward: [-5.92362809]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -293524576.000 | Total reward: -293524576.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -447407616.000 | Total reward: -447407616.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -2366724.750 | Total reward: -2366724.750
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -472131552.000 | Total reward: -472131552.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -407322400.000 | Total reward: -407322400.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -77286696.000 | Total reward: -77286696.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -204496800.000 | Total reward: -204496800.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -66623696.000 | Total reward: -66623696.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -251488432.000 | Total reward: -251488432.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -355641824.000 | Total reward: -355641824.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -257829040.000 ± 158857136.000
  Average reward: -257829040.000 ± 158857136.000
  Total reward: -257829040.000 ± 158857136.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -293524576.000 | Total reward: -293524576.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -447407616.000 | Total reward: -447407616.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -2366724.750 | Total reward: -2366724.750
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -472131552.000 | Total reward: -472131552.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -407322400.000 | Total reward: -407322400.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -77286696.000 | Total reward: -77286696.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -204496800.000 | Total reward: -204496800.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -66623696.000 | Total reward: -66623696.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -251488432.000 | Total reward: -251488432.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -355641824.000 | Total reward: -355641824.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -257829040.000 ± 158857136.000
  Average reward: -257829040.000 ± 158857136.000
  Total reward: -257829040.000 ± 158857136.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -293524576.000 | Total reward: -293524576.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -447407616.000 | Total reward: -447407616.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -2366724.750 | Total reward: -2366724.750
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -472131552.000 | Total reward: -472131552.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -407322400.000 | Total reward: -407322400.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -77286696.000 | Total reward: -77286696.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -204496800.000 | Total reward: -204496800.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -66623696.000 | Total reward: -66623696.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -251488432.000 | Total reward: -251488432.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -355641824.000 | Total reward: -355641824.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -257829040.000 ± 158857136.000
  Average reward: -257829040.000 ± 158857136.000
  Total reward: -257829040.000 ± 158857136.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -257829040.000
Rule-based avg reward: -257829040.000
No control avg reward: -257829040.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
