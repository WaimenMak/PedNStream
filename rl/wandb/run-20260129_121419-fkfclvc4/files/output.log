Iteration 0: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it, episode=10, norm_ret=-13.281, true_ret=-375020320.000, steps=600]
Agent gate_2 episode reward: [-93.76107864]
All agents episode reward: [-93.76107864]
Agent gate_2 episode reward: [-15.47300806]
All agents episode reward: [-15.47300806]
Agent gate_2 episode reward: [-11.60965853]
All agents episode reward: [-11.60965853]
Agent gate_2 episode reward: [-6.08430347]
All agents episode reward: [-6.08430347]
Agent gate_2 episode reward: [-1.6611912]
All agents episode reward: [-1.6611912]
Agent gate_2 episode reward: [-3.02682624]
All agents episode reward: [-3.02682624]
Agent gate_2 episode reward: [-0.25423261]
All agents episode reward: [-0.25423261]
Agent gate_2 episode reward: [-0.28653566]
All agents episode reward: [-0.28653566]
Agent gate_2 episode reward: [-0.28204001]
All agents episode reward: [-0.28204001]
Agent gate_2 episode reward: [-0.37396728]
All agents episode reward: [-0.37396728]
Iteration 1: 100%|██████████| 10/10 [00:23<00:00,  2.32s/it, episode=20, norm_ret=-0.359, true_ret=-281497184.000, steps=600]
Agent gate_2 episode reward: [-0.2805054]
All agents episode reward: [-0.2805054]
Agent gate_2 episode reward: [-0.37439993]
All agents episode reward: [-0.37439993]
Agent gate_2 episode reward: [-0.34433608]
All agents episode reward: [-0.34433608]
Agent gate_2 episode reward: [-0.31031548]
All agents episode reward: [-0.31031548]
Agent gate_2 episode reward: [-0.32698464]
All agents episode reward: [-0.32698464]
Agent gate_2 episode reward: [-0.45756864]
All agents episode reward: [-0.45756864]
Agent gate_2 episode reward: [-0.38688018]
All agents episode reward: [-0.38688018]
Agent gate_2 episode reward: [-0.3536677]
All agents episode reward: [-0.3536677]
Agent gate_2 episode reward: [-0.37609183]
All agents episode reward: [-0.37609183]
Agent gate_2 episode reward: [-0.37488233]
All agents episode reward: [-0.37488233]
Iteration 2: 100%|██████████| 10/10 [00:22<00:00,  2.30s/it, episode=30, norm_ret=-0.449, true_ret=-343432000.000, steps=600]
Agent gate_2 episode reward: [-0.41167374]
All agents episode reward: [-0.41167374]
Agent gate_2 episode reward: [-0.34113551]
All agents episode reward: [-0.34113551]
Agent gate_2 episode reward: [-0.4511826]
All agents episode reward: [-0.4511826]
Agent gate_2 episode reward: [-0.3850236]
All agents episode reward: [-0.3850236]
Agent gate_2 episode reward: [-0.39345692]
All agents episode reward: [-0.39345692]
Agent gate_2 episode reward: [-0.41075849]
All agents episode reward: [-0.41075849]
Agent gate_2 episode reward: [-0.46329299]
All agents episode reward: [-0.46329299]
Agent gate_2 episode reward: [-0.52212666]
All agents episode reward: [-0.52212666]
Agent gate_2 episode reward: [-0.55953506]
All agents episode reward: [-0.55953506]
Agent gate_2 episode reward: [-0.55084263]
All agents episode reward: [-0.55084263]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.29s/it, episode=40, norm_ret=-0.513, true_ret=-286093984.000, steps=600]
Agent gate_2 episode reward: [-0.47268798]
All agents episode reward: [-0.47268798]
Agent gate_2 episode reward: [-0.46694952]
All agents episode reward: [-0.46694952]
Agent gate_2 episode reward: [-0.48406616]
All agents episode reward: [-0.48406616]
Agent gate_2 episode reward: [-0.53629096]
All agents episode reward: [-0.53629096]
Agent gate_2 episode reward: [-0.51894492]
All agents episode reward: [-0.51894492]
Agent gate_2 episode reward: [-0.55126978]
All agents episode reward: [-0.55126978]
Agent gate_2 episode reward: [-0.55443373]
All agents episode reward: [-0.55443373]
Agent gate_2 episode reward: [-0.4948403]
All agents episode reward: [-0.4948403]
Agent gate_2 episode reward: [-0.52663892]
All agents episode reward: [-0.52663892]
Agent gate_2 episode reward: [-0.52512643]
All agents episode reward: [-0.52512643]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it, episode=50, norm_ret=-0.572, true_ret=-299123936.000, steps=600]
Agent gate_2 episode reward: [-0.56771144]
All agents episode reward: [-0.56771144]
Agent gate_2 episode reward: [-0.51603681]
All agents episode reward: [-0.51603681]
Agent gate_2 episode reward: [-0.58418024]
All agents episode reward: [-0.58418024]
Agent gate_2 episode reward: [-0.55147662]
All agents episode reward: [-0.55147662]
Agent gate_2 episode reward: [-0.58687927]
All agents episode reward: [-0.58687927]
Agent gate_2 episode reward: [-0.56185628]
All agents episode reward: [-0.56185628]
Agent gate_2 episode reward: [-0.59546792]
All agents episode reward: [-0.59546792]
Agent gate_2 episode reward: [-0.55680835]
All agents episode reward: [-0.55680835]
Agent gate_2 episode reward: [-0.58934744]
All agents episode reward: [-0.58934744]
Agent gate_2 episode reward: [-0.61064547]
All agents episode reward: [-0.61064547]
Iteration 5: 100%|██████████| 10/10 [00:30<00:00,  3.07s/it, episode=60, norm_ret=-0.651, true_ret=-320970208.000, steps=600]
Agent gate_2 episode reward: [-0.59617908]
All agents episode reward: [-0.59617908]
Agent gate_2 episode reward: [-0.63081776]
All agents episode reward: [-0.63081776]
Agent gate_2 episode reward: [-0.63349235]
All agents episode reward: [-0.63349235]
Agent gate_2 episode reward: [-0.66929011]
All agents episode reward: [-0.66929011]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -303358112.000 at episode 55 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.61656141]
All agents episode reward: [-0.61656141]
Agent gate_2 episode reward: [-0.65874755]
All agents episode reward: [-0.65874755]
Agent gate_2 episode reward: [-0.70347236]
All agents episode reward: [-0.70347236]
Agent gate_2 episode reward: [-0.63293525]
All agents episode reward: [-0.63293525]
Agent gate_2 episode reward: [-0.62219224]
All agents episode reward: [-0.62219224]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -294569472.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.74369395]
All agents episode reward: [-0.74369395]
Iteration 6: 100%|██████████| 10/10 [00:31<00:00,  3.12s/it, episode=70, norm_ret=-0.753, true_ret=-319308960.000, steps=600]
Agent gate_2 episode reward: [-0.72700459]
All agents episode reward: [-0.72700459]
Agent gate_2 episode reward: [-0.7106892]
All agents episode reward: [-0.7106892]
Agent gate_2 episode reward: [-0.78434366]
All agents episode reward: [-0.78434366]
Agent gate_2 episode reward: [-0.69411558]
All agents episode reward: [-0.69411558]
Agent gate_2 episode reward: [-0.72405027]
All agents episode reward: [-0.72405027]
Agent gate_2 episode reward: [-0.72716133]
All agents episode reward: [-0.72716133]
Agent gate_2 episode reward: [-0.81168102]
All agents episode reward: [-0.81168102]
Agent gate_2 episode reward: [-0.73291928]
All agents episode reward: [-0.73291928]
Agent gate_2 episode reward: [-0.7735903]
All agents episode reward: [-0.7735903]
Agent gate_2 episode reward: [-0.84273561]
All agents episode reward: [-0.84273561]
Iteration 7: 100%|██████████| 10/10 [00:30<00:00,  3.06s/it, episode=80, norm_ret=-0.832, true_ret=-291083264.000, steps=600]
Agent gate_2 episode reward: [-0.81284101]
All agents episode reward: [-0.81284101]
Agent gate_2 episode reward: [-0.80573126]
All agents episode reward: [-0.80573126]
Agent gate_2 episode reward: [-0.76342793]
All agents episode reward: [-0.76342793]
Agent gate_2 episode reward: [-0.78205162]
All agents episode reward: [-0.78205162]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -290458528.000 at episode 75 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.83803409]
All agents episode reward: [-0.83803409]
Agent gate_2 episode reward: [-0.90606758]
All agents episode reward: [-0.90606758]
Agent gate_2 episode reward: [-0.87678188]
All agents episode reward: [-0.87678188]
Agent gate_2 episode reward: [-0.83276476]
All agents episode reward: [-0.83276476]
Agent gate_2 episode reward: [-0.85475171]
All agents episode reward: [-0.85475171]
Agent gate_2 episode reward: [-0.85159634]
All agents episode reward: [-0.85159634]
Iteration 8: 100%|██████████| 10/10 [00:31<00:00,  3.11s/it, episode=90, norm_ret=-0.903, true_ret=-297361440.000, steps=600]
Agent gate_2 episode reward: [-0.88004582]
All agents episode reward: [-0.88004582]
Agent gate_2 episode reward: [-0.9139926]
All agents episode reward: [-0.9139926]
Agent gate_2 episode reward: [-0.91605613]
All agents episode reward: [-0.91605613]
Agent gate_2 episode reward: [-0.91053307]
All agents episode reward: [-0.91053307]
Agent gate_2 episode reward: [-0.82372953]
All agents episode reward: [-0.82372953]
Agent gate_2 episode reward: [-0.99356667]
All agents episode reward: [-0.99356667]
Agent gate_2 episode reward: [-0.88084637]
All agents episode reward: [-0.88084637]
Agent gate_2 episode reward: [-0.89182161]
All agents episode reward: [-0.89182161]
Agent gate_2 episode reward: [-0.87309967]
All agents episode reward: [-0.87309967]
Agent gate_2 episode reward: [-0.94726207]
All agents episode reward: [-0.94726207]
Iteration 9: 100%|██████████| 10/10 [00:32<00:00,  3.23s/it, episode=100, norm_ret=-0.967, true_ret=-286806272.000, steps=600]
Agent gate_2 episode reward: [-0.9731305]
All agents episode reward: [-0.9731305]
Agent gate_2 episode reward: [-1.00803916]
All agents episode reward: [-1.00803916]
Agent gate_2 episode reward: [-0.9901628]
All agents episode reward: [-0.9901628]
Agent gate_2 episode reward: [-0.9097002]
All agents episode reward: [-0.9097002]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -286438528.000 at episode 95 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.03112155]
All agents episode reward: [-1.03112155]
Agent gate_2 episode reward: [-0.94201263]
All agents episode reward: [-0.94201263]
Agent gate_2 episode reward: [-0.94117217]
All agents episode reward: [-0.94117217]
Agent gate_2 episode reward: [-0.96778095]
All agents episode reward: [-0.96778095]
Agent gate_2 episode reward: [-0.91966177]
All agents episode reward: [-0.91966177]
Agent gate_2 episode reward: [-0.98239209]
All agents episode reward: [-0.98239209]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -270897600.000 | Total reward: -270897600.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -447350528.000 | Total reward: -447350528.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -2366724.750 | Total reward: -2366724.750
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -472131552.000 | Total reward: -472131552.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -417219264.000 | Total reward: -417219264.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -77285432.000 | Total reward: -77285432.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -202991488.000 | Total reward: -202991488.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -66787264.000 | Total reward: -66787264.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -241826400.000 | Total reward: -241826400.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -355480000.000 | Total reward: -355480000.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -255433632.000 ± 159535424.000
  Average reward: -255433632.000 ± 159535424.000
  Total reward: -255433632.000 ± 159535424.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -293524576.000 | Total reward: -293524576.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -447407616.000 | Total reward: -447407616.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -2366724.750 | Total reward: -2366724.750
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -472131552.000 | Total reward: -472131552.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -407322400.000 | Total reward: -407322400.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -77286696.000 | Total reward: -77286696.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -204496800.000 | Total reward: -204496800.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -66623696.000 | Total reward: -66623696.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -251488432.000 | Total reward: -251488432.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -355641824.000 | Total reward: -355641824.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -257829040.000 ± 158857136.000
  Average reward: -257829040.000 ± 158857136.000
  Total reward: -257829040.000 ± 158857136.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -293524576.000 | Total reward: -293524576.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -447407616.000 | Total reward: -447407616.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -2366724.750 | Total reward: -2366724.750
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -472131552.000 | Total reward: -472131552.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -407322400.000 | Total reward: -407322400.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -77286696.000 | Total reward: -77286696.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -204496800.000 | Total reward: -204496800.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -66623696.000 | Total reward: -66623696.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -251488432.000 | Total reward: -251488432.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -355641824.000 | Total reward: -355641824.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -257829040.000 ± 158857136.000
  Average reward: -257829040.000 ± 158857136.000
  Total reward: -257829040.000 ± 158857136.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -255433632.000
Rule-based avg reward: -257829040.000
No control avg reward: -257829040.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
