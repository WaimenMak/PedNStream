Iteration 0: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it, episode=10, norm_ret=-5.904, true_ret=-102.697, steps=600]
Agent gate_2 episode reward: [-57.85283422]
All agents episode reward: [-57.85283422]
Agent gate_2 episode reward: [-0.0103304]
All agents episode reward: [-0.0103304]
Agent gate_2 episode reward: [-0.12961858]
All agents episode reward: [-0.12961858]
Agent gate_2 episode reward: [-0.12067084]
All agents episode reward: [-0.12067084]
Agent gate_2 episode reward: [-0.14160656]
All agents episode reward: [-0.14160656]
Agent gate_2 episode reward: [-0.1953833]
All agents episode reward: [-0.1953833]
Agent gate_2 episode reward: [-0.12537921]
All agents episode reward: [-0.12537921]
Agent gate_2 episode reward: [-0.15699848]
All agents episode reward: [-0.15699848]
Agent gate_2 episode reward: [-0.14739737]
All agents episode reward: [-0.14739737]
Agent gate_2 episode reward: [-0.16438398]
All agents episode reward: [-0.16438398]
Iteration 1: 100%|██████████| 10/10 [00:23<00:00,  2.32s/it, episode=20, norm_ret=-0.236, true_ret=-113.609, steps=600]
Agent gate_2 episode reward: [-0.15269948]
All agents episode reward: [-0.15269948]
Agent gate_2 episode reward: [-0.27042773]
All agents episode reward: [-0.27042773]
Agent gate_2 episode reward: [-0.23050756]
All agents episode reward: [-0.23050756]
Agent gate_2 episode reward: [-0.21576642]
All agents episode reward: [-0.21576642]
Agent gate_2 episode reward: [-0.24550723]
All agents episode reward: [-0.24550723]
Agent gate_2 episode reward: [-0.21877059]
All agents episode reward: [-0.21877059]
Agent gate_2 episode reward: [-0.20568639]
All agents episode reward: [-0.20568639]
Agent gate_2 episode reward: [-0.28433154]
All agents episode reward: [-0.28433154]
Agent gate_2 episode reward: [-0.270346]
All agents episode reward: [-0.270346]
Agent gate_2 episode reward: [-0.26689562]
All agents episode reward: [-0.26689562]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.34s/it, episode=30, norm_ret=-0.302, true_ret=-111.512, steps=600]
Agent gate_2 episode reward: [-0.27525864]
All agents episode reward: [-0.27525864]
Agent gate_2 episode reward: [-0.28333608]
All agents episode reward: [-0.28333608]
Agent gate_2 episode reward: [-0.22771856]
All agents episode reward: [-0.22771856]
Agent gate_2 episode reward: [-0.23390197]
All agents episode reward: [-0.23390197]
Agent gate_2 episode reward: [-0.31258833]
All agents episode reward: [-0.31258833]
Agent gate_2 episode reward: [-0.35543996]
All agents episode reward: [-0.35543996]
Agent gate_2 episode reward: [-0.24513222]
All agents episode reward: [-0.24513222]
Agent gate_2 episode reward: [-0.47797977]
All agents episode reward: [-0.47797977]
Agent gate_2 episode reward: [-0.2831112]
All agents episode reward: [-0.2831112]
Agent gate_2 episode reward: [-0.32113618]
All agents episode reward: [-0.32113618]
Iteration 3: 100%|██████████| 10/10 [00:23<00:00,  2.34s/it, episode=40, norm_ret=-0.355, true_ret=-92.568, steps=600]
Agent gate_2 episode reward: [-0.31472317]
All agents episode reward: [-0.31472317]
Agent gate_2 episode reward: [-0.29227216]
All agents episode reward: [-0.29227216]
Agent gate_2 episode reward: [-0.38914849]
All agents episode reward: [-0.38914849]
Agent gate_2 episode reward: [-0.32647878]
All agents episode reward: [-0.32647878]
Agent gate_2 episode reward: [-0.33807273]
All agents episode reward: [-0.33807273]
Agent gate_2 episode reward: [-0.28993274]
All agents episode reward: [-0.28993274]
Agent gate_2 episode reward: [-0.33662886]
All agents episode reward: [-0.33662886]
Agent gate_2 episode reward: [-0.66142772]
All agents episode reward: [-0.66142772]
Agent gate_2 episode reward: [-0.29178017]
All agents episode reward: [-0.29178017]
Agent gate_2 episode reward: [-0.3060684]
All agents episode reward: [-0.3060684]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.32s/it, episode=50, norm_ret=-0.349, true_ret=-101.906, steps=600]
Agent gate_2 episode reward: [-0.29504998]
All agents episode reward: [-0.29504998]
Agent gate_2 episode reward: [-0.35384619]
All agents episode reward: [-0.35384619]
Agent gate_2 episode reward: [-0.30881475]
All agents episode reward: [-0.30881475]
Agent gate_2 episode reward: [-0.37258874]
All agents episode reward: [-0.37258874]
Agent gate_2 episode reward: [-0.42299898]
All agents episode reward: [-0.42299898]
Agent gate_2 episode reward: [-0.34023026]
All agents episode reward: [-0.34023026]
Agent gate_2 episode reward: [-0.25753797]
All agents episode reward: [-0.25753797]
Agent gate_2 episode reward: [-0.38125503]
All agents episode reward: [-0.38125503]
Agent gate_2 episode reward: [-0.37754436]
All agents episode reward: [-0.37754436]
Agent gate_2 episode reward: [-0.37529709]
All agents episode reward: [-0.37529709]
Iteration 5: 100%|██████████| 10/10 [00:31<00:00,  3.14s/it, episode=60, norm_ret=-0.428, true_ret=-122.066, steps=600]
Agent gate_2 episode reward: [-0.5463741]
All agents episode reward: [-0.5463741]
Agent gate_2 episode reward: [-0.47874287]
All agents episode reward: [-0.47874287]
Agent gate_2 episode reward: [-0.30219953]
All agents episode reward: [-0.30219953]
Agent gate_2 episode reward: [-0.40174869]
All agents episode reward: [-0.40174869]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -180.810 at episode 55 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.40166347]
All agents episode reward: [-0.40166347]
Agent gate_2 episode reward: [-0.34873707]
All agents episode reward: [-0.34873707]
Agent gate_2 episode reward: [-0.17041152]
All agents episode reward: [-0.17041152]
Agent gate_2 episode reward: [-0.35626864]
All agents episode reward: [-0.35626864]
Agent gate_2 episode reward: [-0.76705799]
All agents episode reward: [-0.76705799]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -150.215 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.50873477]
All agents episode reward: [-0.50873477]
Iteration 6: 100%|██████████| 10/10 [00:31<00:00,  3.10s/it, episode=70, norm_ret=-1.069, true_ret=-199.427, steps=600]
Agent gate_2 episode reward: [-0.8627715]
All agents episode reward: [-0.8627715]
Agent gate_2 episode reward: [-0.88066411]
All agents episode reward: [-0.88066411]
Agent gate_2 episode reward: [-0.88876161]
All agents episode reward: [-0.88876161]
Agent gate_2 episode reward: [-0.55514956]
All agents episode reward: [-0.55514956]
Agent gate_2 episode reward: [-1.04718333]
All agents episode reward: [-1.04718333]
Agent gate_2 episode reward: [-0.62064098]
All agents episode reward: [-0.62064098]
Agent gate_2 episode reward: [-0.68134514]
All agents episode reward: [-0.68134514]
Agent gate_2 episode reward: [-0.59721286]
All agents episode reward: [-0.59721286]
Agent gate_2 episode reward: [-3.36870689]
All agents episode reward: [-3.36870689]
Agent gate_2 episode reward: [-1.18533736]
All agents episode reward: [-1.18533736]
Iteration 7: 100%|██████████| 10/10 [00:31<00:00,  3.11s/it, episode=80, norm_ret=-0.371, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [-0.71712235]
All agents episode reward: [-0.71712235]
Agent gate_2 episode reward: [-0.73949142]
All agents episode reward: [-0.73949142]
Agent gate_2 episode reward: [-0.75109943]
All agents episode reward: [-0.75109943]
Agent gate_2 episode reward: [-0.73089427]
All agents episode reward: [-0.73089427]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -106.771 at episode 75 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.7735619]
All agents episode reward: [-0.7735619]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Iteration 8: 100%|██████████| 10/10 [00:30<00:00,  3.10s/it, episode=90, norm_ret=-1.065, true_ret=-343.806, steps=600]
Agent gate_2 episode reward: [-0.84150336]
All agents episode reward: [-0.84150336]
Agent gate_2 episode reward: [-0.86272458]
All agents episode reward: [-0.86272458]
Agent gate_2 episode reward: [-0.91012072]
All agents episode reward: [-0.91012072]
Agent gate_2 episode reward: [-0.80850059]
All agents episode reward: [-0.80850059]
Agent gate_2 episode reward: [-0.75108703]
All agents episode reward: [-0.75108703]
Agent gate_2 episode reward: [-1.36271899]
All agents episode reward: [-1.36271899]
Agent gate_2 episode reward: [-1.32204511]
All agents episode reward: [-1.32204511]
Agent gate_2 episode reward: [-1.49174726]
All agents episode reward: [-1.49174726]
Agent gate_2 episode reward: [-0.8331074]
All agents episode reward: [-0.8331074]
Agent gate_2 episode reward: [-1.46980745]
All agents episode reward: [-1.46980745]
Iteration 9: 100%|██████████| 10/10 [00:30<00:00,  3.08s/it, episode=100, norm_ret=-0.812, true_ret=-373.665, steps=600]
Agent gate_2 episode reward: [-0.28155307]
All agents episode reward: [-0.28155307]
Agent gate_2 episode reward: [-0.33498644]
All agents episode reward: [-0.33498644]
Agent gate_2 episode reward: [-0.25584157]
All agents episode reward: [-0.25584157]
Agent gate_2 episode reward: [-0.37584317]
All agents episode reward: [-0.37584317]
Agent gate_2 episode reward: [-0.25780527]
All agents episode reward: [-0.25780527]
Agent gate_2 episode reward: [-1.14356103]
All agents episode reward: [-1.14356103]
Agent gate_2 episode reward: [-1.01625676]
All agents episode reward: [-1.01625676]
Agent gate_2 episode reward: [-1.19897986]
All agents episode reward: [-1.19897986]
Agent gate_2 episode reward: [-1.55007415]
All agents episode reward: [-1.55007415]
Agent gate_2 episode reward: [-1.70855862]
All agents episode reward: [-1.70855862]
Saved 1 agents to ppo_agents_butterfly_scC
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -166.944 | Total reward: -166.944
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -235.697 | Total reward: -235.697
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -233.955 | Total reward: -233.955
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -196.801 | Total reward: -196.801
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -48.835 | Total reward: -48.835
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -74.383 | Total reward: -74.383
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -36.972 | Total reward: -36.972
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -90.347 | Total reward: -90.347
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -201.711 | Total reward: -201.711
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -128.565 ± 83.508
  Average reward: -128.565 ± 83.508
  Total reward: -128.565 ± 83.508
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -166.944 | Total reward: -166.944
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -235.697 | Total reward: -235.697
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -233.955 | Total reward: -233.955
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -196.801 | Total reward: -196.801
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -48.835 | Total reward: -48.835
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -74.383 | Total reward: -74.383
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -36.972 | Total reward: -36.972
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -90.347 | Total reward: -90.347
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -201.711 | Total reward: -201.711
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -128.565 ± 83.508
  Average reward: -128.565 ± 83.508
  Total reward: -128.565 ± 83.508
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -166.944 | Total reward: -166.944
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -235.697 | Total reward: -235.697
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -233.955 | Total reward: -233.955
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -196.801 | Total reward: -196.801
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -48.835 | Total reward: -48.835
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -74.383 | Total reward: -74.383
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -36.972 | Total reward: -36.972
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -90.347 | Total reward: -90.347
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -201.711 | Total reward: -201.711
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -128.565 ± 83.508
  Average reward: -128.565 ± 83.508
  Total reward: -128.565 ± 83.508
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -128.565
Rule-based avg reward: -128.565
No control avg reward: -128.565
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
