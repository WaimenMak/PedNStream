Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it, episode=10, norm_ret=-6.740, true_ret=-84.830, steps=600]
Agent gate_2 episode reward: [-67.26976741]
All agents episode reward: [-67.26976741]
Agent gate_2 episode reward: [-0.06411832]
All agents episode reward: [-0.06411832]
Agent gate_2 episode reward: [0.00620307]
All agents episode reward: [0.00620307]
Agent gate_2 episode reward: [-0.01281898]
All agents episode reward: [-0.01281898]
Agent gate_2 episode reward: [-0.00350667]
All agents episode reward: [-0.00350667]
Agent gate_2 episode reward: [-0.00209843]
All agents episode reward: [-0.00209843]
Agent gate_2 episode reward: [-0.00840288]
All agents episode reward: [-0.00840288]
Agent gate_2 episode reward: [-0.01706923]
All agents episode reward: [-0.01706923]
Agent gate_2 episode reward: [-0.01357]
All agents episode reward: [-0.01357]
Agent gate_2 episode reward: [-0.01058406]
All agents episode reward: [-0.01058406]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.23s/it, episode=20, norm_ret=-0.018, true_ret=-124.903, steps=600]
Agent gate_2 episode reward: [-0.01732592]
All agents episode reward: [-0.01732592]
Agent gate_2 episode reward: [-0.01519989]
All agents episode reward: [-0.01519989]
Agent gate_2 episode reward: [-0.01700244]
All agents episode reward: [-0.01700244]
Agent gate_2 episode reward: [-0.01576185]
All agents episode reward: [-0.01576185]
Agent gate_2 episode reward: [-0.01896505]
All agents episode reward: [-0.01896505]
Agent gate_2 episode reward: [-0.01566865]
All agents episode reward: [-0.01566865]
Agent gate_2 episode reward: [-0.01986177]
All agents episode reward: [-0.01986177]
Agent gate_2 episode reward: [-0.02048454]
All agents episode reward: [-0.02048454]
Agent gate_2 episode reward: [-0.02005085]
All agents episode reward: [-0.02005085]
Agent gate_2 episode reward: [-0.02325392]
All agents episode reward: [-0.02325392]
Iteration 2: 100%|██████████| 10/10 [00:22<00:00,  2.23s/it, episode=30, norm_ret=-0.026, true_ret=-127.030, steps=600]
Agent gate_2 episode reward: [-0.01910431]
All agents episode reward: [-0.01910431]
Agent gate_2 episode reward: [-0.02296452]
All agents episode reward: [-0.02296452]
Agent gate_2 episode reward: [-0.02254491]
All agents episode reward: [-0.02254491]
Agent gate_2 episode reward: [-0.02393427]
All agents episode reward: [-0.02393427]
Agent gate_2 episode reward: [-0.02552576]
All agents episode reward: [-0.02552576]
Agent gate_2 episode reward: [-0.02792072]
All agents episode reward: [-0.02792072]
Agent gate_2 episode reward: [-0.01908374]
All agents episode reward: [-0.01908374]
Agent gate_2 episode reward: [-0.02809006]
All agents episode reward: [-0.02809006]
Agent gate_2 episode reward: [-0.04087978]
All agents episode reward: [-0.04087978]
Agent gate_2 episode reward: [-0.02923969]
All agents episode reward: [-0.02923969]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.23s/it, episode=40, norm_ret=-0.031, true_ret=-129.398, steps=600]
Agent gate_2 episode reward: [-0.03872827]
All agents episode reward: [-0.03872827]
Agent gate_2 episode reward: [-0.02756342]
All agents episode reward: [-0.02756342]
Agent gate_2 episode reward: [-0.02084013]
All agents episode reward: [-0.02084013]
Agent gate_2 episode reward: [-0.02624774]
All agents episode reward: [-0.02624774]
Agent gate_2 episode reward: [-0.03135315]
All agents episode reward: [-0.03135315]
Agent gate_2 episode reward: [-0.02661071]
All agents episode reward: [-0.02661071]
Agent gate_2 episode reward: [-0.02619653]
All agents episode reward: [-0.02619653]
Agent gate_2 episode reward: [-0.05200822]
All agents episode reward: [-0.05200822]
Agent gate_2 episode reward: [-0.02709738]
All agents episode reward: [-0.02709738]
Agent gate_2 episode reward: [-0.0345546]
All agents episode reward: [-0.0345546]
Iteration 4: 100%|██████████| 10/10 [00:22<00:00,  2.27s/it, episode=50, norm_ret=-0.031, true_ret=-101.912, steps=600]
Agent gate_2 episode reward: [-0.03396376]
All agents episode reward: [-0.03396376]
Agent gate_2 episode reward: [-0.0313909]
All agents episode reward: [-0.0313909]
Agent gate_2 episode reward: [-0.0310306]
All agents episode reward: [-0.0310306]
Agent gate_2 episode reward: [-0.02604273]
All agents episode reward: [-0.02604273]
Agent gate_2 episode reward: [-0.02793667]
All agents episode reward: [-0.02793667]
Agent gate_2 episode reward: [-0.02680246]
All agents episode reward: [-0.02680246]
Agent gate_2 episode reward: [-0.02806837]
All agents episode reward: [-0.02806837]
Agent gate_2 episode reward: [-0.03767204]
All agents episode reward: [-0.03767204]
Agent gate_2 episode reward: [-0.03388537]
All agents episode reward: [-0.03388537]
Agent gate_2 episode reward: [-0.03043326]
All agents episode reward: [-0.03043326]
Iteration 5: 100%|██████████| 10/10 [00:31<00:00,  3.19s/it, episode=60, norm_ret=-0.052, true_ret=-196.785, steps=600]
Agent gate_2 episode reward: [-0.03349013]
All agents episode reward: [-0.03349013]
Agent gate_2 episode reward: [-0.0344734]
All agents episode reward: [-0.0344734]
Agent gate_2 episode reward: [-0.03351505]
All agents episode reward: [-0.03351505]
Agent gate_2 episode reward: [-0.04454831]
All agents episode reward: [-0.04454831]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -140.788 at episode 55 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.03456182]
All agents episode reward: [-0.03456182]
Agent gate_2 episode reward: [-0.0646217]
All agents episode reward: [-0.0646217]
Agent gate_2 episode reward: [-0.07024525]
All agents episode reward: [-0.07024525]
Agent gate_2 episode reward: [-0.0684019]
All agents episode reward: [-0.0684019]
Agent gate_2 episode reward: [-0.0668155]
All agents episode reward: [-0.0668155]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -119.869 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.06749459]
All agents episode reward: [-0.06749459]
Iteration 6: 100%|██████████| 10/10 [00:30<00:00,  3.09s/it, episode=70, norm_ret=-0.088, true_ret=-223.992, steps=600]
Agent gate_2 episode reward: [-0.08756515]
All agents episode reward: [-0.08756515]
Agent gate_2 episode reward: [-0.07504891]
All agents episode reward: [-0.07504891]
Agent gate_2 episode reward: [-0.09490571]
All agents episode reward: [-0.09490571]
Agent gate_2 episode reward: [-0.07954729]
All agents episode reward: [-0.07954729]
Agent gate_2 episode reward: [-0.09943056]
All agents episode reward: [-0.09943056]
Agent gate_2 episode reward: [-0.08300778]
All agents episode reward: [-0.08300778]
Agent gate_2 episode reward: [-0.08334024]
All agents episode reward: [-0.08334024]
Agent gate_2 episode reward: [-0.10397074]
All agents episode reward: [-0.10397074]
Agent gate_2 episode reward: [-0.0873458]
All agents episode reward: [-0.0873458]
Agent gate_2 episode reward: [-0.08785005]
All agents episode reward: [-0.08785005]
Iteration 7: 100%|██████████| 10/10 [00:34<00:00,  3.42s/it, episode=80, norm_ret=-0.085, true_ret=-206.643, steps=600]
Agent gate_2 episode reward: [-0.0835904]
All agents episode reward: [-0.0835904]
Agent gate_2 episode reward: [-0.07626487]
All agents episode reward: [-0.07626487]
Agent gate_2 episode reward: [-0.08776021]
All agents episode reward: [-0.08776021]
Agent gate_2 episode reward: [-0.08504354]
All agents episode reward: [-0.08504354]
Agent gate_2 episode reward: [-0.08012261]
All agents episode reward: [-0.08012261]
Agent gate_2 episode reward: [-0.08468804]
All agents episode reward: [-0.08468804]
Agent gate_2 episode reward: [-0.08911785]
All agents episode reward: [-0.08911785]
Agent gate_2 episode reward: [-0.0895872]
All agents episode reward: [-0.0895872]
Agent gate_2 episode reward: [-0.08572172]
All agents episode reward: [-0.08572172]
Agent gate_2 episode reward: [-0.09046715]
All agents episode reward: [-0.09046715]
Iteration 8: 100%|██████████| 10/10 [00:32<00:00,  3.23s/it, episode=90, norm_ret=-0.107, true_ret=-199.201, steps=600]
Agent gate_2 episode reward: [-0.09551853]
All agents episode reward: [-0.09551853]
Agent gate_2 episode reward: [-0.08124831]
All agents episode reward: [-0.08124831]
Agent gate_2 episode reward: [-0.08471565]
All agents episode reward: [-0.08471565]
Agent gate_2 episode reward: [-0.07575127]
All agents episode reward: [-0.07575127]
Agent gate_2 episode reward: [-0.08940963]
All agents episode reward: [-0.08940963]
Agent gate_2 episode reward: [-0.14970404]
All agents episode reward: [-0.14970404]
Agent gate_2 episode reward: [-0.12076139]
All agents episode reward: [-0.12076139]
Agent gate_2 episode reward: [-0.16694031]
All agents episode reward: [-0.16694031]
Agent gate_2 episode reward: [-0.11417176]
All agents episode reward: [-0.11417176]
Agent gate_2 episode reward: [-0.09488037]
All agents episode reward: [-0.09488037]
Iteration 9: 100%|██████████| 10/10 [00:31<00:00,  3.15s/it, episode=100, norm_ret=-0.049, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [-0.09820961]
All agents episode reward: [-0.09820961]
Agent gate_2 episode reward: [-0.10165274]
All agents episode reward: [-0.10165274]
Agent gate_2 episode reward: [-0.0975382]
All agents episode reward: [-0.0975382]
Agent gate_2 episode reward: [-0.09939085]
All agents episode reward: [-0.09939085]
Agent gate_2 episode reward: [-0.09319838]
All agents episode reward: [-0.09319838]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -192.538 | Total reward: -192.538
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -171.398 | Total reward: -171.398
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -193.106 | Total reward: -193.106
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -63.118 | Total reward: -63.118
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -159.447 | Total reward: -159.447
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -155.348 | Total reward: -155.348
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -53.868 | Total reward: -53.868
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -93.884 | Total reward: -93.884
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -67.112 | Total reward: -67.112
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -50.386 | Total reward: -50.386
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -120.021 ± 56.558
  Average reward: -120.021 ± 56.558
  Total reward: -120.021 ± 56.558
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -198.361 | Total reward: -198.361
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -84.168 | Total reward: -84.168
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -95.111 | Total reward: -95.111
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -55.107 | Total reward: -55.107
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -145.545 | Total reward: -145.545
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -85.570 | Total reward: -85.570
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -157.462 | Total reward: -157.462
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): 0.000 | Total reward: 0.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -313.672 | Total reward: -313.672
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -113.500 ± 90.212
  Average reward: -113.500 ± 90.212
  Total reward: -113.500 ± 90.212
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -203.909 | Total reward: -203.909
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -236.876 | Total reward: -236.876
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -199.111 | Total reward: -199.111
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -230.003 | Total reward: -230.003
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -53.239 | Total reward: -53.239
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -212.052 | Total reward: -212.052
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -216.936 | Total reward: -216.936
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -0.000 | Total reward: -0.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -215.484 | Total reward: -215.484
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -212.587 | Total reward: -212.587
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -178.020 ± 77.339
  Average reward: -178.020 ± 77.339
  Total reward: -178.020 ± 77.339
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -120.021
Rule-based avg reward: -113.500
No control avg reward: -178.020
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
