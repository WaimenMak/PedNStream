Iteration 0: 100%|██████████| 10/10 [00:21<00:00,  2.14s/it, episode=10, norm_ret=-20.759, true_ret=-2740.462, steps=600]
Agent gate_2 episode reward: [-50.62071134]
All agents episode reward: [-50.62071134]
Agent gate_2 episode reward: [-18.16763631]
All agents episode reward: [-18.16763631]
Agent gate_2 episode reward: [-18.54697416]
All agents episode reward: [-18.54697416]
Agent gate_2 episode reward: [-19.56064215]
All agents episode reward: [-19.56064215]
Agent gate_2 episode reward: [-20.10557232]
All agents episode reward: [-20.10557232]
Agent gate_2 episode reward: [-19.02034791]
All agents episode reward: [-19.02034791]
Agent gate_2 episode reward: [-18.17235481]
All agents episode reward: [-18.17235481]
Agent gate_2 episode reward: [-16.43161208]
All agents episode reward: [-16.43161208]
Agent gate_2 episode reward: [-14.23399582]
All agents episode reward: [-14.23399582]
Agent gate_2 episode reward: [-12.73054996]
All agents episode reward: [-12.73054996]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=20, norm_ret=-11.242, true_ret=-2568.575, steps=600]
Agent gate_2 episode reward: [-12.33034403]
All agents episode reward: [-12.33034403]
Agent gate_2 episode reward: [-11.71357375]
All agents episode reward: [-11.71357375]
Agent gate_2 episode reward: [-12.62688364]
All agents episode reward: [-12.62688364]
Agent gate_2 episode reward: [-9.17931948]
All agents episode reward: [-9.17931948]
Agent gate_2 episode reward: [-11.88747048]
All agents episode reward: [-11.88747048]
Agent gate_2 episode reward: [-10.27856224]
All agents episode reward: [-10.27856224]
Agent gate_2 episode reward: [-10.45644994]
All agents episode reward: [-10.45644994]
Agent gate_2 episode reward: [-10.32169921]
All agents episode reward: [-10.32169921]
Agent gate_2 episode reward: [-11.39142958]
All agents episode reward: [-11.39142958]
Agent gate_2 episode reward: [-12.23090706]
All agents episode reward: [-12.23090706]
Iteration 2: 100%|██████████| 10/10 [00:21<00:00,  2.19s/it, episode=30, norm_ret=-11.134, true_ret=-2038.692, steps=600]
Agent gate_2 episode reward: [-12.0900801]
All agents episode reward: [-12.0900801]
Agent gate_2 episode reward: [-10.32175127]
All agents episode reward: [-10.32175127]
Agent gate_2 episode reward: [-11.83962409]
All agents episode reward: [-11.83962409]
Agent gate_2 episode reward: [-12.32517662]
All agents episode reward: [-12.32517662]
Agent gate_2 episode reward: [-11.21828349]
All agents episode reward: [-11.21828349]
Agent gate_2 episode reward: [-10.86574102]
All agents episode reward: [-10.86574102]
Agent gate_2 episode reward: [-11.65558112]
All agents episode reward: [-11.65558112]
Agent gate_2 episode reward: [-11.18310483]
All agents episode reward: [-11.18310483]
Agent gate_2 episode reward: [-9.57003668]
All agents episode reward: [-9.57003668]
Agent gate_2 episode reward: [-10.27000468]
All agents episode reward: [-10.27000468]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.24s/it, episode=40, norm_ret=-11.763, true_ret=-2435.131, steps=600]
Agent gate_2 episode reward: [-10.23690865]
All agents episode reward: [-10.23690865]
Agent gate_2 episode reward: [-13.12622462]
All agents episode reward: [-13.12622462]
Agent gate_2 episode reward: [-3.63351106]
All agents episode reward: [-3.63351106]
Agent gate_2 episode reward: [-12.95864353]
All agents episode reward: [-12.95864353]
Agent gate_2 episode reward: [-13.12847361]
All agents episode reward: [-13.12847361]
Agent gate_2 episode reward: [-12.11456397]
All agents episode reward: [-12.11456397]
Agent gate_2 episode reward: [-13.35056084]
All agents episode reward: [-13.35056084]
Agent gate_2 episode reward: [-12.71130575]
All agents episode reward: [-12.71130575]
Agent gate_2 episode reward: [-13.4702254]
All agents episode reward: [-13.4702254]
Agent gate_2 episode reward: [-12.8975276]
All agents episode reward: [-12.8975276]
Iteration 4: 100%|██████████| 10/10 [00:22<00:00,  2.21s/it, episode=50, norm_ret=-12.853, true_ret=-2331.936, steps=600]
Agent gate_2 episode reward: [-13.02802679]
All agents episode reward: [-13.02802679]
Agent gate_2 episode reward: [-13.87838747]
All agents episode reward: [-13.87838747]
Agent gate_2 episode reward: [-12.88271249]
All agents episode reward: [-12.88271249]
Agent gate_2 episode reward: [-12.0429832]
All agents episode reward: [-12.0429832]
Agent gate_2 episode reward: [-12.40048576]
All agents episode reward: [-12.40048576]
Agent gate_2 episode reward: [-13.75338039]
All agents episode reward: [-13.75338039]
Agent gate_2 episode reward: [-12.75763979]
All agents episode reward: [-12.75763979]
Agent gate_2 episode reward: [-12.22352556]
All agents episode reward: [-12.22352556]
Agent gate_2 episode reward: [-12.67916495]
All agents episode reward: [-12.67916495]
Agent gate_2 episode reward: [-12.8851853]
All agents episode reward: [-12.8851853]
Iteration 5: 100%|██████████| 10/10 [00:27<00:00,  2.79s/it, episode=60, norm_ret=-12.421, true_ret=-2410.107, steps=600]
Agent gate_2 episode reward: [-13.23231457]
All agents episode reward: [-13.23231457]
Agent gate_2 episode reward: [-14.09729853]
All agents episode reward: [-14.09729853]
Agent gate_2 episode reward: [-13.78458069]
All agents episode reward: [-13.78458069]
Agent gate_2 episode reward: [-12.01401972]
All agents episode reward: [-12.01401972]
Saved 1 agents to ppo_agents_butterfly_scA
[Validation] New best avg return: -2410.363 at episode 55 (over 5 val episodes, saved to ppo_agents_butterfly_scA)
Agent gate_2 episode reward: [-12.37554989]
All agents episode reward: [-12.37554989]
Agent gate_2 episode reward: [-4.21669532]
All agents episode reward: [-4.21669532]
Agent gate_2 episode reward: [-13.32861231]
All agents episode reward: [-13.32861231]
Agent gate_2 episode reward: [-12.70796222]
All agents episode reward: [-12.70796222]
Agent gate_2 episode reward: [-14.6455944]
All agents episode reward: [-14.6455944]
Saved 1 agents to ppo_agents_butterfly_scA
[Validation] New best avg return: -2328.661 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scA)
Agent gate_2 episode reward: [-13.80794512]
All agents episode reward: [-13.80794512]
Iteration 6: 100%|██████████| 10/10 [00:29<00:00,  2.98s/it, episode=70, norm_ret=-12.374, true_ret=-2520.979, steps=600]
Agent gate_2 episode reward: [-12.97094962]
All agents episode reward: [-12.97094962]
Agent gate_2 episode reward: [-4.03089209]
All agents episode reward: [-4.03089209]
Agent gate_2 episode reward: [-14.18686211]
All agents episode reward: [-14.18686211]
Agent gate_2 episode reward: [-13.27111635]
All agents episode reward: [-13.27111635]
Agent gate_2 episode reward: [-14.97812534]
All agents episode reward: [-14.97812534]
Agent gate_2 episode reward: [-4.60472734]
All agents episode reward: [-4.60472734]
Agent gate_2 episode reward: [-15.05612261]
All agents episode reward: [-15.05612261]
Agent gate_2 episode reward: [-14.72341363]
All agents episode reward: [-14.72341363]
Agent gate_2 episode reward: [-14.99415716]
All agents episode reward: [-14.99415716]
Saved 1 agents to ppo_agents_butterfly_scA
[Validation] New best avg return: -2139.128 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scA)
Agent gate_2 episode reward: [-14.92489215]
All agents episode reward: [-14.92489215]
Iteration 7: 100%|██████████| 10/10 [00:29<00:00,  2.91s/it, episode=80, norm_ret=-14.826, true_ret=-2635.546, steps=600]
Agent gate_2 episode reward: [-15.09617295]
All agents episode reward: [-15.09617295]
Agent gate_2 episode reward: [-15.18411796]
All agents episode reward: [-15.18411796]
Agent gate_2 episode reward: [-13.09245791]
All agents episode reward: [-13.09245791]
Agent gate_2 episode reward: [-15.47029247]
All agents episode reward: [-15.47029247]
Agent gate_2 episode reward: [-13.76365212]
All agents episode reward: [-13.76365212]
Agent gate_2 episode reward: [-14.95754917]
All agents episode reward: [-14.95754917]
Agent gate_2 episode reward: [-15.35019127]
All agents episode reward: [-15.35019127]
Agent gate_2 episode reward: [-13.73539641]
All agents episode reward: [-13.73539641]
Agent gate_2 episode reward: [-15.50491594]
All agents episode reward: [-15.50491594]
Agent gate_2 episode reward: [-16.10835144]
All agents episode reward: [-16.10835144]
Iteration 8: 100%|██████████| 10/10 [00:29<00:00,  2.91s/it, episode=90, norm_ret=-14.409, true_ret=-2232.722, steps=600]
Agent gate_2 episode reward: [-13.50247855]
All agents episode reward: [-13.50247855]
Agent gate_2 episode reward: [-13.53018242]
All agents episode reward: [-13.53018242]
Agent gate_2 episode reward: [-15.68926747]
All agents episode reward: [-15.68926747]
Agent gate_2 episode reward: [-13.52262899]
All agents episode reward: [-13.52262899]
Agent gate_2 episode reward: [-15.5984338]
All agents episode reward: [-15.5984338]
Agent gate_2 episode reward: [-15.8329136]
All agents episode reward: [-15.8329136]
Agent gate_2 episode reward: [-13.06696506]
All agents episode reward: [-13.06696506]
Agent gate_2 episode reward: [-14.2674909]
All agents episode reward: [-14.2674909]
Agent gate_2 episode reward: [-15.16146865]
All agents episode reward: [-15.16146865]
Agent gate_2 episode reward: [-13.92215751]
All agents episode reward: [-13.92215751]
Iteration 9: 100%|██████████| 10/10 [00:27<00:00,  2.76s/it, episode=100, norm_ret=-12.011, true_ret=-671.080, steps=600]
Agent gate_2 episode reward: [-8.8224118]
All agents episode reward: [-8.8224118]
Agent gate_2 episode reward: [-14.32285975]
All agents episode reward: [-14.32285975]
Agent gate_2 episode reward: [-15.00343185]
All agents episode reward: [-15.00343185]
Agent gate_2 episode reward: [-14.31348613]
All agents episode reward: [-14.31348613]
Agent gate_2 episode reward: [-14.79273425]
All agents episode reward: [-14.79273425]
Agent gate_2 episode reward: [-15.08593723]
All agents episode reward: [-15.08593723]
Agent gate_2 episode reward: [-14.88466928]
All agents episode reward: [-14.88466928]
Agent gate_2 episode reward: [-13.84816336]
All agents episode reward: [-13.84816336]
Agent gate_2 episode reward: [-4.82971771]
All agents episode reward: [-4.82971771]
Saved 1 agents to ppo_agents_butterfly_scA
[Validation] New best avg return: -2080.501 at episode 100 (over 5 val episodes, saved to ppo_agents_butterfly_scA)
Agent gate_2 episode reward: [-4.20895745]
All agents episode reward: [-4.20895745]
Loaded 1 agents from ppo_agents_butterfly_scA
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -703.842 | Total reward: -703.842
Saved run 1 to rl_training/butterfly_scA/ppo_run1
  Run 2/10... Avg agent reward (episode): -2216.278 | Total reward: -2216.278
Saved run 2 to rl_training/butterfly_scA/ppo_run2
  Run 3/10... Avg agent reward (episode): -2425.265 | Total reward: -2425.265
Saved run 3 to rl_training/butterfly_scA/ppo_run3
  Run 4/10... Avg agent reward (episode): -2273.947 | Total reward: -2273.947
Saved run 4 to rl_training/butterfly_scA/ppo_run4
  Run 5/10... Avg agent reward (episode): -2544.585 | Total reward: -2544.585
Saved run 5 to rl_training/butterfly_scA/ppo_run5
  Run 6/10... Avg agent reward (episode): -2400.324 | Total reward: -2400.324
Saved run 6 to rl_training/butterfly_scA/ppo_run6
  Run 7/10... Avg agent reward (episode): -2456.360 | Total reward: -2456.360
Saved run 7 to rl_training/butterfly_scA/ppo_run7
  Run 8/10... Avg agent reward (episode): -2339.958 | Total reward: -2339.958
Saved run 8 to rl_training/butterfly_scA/ppo_run8
  Run 9/10... Avg agent reward (episode): -2399.435 | Total reward: -2399.435
Saved run 9 to rl_training/butterfly_scA/ppo_run9
  Run 10/10... Avg agent reward (episode): -2530.390 | Total reward: -2530.390
Saved run 10 to rl_training/butterfly_scA/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -2229.039 ± 517.653
  Average reward: -2229.039 ± 517.653
  Total reward: -2229.039 ± 517.653
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -701.285 | Total reward: -701.285
Saved run 1 to rl_training/butterfly_scA/rule_based_run1
  Run 2/10... Avg agent reward (episode): -2216.278 | Total reward: -2216.278
Saved run 2 to rl_training/butterfly_scA/rule_based_run2
  Run 3/10... Avg agent reward (episode): -2425.265 | Total reward: -2425.265
Saved run 3 to rl_training/butterfly_scA/rule_based_run3
  Run 4/10... Avg agent reward (episode): -2273.947 | Total reward: -2273.947
Saved run 4 to rl_training/butterfly_scA/rule_based_run4
  Run 5/10... Avg agent reward (episode): -2544.585 | Total reward: -2544.585
Saved run 5 to rl_training/butterfly_scA/rule_based_run5
  Run 6/10... Avg agent reward (episode): -2400.324 | Total reward: -2400.324
Saved run 6 to rl_training/butterfly_scA/rule_based_run6
  Run 7/10... Avg agent reward (episode): -2456.360 | Total reward: -2456.360
Saved run 7 to rl_training/butterfly_scA/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2339.958 | Total reward: -2339.958
Saved run 8 to rl_training/butterfly_scA/rule_based_run8
  Run 9/10... Avg agent reward (episode): -2399.435 | Total reward: -2399.435
Saved run 9 to rl_training/butterfly_scA/rule_based_run9
  Run 10/10... Avg agent reward (episode): -2530.390 | Total reward: -2530.390
Saved run 10 to rl_training/butterfly_scA/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -2228.783 ± 518.406
  Average reward: -2228.783 ± 518.406
  Total reward: -2228.783 ± 518.406
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -701.285 | Total reward: -701.285
Saved run 1 to rl_training/butterfly_scA/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -2216.278 | Total reward: -2216.278
Saved run 2 to rl_training/butterfly_scA/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -2425.265 | Total reward: -2425.265
Saved run 3 to rl_training/butterfly_scA/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -2273.947 | Total reward: -2273.947
Saved run 4 to rl_training/butterfly_scA/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -2544.585 | Total reward: -2544.585
Saved run 5 to rl_training/butterfly_scA/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -2400.324 | Total reward: -2400.324
Saved run 6 to rl_training/butterfly_scA/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -2456.360 | Total reward: -2456.360
Saved run 7 to rl_training/butterfly_scA/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -2339.958 | Total reward: -2339.958
Saved run 8 to rl_training/butterfly_scA/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -2399.435 | Total reward: -2399.435
Saved run 9 to rl_training/butterfly_scA/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -2530.390 | Total reward: -2530.390
Saved run 10 to rl_training/butterfly_scA/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -2228.783 ± 518.406
  Average reward: -2228.783 ± 518.406
  Total reward: -2228.783 ± 518.406
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -2229.039
Rule-based avg reward: -2228.783
No control avg reward: -2228.783
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
