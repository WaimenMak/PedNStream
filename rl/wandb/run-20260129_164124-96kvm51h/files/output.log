Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.24s/it, episode=10, norm_ret=-10.264, true_ret=-606349824.000, steps=600]
Agent gate_2 episode reward: [-70.97840425]
All agents episode reward: [-70.97840425]
Agent gate_2 episode reward: [-2.7885649]
All agents episode reward: [-2.7885649]
Agent gate_2 episode reward: [-7.52249173]
All agents episode reward: [-7.52249173]
Agent gate_2 episode reward: [-2.66394118]
All agents episode reward: [-2.66394118]
Agent gate_2 episode reward: [-3.0058187]
All agents episode reward: [-3.0058187]
Agent gate_2 episode reward: [-2.66688055]
All agents episode reward: [-2.66688055]
Agent gate_2 episode reward: [-2.32952973]
All agents episode reward: [-2.32952973]
Agent gate_2 episode reward: [-1.64381836]
All agents episode reward: [-1.64381836]
Agent gate_2 episode reward: [-4.40442408]
All agents episode reward: [-4.40442408]
Agent gate_2 episode reward: [-4.63693772]
All agents episode reward: [-4.63693772]
Iteration 1: 100%|██████████| 10/10 [00:24<00:00,  2.42s/it, episode=20, norm_ret=-3.071, true_ret=-212448240.000, steps=600]
Agent gate_2 episode reward: [-4.99662141]
All agents episode reward: [-4.99662141]
Agent gate_2 episode reward: [-2.69363528]
All agents episode reward: [-2.69363528]
Agent gate_2 episode reward: [-1.83873987]
All agents episode reward: [-1.83873987]
Agent gate_2 episode reward: [-1.87991425]
All agents episode reward: [-1.87991425]
Agent gate_2 episode reward: [-3.55207561]
All agents episode reward: [-3.55207561]
Agent gate_2 episode reward: [-3.99279714]
All agents episode reward: [-3.99279714]
Agent gate_2 episode reward: [-3.64723771]
All agents episode reward: [-3.64723771]
Agent gate_2 episode reward: [-2.79412816]
All agents episode reward: [-2.79412816]
Agent gate_2 episode reward: [-3.17967039]
All agents episode reward: [-3.17967039]
Agent gate_2 episode reward: [-2.13469103]
All agents episode reward: [-2.13469103]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.36s/it, episode=30, norm_ret=-2.759, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [-2.14908834]
All agents episode reward: [-2.14908834]
Agent gate_2 episode reward: [-4.78711455]
All agents episode reward: [-4.78711455]
Agent gate_2 episode reward: [-3.86893623]
All agents episode reward: [-3.86893623]
Agent gate_2 episode reward: [-2.72215873]
All agents episode reward: [-2.72215873]
Agent gate_2 episode reward: [-3.0414673]
All agents episode reward: [-3.0414673]
Agent gate_2 episode reward: [-3.33552785]
All agents episode reward: [-3.33552785]
Agent gate_2 episode reward: [-0.0040639]
All agents episode reward: [-0.0040639]
Agent gate_2 episode reward: [-2.62330856]
All agents episode reward: [-2.62330856]
Agent gate_2 episode reward: [-5.0565353]
All agents episode reward: [-5.0565353]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.24s/it, episode=40, norm_ret=-3.656, true_ret=-219843888.000, steps=600]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-3.19437465]
All agents episode reward: [-3.19437465]
Agent gate_2 episode reward: [-5.35500699]
All agents episode reward: [-5.35500699]
Agent gate_2 episode reward: [-7.11969132]
All agents episode reward: [-7.11969132]
Agent gate_2 episode reward: [-5.96547572]
All agents episode reward: [-5.96547572]
Agent gate_2 episode reward: [-3.59881329]
All agents episode reward: [-3.59881329]
Agent gate_2 episode reward: [-3.39462991]
All agents episode reward: [-3.39462991]
Agent gate_2 episode reward: [-5.07685348]
All agents episode reward: [-5.07685348]
Agent gate_2 episode reward: [-2.85744921]
All agents episode reward: [-2.85744921]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it, episode=50, norm_ret=-3.863, true_ret=-201500896.000, steps=600]
Agent gate_2 episode reward: [-3.09770773]
All agents episode reward: [-3.09770773]
Agent gate_2 episode reward: [-4.17072664]
All agents episode reward: [-4.17072664]
Agent gate_2 episode reward: [-5.04204516]
All agents episode reward: [-5.04204516]
Agent gate_2 episode reward: [-4.88696253]
All agents episode reward: [-4.88696253]
Agent gate_2 episode reward: [-0.03939806]
All agents episode reward: [-0.03939806]
Agent gate_2 episode reward: [-6.39631509]
All agents episode reward: [-6.39631509]
Agent gate_2 episode reward: [-5.76720318]
All agents episode reward: [-5.76720318]
Agent gate_2 episode reward: [-6.38436505]
All agents episode reward: [-6.38436505]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-2.84167936]
All agents episode reward: [-2.84167936]
Iteration 5: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it, episode=60, norm_ret=-4.043, true_ret=-312662112.000, steps=600]
Agent gate_2 episode reward: [-2.78358216]
All agents episode reward: [-2.78358216]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-4.87597887]
All agents episode reward: [-4.87597887]
Agent gate_2 episode reward: [-2.38245275]
All agents episode reward: [-2.38245275]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -7.002 at episode 55 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-7.0019826]
All agents episode reward: [-7.0019826]
Agent gate_2 episode reward: [-5.95292112]
All agents episode reward: [-5.95292112]
Agent gate_2 episode reward: [-6.31158246]
All agents episode reward: [-6.31158246]
Agent gate_2 episode reward: [-0.34409926]
All agents episode reward: [-0.34409926]
Agent gate_2 episode reward: [-6.07797872]
All agents episode reward: [-6.07797872]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -4.703 at episode 60 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-4.70320596]
All agents episode reward: [-4.70320596]
Iteration 6: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it, episode=70, norm_ret=-4.677, true_ret=-8592322.000, steps=600]
Agent gate_2 episode reward: [-4.6244187]
All agents episode reward: [-4.6244187]
Agent gate_2 episode reward: [-4.29297697]
All agents episode reward: [-4.29297697]
Agent gate_2 episode reward: [-7.02072623]
All agents episode reward: [-7.02072623]
Agent gate_2 episode reward: [-6.75005133]
All agents episode reward: [-6.75005133]
Agent gate_2 episode reward: [-8.30309208]
All agents episode reward: [-8.30309208]
Agent gate_2 episode reward: [-4.78320784]
All agents episode reward: [-4.78320784]
Agent gate_2 episode reward: [-3.08033212]
All agents episode reward: [-3.08033212]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-7.78337954]
All agents episode reward: [-7.78337954]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -0.136 at episode 70 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.13582657]
All agents episode reward: [-0.13582657]
Iteration 7: 100%|██████████| 10/10 [00:23<00:00,  2.37s/it, episode=80, norm_ret=-5.150, true_ret=-293179872.000, steps=600]
Agent gate_2 episode reward: [-0.27378417]
All agents episode reward: [-0.27378417]
Agent gate_2 episode reward: [-6.90171028]
All agents episode reward: [-6.90171028]
Agent gate_2 episode reward: [-6.05270928]
All agents episode reward: [-6.05270928]
Agent gate_2 episode reward: [-6.88272427]
All agents episode reward: [-6.88272427]
Agent gate_2 episode reward: [-8.39360379]
All agents episode reward: [-8.39360379]
Agent gate_2 episode reward: [-6.03747882]
All agents episode reward: [-6.03747882]
Agent gate_2 episode reward: [-6.13845356]
All agents episode reward: [-6.13845356]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-5.99403795]
All agents episode reward: [-5.99403795]
Agent gate_2 episode reward: [-4.82197651]
All agents episode reward: [-4.82197651]
Iteration 8: 100%|██████████| 10/10 [00:22<00:00,  2.27s/it, episode=90, norm_ret=-5.444, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [-5.35533825]
All agents episode reward: [-5.35533825]
Agent gate_2 episode reward: [-3.32110384]
All agents episode reward: [-3.32110384]
Agent gate_2 episode reward: [-6.9339767]
All agents episode reward: [-6.9339767]
Agent gate_2 episode reward: [-6.11868136]
All agents episode reward: [-6.11868136]
Agent gate_2 episode reward: [-7.29128031]
All agents episode reward: [-7.29128031]
Agent gate_2 episode reward: [-3.33880477]
All agents episode reward: [-3.33880477]
Agent gate_2 episode reward: [-7.86777337]
All agents episode reward: [-7.86777337]
Agent gate_2 episode reward: [-6.65738762]
All agents episode reward: [-6.65738762]
Agent gate_2 episode reward: [-7.56028669]
All agents episode reward: [-7.56028669]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: 0.000 at episode 90 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Iteration 9: 100%|██████████| 10/10 [00:23<00:00,  2.39s/it, episode=100, norm_ret=-5.297, true_ret=-204092464.000, steps=600]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-6.60704154]
All agents episode reward: [-6.60704154]
Agent gate_2 episode reward: [-4.53120468]
All agents episode reward: [-4.53120468]
Agent gate_2 episode reward: [-11.3724958]
All agents episode reward: [-11.3724958]
Agent gate_2 episode reward: [-4.20279158]
All agents episode reward: [-4.20279158]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-8.28652773]
All agents episode reward: [-8.28652773]
Agent gate_2 episode reward: [-6.11335303]
All agents episode reward: [-6.11335303]
Agent gate_2 episode reward: [-8.30380398]
All agents episode reward: [-8.30380398]
Agent gate_2 episode reward: [-3.5564903]
All agents episode reward: [-3.5564903]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -208450240.000 | Total reward: -208450240.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377508000.000 ± 81819816.000
  Average reward: -377508000.000 ± 81819816.000
  Total reward: -377508000.000 ± 81819816.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -212225136.000 | Total reward: -212225136.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81044008.000
  Average reward: -377885472.000 ± 81044008.000
  Total reward: -377885472.000 ± 81044008.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -212225136.000 | Total reward: -212225136.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81044008.000
  Average reward: -377885472.000 ± 81044008.000
  Total reward: -377885472.000 ± 81044008.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -377508000.000
Rule-based avg reward: -377885472.000
No control avg reward: -377885472.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
