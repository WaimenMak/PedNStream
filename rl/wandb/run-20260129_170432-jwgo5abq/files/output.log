Iteration 0: 100%|██████████| 10/10 [00:24<00:00,  2.44s/it, episode=10, norm_ret=-12.236, true_ret=-1191.454, steps=600]
Agent gate_2 episode reward: [-67.99130877]
All agents episode reward: [-67.99130877]
Agent gate_2 episode reward: [-13.27823193]
All agents episode reward: [-13.27823193]
Agent gate_2 episode reward: [-2.52833258]
All agents episode reward: [-2.52833258]
Agent gate_2 episode reward: [-4.10005233]
All agents episode reward: [-4.10005233]
Agent gate_2 episode reward: [-6.29958402]
All agents episode reward: [-6.29958402]
Agent gate_2 episode reward: [-4.82488869]
All agents episode reward: [-4.82488869]
Agent gate_2 episode reward: [-6.17427898]
All agents episode reward: [-6.17427898]
Agent gate_2 episode reward: [-4.78205017]
All agents episode reward: [-4.78205017]
Agent gate_2 episode reward: [-6.58739249]
All agents episode reward: [-6.58739249]
Agent gate_2 episode reward: [-5.79246999]
All agents episode reward: [-5.79246999]
Iteration 1: 100%|██████████| 10/10 [00:23<00:00,  2.38s/it, episode=20, norm_ret=-5.150, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [-6.103459]
All agents episode reward: [-6.103459]
Agent gate_2 episode reward: [-6.1128911]
All agents episode reward: [-6.1128911]
Agent gate_2 episode reward: [-2.65858791]
All agents episode reward: [-2.65858791]
Agent gate_2 episode reward: [-5.08035238]
All agents episode reward: [-5.08035238]
Agent gate_2 episode reward: [-5.2700492]
All agents episode reward: [-5.2700492]
Agent gate_2 episode reward: [-7.46627102]
All agents episode reward: [-7.46627102]
Agent gate_2 episode reward: [-5.27689929]
All agents episode reward: [-5.27689929]
Agent gate_2 episode reward: [-3.33200784]
All agents episode reward: [-3.33200784]
Agent gate_2 episode reward: [-10.20163663]
All agents episode reward: [-10.20163663]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.33s/it, episode=30, norm_ret=-4.549, true_ret=-1251.281, steps=600]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-5.57306227]
All agents episode reward: [-5.57306227]
Agent gate_2 episode reward: [-5.28301555]
All agents episode reward: [-5.28301555]
Agent gate_2 episode reward: [-5.2359702]
All agents episode reward: [-5.2359702]
Agent gate_2 episode reward: [-1.01415292]
All agents episode reward: [-1.01415292]
Agent gate_2 episode reward: [-5.14506505]
All agents episode reward: [-5.14506505]
Agent gate_2 episode reward: [-6.50296773]
All agents episode reward: [-6.50296773]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-8.58007723]
All agents episode reward: [-8.58007723]
Agent gate_2 episode reward: [-8.15747196]
All agents episode reward: [-8.15747196]
Iteration 3: 100%|██████████| 10/10 [00:24<00:00,  2.43s/it, episode=40, norm_ret=-6.916, true_ret=-1224.328, steps=600]
Agent gate_2 episode reward: [-8.11443259]
All agents episode reward: [-8.11443259]
Agent gate_2 episode reward: [-3.84400009]
All agents episode reward: [-3.84400009]
Agent gate_2 episode reward: [-4.78126125]
All agents episode reward: [-4.78126125]
Agent gate_2 episode reward: [-7.658316]
All agents episode reward: [-7.658316]
Agent gate_2 episode reward: [-7.84091565]
All agents episode reward: [-7.84091565]
Agent gate_2 episode reward: [-5.28517893]
All agents episode reward: [-5.28517893]
Agent gate_2 episode reward: [-7.42019119]
All agents episode reward: [-7.42019119]
Agent gate_2 episode reward: [-9.23555039]
All agents episode reward: [-9.23555039]
Agent gate_2 episode reward: [-6.31708169]
All agents episode reward: [-6.31708169]
Agent gate_2 episode reward: [-8.66204361]
All agents episode reward: [-8.66204361]
Iteration 4: 100%|██████████| 10/10 [00:24<00:00,  2.41s/it, episode=50, norm_ret=-4.490, true_ret=-763.086, steps=600]
Agent gate_2 episode reward: [-8.64774554]
All agents episode reward: [-8.64774554]
Agent gate_2 episode reward: [-10.2171156]
All agents episode reward: [-10.2171156]
Agent gate_2 episode reward: [-4.79198915]
All agents episode reward: [-4.79198915]
Agent gate_2 episode reward: [-7.11140263]
All agents episode reward: [-7.11140263]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-0.00291029]
All agents episode reward: [-0.00291029]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-8.54115485]
All agents episode reward: [-8.54115485]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-5.59141956]
All agents episode reward: [-5.59141956]
Iteration 5: 100%|██████████| 10/10 [00:23<00:00,  2.34s/it, episode=60, norm_ret=-6.699, true_ret=-511.788, steps=600]
Agent gate_2 episode reward: [-5.96924263]
All agents episode reward: [-5.96924263]
Agent gate_2 episode reward: [-11.27042198]
All agents episode reward: [-11.27042198]
Agent gate_2 episode reward: [-7.52937295]
All agents episode reward: [-7.52937295]
Agent gate_2 episode reward: [-10.68892523]
All agents episode reward: [-10.68892523]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -5.802 at episode 55 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-5.80155445]
All agents episode reward: [-5.80155445]
Agent gate_2 episode reward: [-4.19755811]
All agents episode reward: [-4.19755811]
Agent gate_2 episode reward: [-9.93934649]
All agents episode reward: [-9.93934649]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-7.70172917]
All agents episode reward: [-7.70172917]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -3.894 at episode 60 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-3.89369634]
All agents episode reward: [-3.89369634]
Iteration 6: 100%|██████████| 10/10 [00:23<00:00,  2.39s/it, episode=70, norm_ret=-4.121, true_ret=-56.295, steps=600]
Agent gate_2 episode reward: [-3.34817484]
All agents episode reward: [-3.34817484]
Agent gate_2 episode reward: [-3.40529781]
All agents episode reward: [-3.40529781]
Agent gate_2 episode reward: [-7.99801848]
All agents episode reward: [-7.99801848]
Agent gate_2 episode reward: [-3.34943059]
All agents episode reward: [-3.34943059]
Agent gate_2 episode reward: [-5.70466972]
All agents episode reward: [-5.70466972]
Agent gate_2 episode reward: [-0.02618598]
All agents episode reward: [-0.02618598]
Agent gate_2 episode reward: [-3.31825501]
All agents episode reward: [-3.31825501]
Agent gate_2 episode reward: [-4.26012415]
All agents episode reward: [-4.26012415]
Agent gate_2 episode reward: [-9.35803487]
All agents episode reward: [-9.35803487]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -0.446 at episode 70 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.44570588]
All agents episode reward: [-0.44570588]
Iteration 7: 100%|██████████| 10/10 [00:22<00:00,  2.29s/it, episode=80, norm_ret=-6.099, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [-0.57440956]
All agents episode reward: [-0.57440956]
Agent gate_2 episode reward: [-10.79877857]
All agents episode reward: [-10.79877857]
Agent gate_2 episode reward: [-10.58495366]
All agents episode reward: [-10.58495366]
Agent gate_2 episode reward: [-5.95395392]
All agents episode reward: [-5.95395392]
Agent gate_2 episode reward: [-9.34233858]
All agents episode reward: [-9.34233858]
Agent gate_2 episode reward: [-4.07627814]
All agents episode reward: [-4.07627814]
Agent gate_2 episode reward: [-2.97415574]
All agents episode reward: [-2.97415574]
Agent gate_2 episode reward: [-4.39484553]
All agents episode reward: [-4.39484553]
Agent gate_2 episode reward: [-12.29065189]
All agents episode reward: [-12.29065189]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: 0.000 at episode 80 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Iteration 8: 100%|██████████| 10/10 [00:23<00:00,  2.40s/it, episode=90, norm_ret=-5.337, true_ret=-507.112, steps=600]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-11.81942416]
All agents episode reward: [-11.81942416]
Agent gate_2 episode reward: [-2.91887421]
All agents episode reward: [-2.91887421]
Agent gate_2 episode reward: [-4.37527689]
All agents episode reward: [-4.37527689]
Agent gate_2 episode reward: [-11.07179167]
All agents episode reward: [-11.07179167]
Agent gate_2 episode reward: [-4.38345786]
All agents episode reward: [-4.38345786]
Agent gate_2 episode reward: [-6.3854103]
All agents episode reward: [-6.3854103]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-8.26329478]
All agents episode reward: [-8.26329478]
Agent gate_2 episode reward: [-4.15739086]
All agents episode reward: [-4.15739086]
Iteration 9: 100%|██████████| 10/10 [00:24<00:00,  2.42s/it, episode=100, norm_ret=-5.847, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [-4.25222665]
All agents episode reward: [-4.25222665]
Agent gate_2 episode reward: [-6.81549756]
All agents episode reward: [-6.81549756]
Agent gate_2 episode reward: [-6.20722252]
All agents episode reward: [-6.20722252]
Agent gate_2 episode reward: [-11.02778178]
All agents episode reward: [-11.02778178]
Agent gate_2 episode reward: [-5.34211097]
All agents episode reward: [-5.34211097]
Agent gate_2 episode reward: [-6.60700168]
All agents episode reward: [-6.60700168]
Agent gate_2 episode reward: [-8.03508882]
All agents episode reward: [-8.03508882]
Agent gate_2 episode reward: [-8.30497925]
All agents episode reward: [-8.30497925]
Agent gate_2 episode reward: [-1.88033408]
All agents episode reward: [-1.88033408]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -589.514 | Total reward: -589.514
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -1023.275 | Total reward: -1023.275
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -1180.363 | Total reward: -1180.363
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -1414.308 | Total reward: -1414.308
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -945.117 | Total reward: -945.117
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -1179.414 | Total reward: -1179.414
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -1263.859 | Total reward: -1263.859
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -1034.603 | Total reward: -1034.603
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -1080.338 | Total reward: -1080.338
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -786.026 | Total reward: -786.026
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -1049.682 ± 225.122
  Average reward: -1049.682 ± 225.122
  Total reward: -1049.682 ± 225.122
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -589.514 | Total reward: -589.514
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -1023.275 | Total reward: -1023.275
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -1180.363 | Total reward: -1180.363
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1414.308 | Total reward: -1414.308
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -945.117 | Total reward: -945.117
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -1179.414 | Total reward: -1179.414
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -1263.859 | Total reward: -1263.859
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -1034.603 | Total reward: -1034.603
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -1080.338 | Total reward: -1080.338
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -786.026 | Total reward: -786.026
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -1049.682 ± 225.122
  Average reward: -1049.682 ± 225.122
  Total reward: -1049.682 ± 225.122
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -589.514 | Total reward: -589.514
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -1023.275 | Total reward: -1023.275
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -1180.363 | Total reward: -1180.363
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -1414.308 | Total reward: -1414.308
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -945.117 | Total reward: -945.117
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -1179.414 | Total reward: -1179.414
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -1263.859 | Total reward: -1263.859
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -1034.603 | Total reward: -1034.603
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -1080.338 | Total reward: -1080.338
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -786.026 | Total reward: -786.026
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -1049.682 ± 225.122
  Average reward: -1049.682 ± 225.122
  Total reward: -1049.682 ± 225.122
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -1049.682
Rule-based avg reward: -1049.682
No control avg reward: -1049.682
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
