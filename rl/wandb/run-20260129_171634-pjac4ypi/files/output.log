Iteration 0: 100%|██████████| 10/10 [00:14<00:00,  1.42s/it, episode=10, norm_ret=-9.420, true_ret=-283220768.000, steps=300]
Agent gate_2 episode reward: [-80.17066514]
All agents episode reward: [-80.17066514]
Agent gate_2 episode reward: [-2.84940143]
All agents episode reward: [-2.84940143]
Agent gate_2 episode reward: [-2.00870965]
All agents episode reward: [-2.00870965]
Agent gate_2 episode reward: [-7.14279157]
All agents episode reward: [-7.14279157]
Agent gate_2 episode reward: [-1.02893557]
All agents episode reward: [-1.02893557]
Agent gate_2 episode reward: [-0.40060222]
All agents episode reward: [-0.40060222]
Agent gate_2 episode reward: [-0.20296105]
All agents episode reward: [-0.20296105]
Agent gate_2 episode reward: [-0.11171479]
All agents episode reward: [-0.11171479]
Agent gate_2 episode reward: [-0.1594333]
All agents episode reward: [-0.1594333]
Agent gate_2 episode reward: [-0.12464503]
All agents episode reward: [-0.12464503]
Iteration 1: 100%|██████████| 10/10 [00:13<00:00,  1.39s/it, episode=20, norm_ret=-0.156, true_ret=-314121920.000, steps=300]
Agent gate_2 episode reward: [-0.14389795]
All agents episode reward: [-0.14389795]
Agent gate_2 episode reward: [-0.14594389]
All agents episode reward: [-0.14594389]
Agent gate_2 episode reward: [-0.15246925]
All agents episode reward: [-0.15246925]
Agent gate_2 episode reward: [-0.14750912]
All agents episode reward: [-0.14750912]
Agent gate_2 episode reward: [-0.15567429]
All agents episode reward: [-0.15567429]
Agent gate_2 episode reward: [-0.1449605]
All agents episode reward: [-0.1449605]
Agent gate_2 episode reward: [-0.16055303]
All agents episode reward: [-0.16055303]
Agent gate_2 episode reward: [-0.16245283]
All agents episode reward: [-0.16245283]
Agent gate_2 episode reward: [-0.16602053]
All agents episode reward: [-0.16602053]
Agent gate_2 episode reward: [-0.18531128]
All agents episode reward: [-0.18531128]
Iteration 2: 100%|██████████| 10/10 [00:14<00:00,  1.45s/it, episode=30, norm_ret=-0.192, true_ret=-287413504.000, steps=300]
Agent gate_2 episode reward: [-0.17236047]
All agents episode reward: [-0.17236047]
Agent gate_2 episode reward: [-0.1882504]
All agents episode reward: [-0.1882504]
Agent gate_2 episode reward: [-0.18648866]
All agents episode reward: [-0.18648866]
Agent gate_2 episode reward: [-0.18784056]
All agents episode reward: [-0.18784056]
Agent gate_2 episode reward: [-0.17926168]
All agents episode reward: [-0.17926168]
Agent gate_2 episode reward: [-0.20846741]
All agents episode reward: [-0.20846741]
Agent gate_2 episode reward: [-0.19686284]
All agents episode reward: [-0.19686284]
Agent gate_2 episode reward: [-0.19053974]
All agents episode reward: [-0.19053974]
Agent gate_2 episode reward: [-0.20261097]
All agents episode reward: [-0.20261097]
Agent gate_2 episode reward: [-0.2043849]
All agents episode reward: [-0.2043849]
Iteration 3: 100%|██████████| 10/10 [00:13<00:00,  1.37s/it, episode=40, norm_ret=-0.226, true_ret=-305616640.000, steps=300]
Agent gate_2 episode reward: [-0.21261051]
All agents episode reward: [-0.21261051]
Agent gate_2 episode reward: [-0.2061143]
All agents episode reward: [-0.2061143]
Agent gate_2 episode reward: [-0.22643681]
All agents episode reward: [-0.22643681]
Agent gate_2 episode reward: [-0.22663922]
All agents episode reward: [-0.22663922]
Agent gate_2 episode reward: [-0.21062258]
All agents episode reward: [-0.21062258]
Agent gate_2 episode reward: [-0.23359948]
All agents episode reward: [-0.23359948]
Agent gate_2 episode reward: [-0.23357563]
All agents episode reward: [-0.23357563]
Agent gate_2 episode reward: [-0.22673485]
All agents episode reward: [-0.22673485]
Agent gate_2 episode reward: [-0.23283167]
All agents episode reward: [-0.23283167]
Agent gate_2 episode reward: [-0.2489273]
All agents episode reward: [-0.2489273]
Iteration 4: 100%|██████████| 10/10 [00:13<00:00,  1.38s/it, episode=50, norm_ret=-0.257, true_ret=-292409632.000, steps=300]
Agent gate_2 episode reward: [-0.23635117]
All agents episode reward: [-0.23635117]
Agent gate_2 episode reward: [-0.26008248]
All agents episode reward: [-0.26008248]
Agent gate_2 episode reward: [-0.25181558]
All agents episode reward: [-0.25181558]
Agent gate_2 episode reward: [-0.24057294]
All agents episode reward: [-0.24057294]
Agent gate_2 episode reward: [-0.25174658]
All agents episode reward: [-0.25174658]
Agent gate_2 episode reward: [-0.24779826]
All agents episode reward: [-0.24779826]
Agent gate_2 episode reward: [-0.2449517]
All agents episode reward: [-0.2449517]
Agent gate_2 episode reward: [-0.25873902]
All agents episode reward: [-0.25873902]
Agent gate_2 episode reward: [-0.31377771]
All agents episode reward: [-0.31377771]
Agent gate_2 episode reward: [-0.26504213]
All agents episode reward: [-0.26504213]
Iteration 5: 100%|██████████| 10/10 [00:13<00:00,  1.39s/it, episode=60, norm_ret=-0.279, true_ret=-290504288.000, steps=300]
Agent gate_2 episode reward: [-0.2602702]
All agents episode reward: [-0.2602702]
Agent gate_2 episode reward: [-0.27262375]
All agents episode reward: [-0.27262375]
Agent gate_2 episode reward: [-0.25910811]
All agents episode reward: [-0.25910811]
Agent gate_2 episode reward: [-0.28399554]
All agents episode reward: [-0.28399554]
Saved 1 agents to ppo_agents_butterfly_scC
New best average return achieved: -0.281 at episode 55 (saved all agents to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.28105212]
All agents episode reward: [-0.28105212]
Agent gate_2 episode reward: [-0.29980045]
All agents episode reward: [-0.29980045]
Agent gate_2 episode reward: [-0.27502872]
All agents episode reward: [-0.27502872]
Agent gate_2 episode reward: [-0.29261816]
All agents episode reward: [-0.29261816]
Agent gate_2 episode reward: [-0.28269987]
All agents episode reward: [-0.28269987]
Agent gate_2 episode reward: [-0.28757491]
All agents episode reward: [-0.28757491]
Iteration 6: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it, episode=70, norm_ret=-0.306, true_ret=-289003904.000, steps=300]
Agent gate_2 episode reward: [-0.29203961]
All agents episode reward: [-0.29203961]
Agent gate_2 episode reward: [-0.31497218]
All agents episode reward: [-0.31497218]
Agent gate_2 episode reward: [-0.3156957]
All agents episode reward: [-0.3156957]
Agent gate_2 episode reward: [-0.31284951]
All agents episode reward: [-0.31284951]
Agent gate_2 episode reward: [-0.29831788]
All agents episode reward: [-0.29831788]
Agent gate_2 episode reward: [-0.30228611]
All agents episode reward: [-0.30228611]
Agent gate_2 episode reward: [-0.31482648]
All agents episode reward: [-0.31482648]
Agent gate_2 episode reward: [-0.27791784]
All agents episode reward: [-0.27791784]
Agent gate_2 episode reward: [-0.31893105]
All agents episode reward: [-0.31893105]
Agent gate_2 episode reward: [-0.30831569]
All agents episode reward: [-0.30831569]
Iteration 7: 100%|██████████| 10/10 [00:13<00:00,  1.40s/it, episode=80, norm_ret=-0.323, true_ret=-282452480.000, steps=300]
Agent gate_2 episode reward: [-0.3042084]
All agents episode reward: [-0.3042084]
Agent gate_2 episode reward: [-0.32097891]
All agents episode reward: [-0.32097891]
Agent gate_2 episode reward: [-0.31291026]
All agents episode reward: [-0.31291026]
Agent gate_2 episode reward: [-0.30924904]
All agents episode reward: [-0.30924904]
Agent gate_2 episode reward: [-0.34762485]
All agents episode reward: [-0.34762485]
Agent gate_2 episode reward: [-0.31749368]
All agents episode reward: [-0.31749368]
Agent gate_2 episode reward: [-0.32375396]
All agents episode reward: [-0.32375396]
Agent gate_2 episode reward: [-0.31977809]
All agents episode reward: [-0.31977809]
Agent gate_2 episode reward: [-0.34860071]
All agents episode reward: [-0.34860071]
Agent gate_2 episode reward: [-0.32158304]
All agents episode reward: [-0.32158304]
Iteration 8: 100%|██████████| 10/10 [00:14<00:00,  1.49s/it, episode=90, norm_ret=-0.353, true_ret=-317741536.000, steps=300]
Agent gate_2 episode reward: [-0.30752017]
All agents episode reward: [-0.30752017]
Agent gate_2 episode reward: [-0.34315452]
All agents episode reward: [-0.34315452]
Agent gate_2 episode reward: [-0.32958708]
All agents episode reward: [-0.32958708]
Agent gate_2 episode reward: [-0.34410283]
All agents episode reward: [-0.34410283]
Agent gate_2 episode reward: [-0.36830123]
All agents episode reward: [-0.36830123]
Agent gate_2 episode reward: [-0.36655667]
All agents episode reward: [-0.36655667]
Agent gate_2 episode reward: [-0.38386785]
All agents episode reward: [-0.38386785]
Agent gate_2 episode reward: [-0.3494834]
All agents episode reward: [-0.3494834]
Agent gate_2 episode reward: [-0.3545252]
All agents episode reward: [-0.3545252]
Agent gate_2 episode reward: [-0.38317957]
All agents episode reward: [-0.38317957]
Iteration 9: 100%|██████████| 10/10 [00:13<00:00,  1.36s/it, episode=100, norm_ret=-0.362, true_ret=-291698400.000, steps=300]
Agent gate_2 episode reward: [-0.3604782]
All agents episode reward: [-0.3604782]
Agent gate_2 episode reward: [-0.36563275]
All agents episode reward: [-0.36563275]
Agent gate_2 episode reward: [-0.35139986]
All agents episode reward: [-0.35139986]
Agent gate_2 episode reward: [-0.35732789]
All agents episode reward: [-0.35732789]
Agent gate_2 episode reward: [-0.34643849]
All agents episode reward: [-0.34643849]
Agent gate_2 episode reward: [-0.35388773]
All agents episode reward: [-0.35388773]
Agent gate_2 episode reward: [-0.36032958]
All agents episode reward: [-0.36032958]
Agent gate_2 episode reward: [-0.38821463]
All agents episode reward: [-0.38821463]
Agent gate_2 episode reward: [-0.36503995]
All agents episode reward: [-0.36503995]
Agent gate_2 episode reward: [-0.37039336]
All agents episode reward: [-0.37039336]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -212225136.000 | Total reward: -212225136.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81044008.000
  Average reward: -377885472.000 ± 81044008.000
  Total reward: -377885472.000 ± 81044008.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -212225152.000 | Total reward: -212225152.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -368378912.000 | Total reward: -368378912.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -424930752.000 | Total reward: -424930752.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -509151168.000 | Total reward: -509151168.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -340242176.000 | Total reward: -340242176.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -424588992.000 | Total reward: -424588992.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -454989248.000 | Total reward: -454989248.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -372457120.000 | Total reward: -372457120.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -388921760.000 | Total reward: -388921760.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81043944.000
  Average reward: -377885472.000 ± 81043944.000
  Total reward: -377885472.000 ± 81043944.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -212225152.000 | Total reward: -212225152.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -368378912.000 | Total reward: -368378912.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -424930752.000 | Total reward: -424930752.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -509151168.000 | Total reward: -509151168.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -340242176.000 | Total reward: -340242176.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -424588992.000 | Total reward: -424588992.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -454989248.000 | Total reward: -454989248.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -372457120.000 | Total reward: -372457120.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -388921760.000 | Total reward: -388921760.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81043944.000
  Average reward: -377885472.000 ± 81043944.000
  Total reward: -377885472.000 ± 81043944.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -377885472.000
Rule-based avg reward: -377885472.000
No control avg reward: -377885472.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
