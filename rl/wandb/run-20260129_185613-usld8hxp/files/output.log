Iteration 0: 100%|██████████| 10/10 [00:23<00:00,  2.36s/it, episode=10, norm_ret=-14.615, true_ret=-1152953600.000, steps=600]
Agent gate_2 episode reward: [-95.69392338]
All agents episode reward: [-95.69392338]
Agent gate_2 episode reward: [-6.83903685]
All agents episode reward: [-6.83903685]
Agent gate_2 episode reward: [-16.43199921]
All agents episode reward: [-16.43199921]
Agent gate_2 episode reward: [-9.55559928]
All agents episode reward: [-9.55559928]
Agent gate_2 episode reward: [-3.58327508]
All agents episode reward: [-3.58327508]
Agent gate_2 episode reward: [-5.8507672]
All agents episode reward: [-5.8507672]
Agent gate_2 episode reward: [-1.86199351]
All agents episode reward: [-1.86199351]
Agent gate_2 episode reward: [-2.91607164]
All agents episode reward: [-2.91607164]
Agent gate_2 episode reward: [-2.80432546]
All agents episode reward: [-2.80432546]
Agent gate_2 episode reward: [-0.61690388]
All agents episode reward: [-0.61690388]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it, episode=20, norm_ret=-0.185, true_ret=-301808224.000, steps=600]
Agent gate_2 episode reward: [-0.2087361]
All agents episode reward: [-0.2087361]
Agent gate_2 episode reward: [-0.18088391]
All agents episode reward: [-0.18088391]
Agent gate_2 episode reward: [-0.17138967]
All agents episode reward: [-0.17138967]
Agent gate_2 episode reward: [-0.1769796]
All agents episode reward: [-0.1769796]
Agent gate_2 episode reward: [-0.18413499]
All agents episode reward: [-0.18413499]
Agent gate_2 episode reward: [-0.18284832]
All agents episode reward: [-0.18284832]
Agent gate_2 episode reward: [-0.17568725]
All agents episode reward: [-0.17568725]
Agent gate_2 episode reward: [-0.19672234]
All agents episode reward: [-0.19672234]
Agent gate_2 episode reward: [-0.17356205]
All agents episode reward: [-0.17356205]
Agent gate_2 episode reward: [-0.20074749]
All agents episode reward: [-0.20074749]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.32s/it, episode=30, norm_ret=-0.220, true_ret=-289870592.000, steps=600]
Agent gate_2 episode reward: [-0.1868942]
All agents episode reward: [-0.1868942]
Agent gate_2 episode reward: [-0.21319977]
All agents episode reward: [-0.21319977]
Agent gate_2 episode reward: [-0.2381355]
All agents episode reward: [-0.2381355]
Agent gate_2 episode reward: [-0.24402363]
All agents episode reward: [-0.24402363]
Agent gate_2 episode reward: [-0.2198636]
All agents episode reward: [-0.2198636]
Agent gate_2 episode reward: [-0.20706679]
All agents episode reward: [-0.20706679]
Agent gate_2 episode reward: [-0.20560799]
All agents episode reward: [-0.20560799]
Agent gate_2 episode reward: [-0.20258277]
All agents episode reward: [-0.20258277]
Agent gate_2 episode reward: [-0.25241645]
All agents episode reward: [-0.25241645]
Agent gate_2 episode reward: [-0.22808432]
All agents episode reward: [-0.22808432]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it, episode=40, norm_ret=-0.333, true_ret=-327352320.000, steps=600]
Agent gate_2 episode reward: [-0.23286117]
All agents episode reward: [-0.23286117]
Agent gate_2 episode reward: [-1.07308153]
All agents episode reward: [-1.07308153]
Agent gate_2 episode reward: [-0.22459606]
All agents episode reward: [-0.22459606]
Agent gate_2 episode reward: [-0.23999556]
All agents episode reward: [-0.23999556]
Agent gate_2 episode reward: [-0.25461936]
All agents episode reward: [-0.25461936]
Agent gate_2 episode reward: [-0.27218289]
All agents episode reward: [-0.27218289]
Agent gate_2 episode reward: [-0.25561391]
All agents episode reward: [-0.25561391]
Agent gate_2 episode reward: [-0.24212961]
All agents episode reward: [-0.24212961]
Agent gate_2 episode reward: [-0.24368247]
All agents episode reward: [-0.24368247]
Agent gate_2 episode reward: [-0.29268771]
All agents episode reward: [-0.29268771]
Iteration 4: 100%|██████████| 10/10 [00:22<00:00,  2.24s/it, episode=50, norm_ret=-0.369, true_ret=-573431040.000, steps=600]
Agent gate_2 episode reward: [-0.27669821]
All agents episode reward: [-0.27669821]
Agent gate_2 episode reward: [-0.33078168]
All agents episode reward: [-0.33078168]
Agent gate_2 episode reward: [-0.36260694]
All agents episode reward: [-0.36260694]
Agent gate_2 episode reward: [-0.32397528]
All agents episode reward: [-0.32397528]
Agent gate_2 episode reward: [-0.40670231]
All agents episode reward: [-0.40670231]
Agent gate_2 episode reward: [-0.28968298]
All agents episode reward: [-0.28968298]
Agent gate_2 episode reward: [-0.30460744]
All agents episode reward: [-0.30460744]
Agent gate_2 episode reward: [-0.41799434]
All agents episode reward: [-0.41799434]
Agent gate_2 episode reward: [-0.41305366]
All agents episode reward: [-0.41305366]
Agent gate_2 episode reward: [-0.56802695]
All agents episode reward: [-0.56802695]
Iteration 5: 100%|██████████| 10/10 [00:30<00:00,  3.05s/it, episode=60, norm_ret=-0.561, true_ret=-571725184.000, steps=600]
Agent gate_2 episode reward: [-0.43254392]
All agents episode reward: [-0.43254392]
Agent gate_2 episode reward: [-0.42342258]
All agents episode reward: [-0.42342258]
Agent gate_2 episode reward: [-0.69111818]
All agents episode reward: [-0.69111818]
Agent gate_2 episode reward: [-0.39712146]
All agents episode reward: [-0.39712146]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -1098537984.000 at episode 55 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.36371075]
All agents episode reward: [-0.36371075]
Agent gate_2 episode reward: [-0.72068297]
All agents episode reward: [-0.72068297]
Agent gate_2 episode reward: [-0.65610637]
All agents episode reward: [-0.65610637]
Agent gate_2 episode reward: [-0.64981847]
All agents episode reward: [-0.64981847]
Agent gate_2 episode reward: [-0.63557687]
All agents episode reward: [-0.63557687]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -321791808.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.64070801]
All agents episode reward: [-0.64070801]
Iteration 6: 100%|██████████| 10/10 [00:29<00:00,  2.99s/it, episode=70, norm_ret=-0.407, true_ret=-240034528.000, steps=600]
Agent gate_2 episode reward: [-0.47021511]
All agents episode reward: [-0.47021511]
Agent gate_2 episode reward: [-0.48999164]
All agents episode reward: [-0.48999164]
Agent gate_2 episode reward: [-0.5575496]
All agents episode reward: [-0.5575496]
Agent gate_2 episode reward: [-0.50393734]
All agents episode reward: [-0.50393734]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -298547520.000 at episode 65 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.51656077]
All agents episode reward: [-0.51656077]
Agent gate_2 episode reward: [-0.31006643]
All agents episode reward: [-0.31006643]
Agent gate_2 episode reward: [-0.32516126]
All agents episode reward: [-0.32516126]
Agent gate_2 episode reward: [-0.30839859]
All agents episode reward: [-0.30839859]
Agent gate_2 episode reward: [-0.28178829]
All agents episode reward: [-0.28178829]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -265264032.000 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.30534134]
All agents episode reward: [-0.30534134]
Iteration 7: 100%|██████████| 10/10 [00:30<00:00,  3.02s/it, episode=80, norm_ret=-0.486, true_ret=-360737920.000, steps=600]
Agent gate_2 episode reward: [-0.49036473]
All agents episode reward: [-0.49036473]
Agent gate_2 episode reward: [-0.47523078]
All agents episode reward: [-0.47523078]
Agent gate_2 episode reward: [-0.48185428]
All agents episode reward: [-0.48185428]
Agent gate_2 episode reward: [-0.50492536]
All agents episode reward: [-0.50492536]
Agent gate_2 episode reward: [-0.48803304]
All agents episode reward: [-0.48803304]
Agent gate_2 episode reward: [-0.47375372]
All agents episode reward: [-0.47375372]
Agent gate_2 episode reward: [-0.43765679]
All agents episode reward: [-0.43765679]
Agent gate_2 episode reward: [-0.49269139]
All agents episode reward: [-0.49269139]
Agent gate_2 episode reward: [-0.50358018]
All agents episode reward: [-0.50358018]
Agent gate_2 episode reward: [-0.50761736]
All agents episode reward: [-0.50761736]
Iteration 8: 100%|██████████| 10/10 [00:29<00:00,  2.99s/it, episode=90, norm_ret=-0.280, true_ret=-68325312.000, steps=600]
Agent gate_2 episode reward: [-0.45810052]
All agents episode reward: [-0.45810052]
Agent gate_2 episode reward: [-0.58604723]
All agents episode reward: [-0.58604723]
Agent gate_2 episode reward: [-0.49349668]
All agents episode reward: [-0.49349668]
Agent gate_2 episode reward: [-0.39071971]
All agents episode reward: [-0.39071971]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -256082304.000 at episode 85 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.46607764]
All agents episode reward: [-0.46607764]
Agent gate_2 episode reward: [-0.07503572]
All agents episode reward: [-0.07503572]
Agent gate_2 episode reward: [-0.07879805]
All agents episode reward: [-0.07879805]
Agent gate_2 episode reward: [-0.06257567]
All agents episode reward: [-0.06257567]
Agent gate_2 episode reward: [-0.08351944]
All agents episode reward: [-0.08351944]
Agent gate_2 episode reward: [-0.10454863]
All agents episode reward: [-0.10454863]
Iteration 9: 100%|██████████| 10/10 [00:30<00:00,  3.04s/it, episode=100, norm_ret=-0.394, true_ret=-156090992.000, steps=600]
Agent gate_2 episode reward: [-0.5369019]
All agents episode reward: [-0.5369019]
Agent gate_2 episode reward: [-0.51328525]
All agents episode reward: [-0.51328525]
Agent gate_2 episode reward: [-0.58662834]
All agents episode reward: [-0.58662834]
Agent gate_2 episode reward: [-0.50591666]
All agents episode reward: [-0.50591666]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -226451504.000 at episode 95 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.56707967]
All agents episode reward: [-0.56707967]
Agent gate_2 episode reward: [-0.23097477]
All agents episode reward: [-0.23097477]
Agent gate_2 episode reward: [-0.26667901]
All agents episode reward: [-0.26667901]
Agent gate_2 episode reward: [-0.25388183]
All agents episode reward: [-0.25388183]
Agent gate_2 episode reward: [-0.22448442]
All agents episode reward: [-0.22448442]
Agent gate_2 episode reward: [-0.25646175]
All agents episode reward: [-0.25646175]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -267465152.000 | Total reward: -267465152.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -411166144.000 | Total reward: -411166144.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -464834944.000 | Total reward: -464834944.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -593797568.000 | Total reward: -593797568.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -391783744.000 | Total reward: -391783744.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -453057728.000 | Total reward: -453057728.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -511425312.000 | Total reward: -511425312.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -426712928.000 | Total reward: -426712928.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -431882496.000 | Total reward: -431882496.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -282738656.000 | Total reward: -282738656.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -423486496.000 ± 92040000.000
  Average reward: -423486496.000 ± 92040000.000
  Total reward: -423486496.000 ± 92040000.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -407377344.000 | Total reward: -407377344.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -724314624.000 | Total reward: -724314624.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -805422336.000 | Total reward: -805422336.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1174821632.000 | Total reward: -1174821632.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1778629607424.000 | Total reward: -1778629607424.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -791052160.000 | Total reward: -791052160.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -822285120.000 | Total reward: -822285120.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2202740457472.000 | Total reward: -2202740457472.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -744597440.000 | Total reward: -744597440.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -499645216.000 | Total reward: -499645216.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -398733934592.000 ± 801605025792.000
  Average reward: -398733934592.000 ± 801605025792.000
  Total reward: -398733934592.000 ± 801605025792.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -212225136.000 | Total reward: -212225136.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81044008.000
  Average reward: -377885472.000 ± 81044008.000
  Total reward: -377885472.000 ± 81044008.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -423486496.000
Rule-based avg reward: -398733934592.000
No control avg reward: -377885472.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
