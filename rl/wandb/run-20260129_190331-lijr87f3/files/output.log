Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it, episode=10, norm_ret=-13.895, true_ret=-917067392.000, steps=600]
Agent gate_2 episode reward: [-95.69392338]
All agents episode reward: [-95.69392338]
Agent gate_2 episode reward: [-9.07059595]
All agents episode reward: [-9.07059595]
Agent gate_2 episode reward: [-13.22684235]
All agents episode reward: [-13.22684235]
Agent gate_2 episode reward: [-6.9114321]
All agents episode reward: [-6.9114321]
Agent gate_2 episode reward: [-2.99227844]
All agents episode reward: [-2.99227844]
Agent gate_2 episode reward: [-3.89324964]
All agents episode reward: [-3.89324964]
Agent gate_2 episode reward: [-2.07156153]
All agents episode reward: [-2.07156153]
Agent gate_2 episode reward: [-1.56764682]
All agents episode reward: [-1.56764682]
Agent gate_2 episode reward: [-2.92641348]
All agents episode reward: [-2.92641348]
Agent gate_2 episode reward: [-0.59270365]
All agents episode reward: [-0.59270365]
Iteration 1: 100%|██████████| 10/10 [00:24<00:00,  2.44s/it, episode=20, norm_ret=-0.223, true_ret=-1690.363, steps=600]
Agent gate_2 episode reward: [-0.15159157]
All agents episode reward: [-0.15159157]
Agent gate_2 episode reward: [-0.40663103]
All agents episode reward: [-0.40663103]
Agent gate_2 episode reward: [-0.28703656]
All agents episode reward: [-0.28703656]
Agent gate_2 episode reward: [-0.20924073]
All agents episode reward: [-0.20924073]
Agent gate_2 episode reward: [-0.22239791]
All agents episode reward: [-0.22239791]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-0.38042495]
All agents episode reward: [-0.38042495]
Agent gate_2 episode reward: [-0.19329192]
All agents episode reward: [-0.19329192]
Agent gate_2 episode reward: [-0.37457163]
All agents episode reward: [-0.37457163]
Agent gate_2 episode reward: [-1.37823321e-06]
All agents episode reward: [-1.37823321e-06]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.38s/it, episode=30, norm_ret=-0.184, true_ret=-4321959.500, steps=600]
Agent gate_2 episode reward: [-1.65284251e-05]
All agents episode reward: [-1.65284251e-05]
Agent gate_2 episode reward: [-0.00322207]
All agents episode reward: [-0.00322207]
Agent gate_2 episode reward: [-0.21359529]
All agents episode reward: [-0.21359529]
Agent gate_2 episode reward: [-0.42992926]
All agents episode reward: [-0.42992926]
Agent gate_2 episode reward: [-0.39392371]
All agents episode reward: [-0.39392371]
Agent gate_2 episode reward: [-0.00310828]
All agents episode reward: [-0.00310828]
Agent gate_2 episode reward: [-0.28238092]
All agents episode reward: [-0.28238092]
Agent gate_2 episode reward: [-0.50768532]
All agents episode reward: [-0.50768532]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-0.00417496]
All agents episode reward: [-0.00417496]
Iteration 3: 100%|██████████| 10/10 [00:23<00:00,  2.34s/it, episode=40, norm_ret=-0.350, true_ret=-351675840.000, steps=600]
Agent gate_2 episode reward: [-0.00289552]
All agents episode reward: [-0.00289552]
Agent gate_2 episode reward: [-0.79907579]
All agents episode reward: [-0.79907579]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-0.42915475]
All agents episode reward: [-0.42915475]
Agent gate_2 episode reward: [-0.10918772]
All agents episode reward: [-0.10918772]
Agent gate_2 episode reward: [-0.55573511]
All agents episode reward: [-0.55573511]
Agent gate_2 episode reward: [-0.44125912]
All agents episode reward: [-0.44125912]
Agent gate_2 episode reward: [-0.45384528]
All agents episode reward: [-0.45384528]
Agent gate_2 episode reward: [-0.31949735]
All agents episode reward: [-0.31949735]
Agent gate_2 episode reward: [-0.3852687]
All agents episode reward: [-0.3852687]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.30s/it, episode=50, norm_ret=-0.501, true_ret=-289205504.000, steps=600]
Agent gate_2 episode reward: [-0.30998613]
All agents episode reward: [-0.30998613]
Agent gate_2 episode reward: [-0.43609561]
All agents episode reward: [-0.43609561]
Agent gate_2 episode reward: [-0.47639003]
All agents episode reward: [-0.47639003]
Agent gate_2 episode reward: [-1.14382163]
All agents episode reward: [-1.14382163]
Agent gate_2 episode reward: [-0.87975721]
All agents episode reward: [-0.87975721]
Agent gate_2 episode reward: [-0.55805879]
All agents episode reward: [-0.55805879]
Agent gate_2 episode reward: [-0.32843837]
All agents episode reward: [-0.32843837]
Agent gate_2 episode reward: [-0.01575498]
All agents episode reward: [-0.01575498]
Agent gate_2 episode reward: [-0.50529911]
All agents episode reward: [-0.50529911]
Agent gate_2 episode reward: [-0.3515757]
All agents episode reward: [-0.3515757]
Iteration 5: 100%|██████████| 10/10 [00:30<00:00,  3.03s/it, episode=60, norm_ret=-0.624, true_ret=-137222592.000, steps=600]
Agent gate_2 episode reward: [-0.29192272]
All agents episode reward: [-0.29192272]
Agent gate_2 episode reward: [-1.11379015]
All agents episode reward: [-1.11379015]
Agent gate_2 episode reward: [-1.3059107]
All agents episode reward: [-1.3059107]
Agent gate_2 episode reward: [-0.53601316]
All agents episode reward: [-0.53601316]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -340570240.000 at episode 55 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.69708463]
All agents episode reward: [-0.69708463]
Agent gate_2 episode reward: [-0.80720574]
All agents episode reward: [-0.80720574]
Agent gate_2 episode reward: [-0.4680998]
All agents episode reward: [-0.4680998]
Agent gate_2 episode reward: [-0.29665714]
All agents episode reward: [-0.29665714]
Agent gate_2 episode reward: [-0.53028536]
All agents episode reward: [-0.53028536]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -238424704.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.18849358]
All agents episode reward: [-0.18849358]
Iteration 6: 100%|██████████| 10/10 [00:31<00:00,  3.19s/it, episode=70, norm_ret=-0.514, true_ret=-294159904.000, steps=600]
Agent gate_2 episode reward: [-0.17756476]
All agents episode reward: [-0.17756476]
Agent gate_2 episode reward: [-0.71575671]
All agents episode reward: [-0.71575671]
Agent gate_2 episode reward: [-0.7851728]
All agents episode reward: [-0.7851728]
Agent gate_2 episode reward: [-0.65708989]
All agents episode reward: [-0.65708989]
Agent gate_2 episode reward: [-0.42330078]
All agents episode reward: [-0.42330078]
Agent gate_2 episode reward: [-0.60188275]
All agents episode reward: [-0.60188275]
Agent gate_2 episode reward: [-0.27926387]
All agents episode reward: [-0.27926387]
Agent gate_2 episode reward: [-0.52365538]
All agents episode reward: [-0.52365538]
Agent gate_2 episode reward: [-0.52053533]
All agents episode reward: [-0.52053533]
Agent gate_2 episode reward: [-0.45914343]
All agents episode reward: [-0.45914343]
Iteration 7: 100%|██████████| 10/10 [00:30<00:00,  3.03s/it, episode=80, norm_ret=-0.572, true_ret=-321374976.000, steps=600]
Agent gate_2 episode reward: [-0.07390336]
All agents episode reward: [-0.07390336]
Agent gate_2 episode reward: [-0.58925589]
All agents episode reward: [-0.58925589]
Agent gate_2 episode reward: [-0.63790436]
All agents episode reward: [-0.63790436]
Agent gate_2 episode reward: [-0.75619791]
All agents episode reward: [-0.75619791]
Agent gate_2 episode reward: [-0.24302059]
All agents episode reward: [-0.24302059]
Agent gate_2 episode reward: [-0.81169049]
All agents episode reward: [-0.81169049]
Agent gate_2 episode reward: [-0.43790323]
All agents episode reward: [-0.43790323]
Agent gate_2 episode reward: [-0.65100665]
All agents episode reward: [-0.65100665]
Agent gate_2 episode reward: [-0.96087013]
All agents episode reward: [-0.96087013]
Agent gate_2 episode reward: [-0.55501269]
All agents episode reward: [-0.55501269]
Iteration 8: 100%|██████████| 10/10 [00:31<00:00,  3.12s/it, episode=90, norm_ret=-0.646, true_ret=-328931040.000, steps=600]
Agent gate_2 episode reward: [-0.00996892]
All agents episode reward: [-0.00996892]
Agent gate_2 episode reward: [-0.47290043]
All agents episode reward: [-0.47290043]
Agent gate_2 episode reward: [-0.84360615]
All agents episode reward: [-0.84360615]
Agent gate_2 episode reward: [-0.58845874]
All agents episode reward: [-0.58845874]
Agent gate_2 episode reward: [-1.00862694]
All agents episode reward: [-1.00862694]
Agent gate_2 episode reward: [-0.18659463]
All agents episode reward: [-0.18659463]
Agent gate_2 episode reward: [-1.1062694]
All agents episode reward: [-1.1062694]
Agent gate_2 episode reward: [-1.09403124]
All agents episode reward: [-1.09403124]
Agent gate_2 episode reward: [-0.53241796]
All agents episode reward: [-0.53241796]
Agent gate_2 episode reward: [-0.61798145]
All agents episode reward: [-0.61798145]
Iteration 9: 100%|██████████| 10/10 [00:30<00:00,  3.01s/it, episode=100, norm_ret=-0.808, true_ret=-298854432.000, steps=600]
Agent gate_2 episode reward: [-0.20075927]
All agents episode reward: [-0.20075927]
Agent gate_2 episode reward: [-1.13145987]
All agents episode reward: [-1.13145987]
Agent gate_2 episode reward: [-1.12573951]
All agents episode reward: [-1.12573951]
Agent gate_2 episode reward: [-0.61259114]
All agents episode reward: [-0.61259114]
Agent gate_2 episode reward: [-0.94733632]
All agents episode reward: [-0.94733632]
Agent gate_2 episode reward: [-0.77567201]
All agents episode reward: [-0.77567201]
Agent gate_2 episode reward: [-1.01228911]
All agents episode reward: [-1.01228911]
Agent gate_2 episode reward: [-1.06527269]
All agents episode reward: [-1.06527269]
Agent gate_2 episode reward: [-0.60438148]
All agents episode reward: [-0.60438148]
Agent gate_2 episode reward: [-0.60336176]
All agents episode reward: [-0.60336176]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -222840208.000 | Total reward: -222840208.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -424042784.000 | Total reward: -424042784.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -410551488.000 | Total reward: -410551488.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -589783232.000 | Total reward: -589783232.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -350407264.000 | Total reward: -350407264.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -439714848.000 | Total reward: -439714848.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -490336320.000 | Total reward: -490336320.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -392943200.000 | Total reward: -392943200.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -430767200.000 | Total reward: -430767200.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -263557744.000 | Total reward: -263557744.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -401494400.000 ± 99940280.000
  Average reward: -401494400.000 ± 99940280.000
  Total reward: -401494400.000 ± 99940280.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -407377344.000 | Total reward: -407377344.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -724314624.000 | Total reward: -724314624.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -805422336.000 | Total reward: -805422336.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1174821632.000 | Total reward: -1174821632.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1778629607424.000 | Total reward: -1778629607424.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -791052160.000 | Total reward: -791052160.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -822285120.000 | Total reward: -822285120.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2202740457472.000 | Total reward: -2202740457472.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -744597440.000 | Total reward: -744597440.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -499645216.000 | Total reward: -499645216.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -398733934592.000 ± 801605025792.000
  Average reward: -398733934592.000 ± 801605025792.000
  Total reward: -398733934592.000 ± 801605025792.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -212225136.000 | Total reward: -212225136.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81044008.000
  Average reward: -377885472.000 ± 81044008.000
  Total reward: -377885472.000 ± 81044008.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -401494400.000
Rule-based avg reward: -398733934592.000
No control avg reward: -377885472.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
