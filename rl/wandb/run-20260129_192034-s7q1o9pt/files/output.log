Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it, episode=10, norm_ret=-11.520, true_ret=-308980384.000, steps=600]
Agent gate_2 episode reward: [-75.78346819]
All agents episode reward: [-75.78346819]
Agent gate_2 episode reward: [-23.73359516]
All agents episode reward: [-23.73359516]
Agent gate_2 episode reward: [-3.75178693]
All agents episode reward: [-3.75178693]
Agent gate_2 episode reward: [-6.63615848]
All agents episode reward: [-6.63615848]
Agent gate_2 episode reward: [-0.98749336]
All agents episode reward: [-0.98749336]
Agent gate_2 episode reward: [-2.33501323]
All agents episode reward: [-2.33501323]
Agent gate_2 episode reward: [-0.45900919]
All agents episode reward: [-0.45900919]
Agent gate_2 episode reward: [-0.77292374]
All agents episode reward: [-0.77292374]
Agent gate_2 episode reward: [-0.33502341]
All agents episode reward: [-0.33502341]
Agent gate_2 episode reward: [-0.40301557]
All agents episode reward: [-0.40301557]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.30s/it, episode=20, norm_ret=-0.519, true_ret=-295098400.000, steps=600]
Agent gate_2 episode reward: [-0.52524557]
All agents episode reward: [-0.52524557]
Agent gate_2 episode reward: [-0.39677778]
All agents episode reward: [-0.39677778]
Agent gate_2 episode reward: [-0.78536965]
All agents episode reward: [-0.78536965]
Agent gate_2 episode reward: [-0.44662287]
All agents episode reward: [-0.44662287]
Agent gate_2 episode reward: [-0.50906255]
All agents episode reward: [-0.50906255]
Agent gate_2 episode reward: [-0.52426128]
All agents episode reward: [-0.52426128]
Agent gate_2 episode reward: [-0.49313423]
All agents episode reward: [-0.49313423]
Agent gate_2 episode reward: [-0.50232147]
All agents episode reward: [-0.50232147]
Agent gate_2 episode reward: [-0.48316411]
All agents episode reward: [-0.48316411]
Agent gate_2 episode reward: [-0.5199295]
All agents episode reward: [-0.5199295]
Iteration 2: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=30, norm_ret=-0.582, true_ret=-293820800.000, steps=600]
Agent gate_2 episode reward: [-0.50794885]
All agents episode reward: [-0.50794885]
Agent gate_2 episode reward: [-0.54120597]
All agents episode reward: [-0.54120597]
Agent gate_2 episode reward: [-0.53861294]
All agents episode reward: [-0.53861294]
Agent gate_2 episode reward: [-0.59111857]
All agents episode reward: [-0.59111857]
Agent gate_2 episode reward: [-0.53294503]
All agents episode reward: [-0.53294503]
Agent gate_2 episode reward: [-0.56739476]
All agents episode reward: [-0.56739476]
Agent gate_2 episode reward: [-0.66979228]
All agents episode reward: [-0.66979228]
Agent gate_2 episode reward: [-0.58989143]
All agents episode reward: [-0.58989143]
Agent gate_2 episode reward: [-0.65527196]
All agents episode reward: [-0.65527196]
Agent gate_2 episode reward: [-0.62487219]
All agents episode reward: [-0.62487219]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=40, norm_ret=-0.839, true_ret=-298530464.000, steps=600]
Agent gate_2 episode reward: [-0.95657741]
All agents episode reward: [-0.95657741]
Agent gate_2 episode reward: [-0.6186028]
All agents episode reward: [-0.6186028]
Agent gate_2 episode reward: [-0.71916019]
All agents episode reward: [-0.71916019]
Agent gate_2 episode reward: [-1.82625191]
All agents episode reward: [-1.82625191]
Agent gate_2 episode reward: [-0.6742002]
All agents episode reward: [-0.6742002]
Agent gate_2 episode reward: [-0.69608758]
All agents episode reward: [-0.69608758]
Agent gate_2 episode reward: [-0.6859317]
All agents episode reward: [-0.6859317]
Agent gate_2 episode reward: [-0.75447415]
All agents episode reward: [-0.75447415]
Agent gate_2 episode reward: [-0.72721048]
All agents episode reward: [-0.72721048]
Agent gate_2 episode reward: [-0.72707066]
All agents episode reward: [-0.72707066]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it, episode=50, norm_ret=-0.759, true_ret=-287370528.000, steps=600]
Agent gate_2 episode reward: [-0.71766072]
All agents episode reward: [-0.71766072]
Agent gate_2 episode reward: [-0.69991678]
All agents episode reward: [-0.69991678]
Agent gate_2 episode reward: [-0.71790362]
All agents episode reward: [-0.71790362]
Agent gate_2 episode reward: [-0.73523554]
All agents episode reward: [-0.73523554]
Agent gate_2 episode reward: [-0.78561352]
All agents episode reward: [-0.78561352]
Agent gate_2 episode reward: [-0.75145227]
All agents episode reward: [-0.75145227]
Agent gate_2 episode reward: [-0.74475674]
All agents episode reward: [-0.74475674]
Agent gate_2 episode reward: [-0.80361401]
All agents episode reward: [-0.80361401]
Agent gate_2 episode reward: [-0.85553932]
All agents episode reward: [-0.85553932]
Agent gate_2 episode reward: [-0.77857292]
All agents episode reward: [-0.77857292]
Iteration 5: 100%|██████████| 10/10 [00:32<00:00,  3.27s/it, episode=60, norm_ret=-0.759, true_ret=-244603616.000, steps=600]
Agent gate_2 episode reward: [-0.7995779]
All agents episode reward: [-0.7995779]
Agent gate_2 episode reward: [-0.86456535]
All agents episode reward: [-0.86456535]
Agent gate_2 episode reward: [-0.81756205]
All agents episode reward: [-0.81756205]
Agent gate_2 episode reward: [-0.81627165]
All agents episode reward: [-0.81627165]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -257437696.000 at episode 55 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.81298041]
All agents episode reward: [-0.81298041]
Agent gate_2 episode reward: [-0.67885777]
All agents episode reward: [-0.67885777]
Agent gate_2 episode reward: [-0.69002503]
All agents episode reward: [-0.69002503]
Agent gate_2 episode reward: [-0.69934242]
All agents episode reward: [-0.69934242]
Agent gate_2 episode reward: [-0.65644653]
All agents episode reward: [-0.65644653]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -234279936.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.75162008]
All agents episode reward: [-0.75162008]
Iteration 6: 100%|██████████| 10/10 [00:32<00:00,  3.21s/it, episode=70, norm_ret=-0.417, true_ret=-1008657.500, steps=600]
Agent gate_2 episode reward: [-0.82713906]
All agents episode reward: [-0.82713906]
Agent gate_2 episode reward: [-0.79553647]
All agents episode reward: [-0.79553647]
Agent gate_2 episode reward: [-0.8652202]
All agents episode reward: [-0.8652202]
Agent gate_2 episode reward: [-0.79436604]
All agents episode reward: [-0.79436604]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -183248896.000 at episode 65 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.83758025]
All agents episode reward: [-0.83758025]
Agent gate_2 episode reward: [-0.01013396]
All agents episode reward: [-0.01013396]
Agent gate_2 episode reward: [-0.00138333]
All agents episode reward: [-0.00138333]
Agent gate_2 episode reward: [-0.01072437]
All agents episode reward: [-0.01072437]
Agent gate_2 episode reward: [-0.02196997]
All agents episode reward: [-0.02196997]
Agent gate_2 episode reward: [-0.00351658]
All agents episode reward: [-0.00351658]
Iteration 7: 100%|██████████| 10/10 [00:31<00:00,  3.11s/it, episode=80, norm_ret=-1.529, true_ret=-304938816.000, steps=600]
Agent gate_2 episode reward: [-1.80359996]
All agents episode reward: [-1.80359996]
Agent gate_2 episode reward: [-1.89091195]
All agents episode reward: [-1.89091195]
Agent gate_2 episode reward: [-1.8304707]
All agents episode reward: [-1.8304707]
Agent gate_2 episode reward: [-1.79358531]
All agents episode reward: [-1.79358531]
Agent gate_2 episode reward: [-1.95798067]
All agents episode reward: [-1.95798067]
Agent gate_2 episode reward: [-1.24750583]
All agents episode reward: [-1.24750583]
Agent gate_2 episode reward: [-1.17965129]
All agents episode reward: [-1.17965129]
Agent gate_2 episode reward: [-1.14237446]
All agents episode reward: [-1.14237446]
Agent gate_2 episode reward: [-1.26851839]
All agents episode reward: [-1.26851839]
Agent gate_2 episode reward: [-1.17958069]
All agents episode reward: [-1.17958069]
Iteration 8: 100%|██████████| 10/10 [00:31<00:00,  3.16s/it, episode=90, norm_ret=-1.191, true_ret=-381942688.000, steps=600]
Agent gate_2 episode reward: [-0.76287737]
All agents episode reward: [-0.76287737]
Agent gate_2 episode reward: [-0.7356668]
All agents episode reward: [-0.7356668]
Agent gate_2 episode reward: [-0.95452911]
All agents episode reward: [-0.95452911]
Agent gate_2 episode reward: [-0.83585778]
All agents episode reward: [-0.83585778]
Agent gate_2 episode reward: [-0.78889035]
All agents episode reward: [-0.78889035]
Agent gate_2 episode reward: [-1.55377035]
All agents episode reward: [-1.55377035]
Agent gate_2 episode reward: [-1.52442099]
All agents episode reward: [-1.52442099]
Agent gate_2 episode reward: [-1.58510716]
All agents episode reward: [-1.58510716]
Agent gate_2 episode reward: [-1.56140612]
All agents episode reward: [-1.56140612]
Agent gate_2 episode reward: [-1.60795636]
All agents episode reward: [-1.60795636]
Iteration 9: 100%|██████████| 10/10 [00:30<00:00,  3.04s/it, episode=100, norm_ret=-0.877, true_ret=-359261088.000, steps=600]
Agent gate_2 episode reward: [-0.13384499]
All agents episode reward: [-0.13384499]
Agent gate_2 episode reward: [-0.13694411]
All agents episode reward: [-0.13694411]
Agent gate_2 episode reward: [-0.12954599]
All agents episode reward: [-0.12954599]
Agent gate_2 episode reward: [-0.13602519]
All agents episode reward: [-0.13602519]
Agent gate_2 episode reward: [-0.12789291]
All agents episode reward: [-0.12789291]
Agent gate_2 episode reward: [-1.62881278]
All agents episode reward: [-1.62881278]
Agent gate_2 episode reward: [-1.60995365]
All agents episode reward: [-1.60995365]
Agent gate_2 episode reward: [-1.61028786]
All agents episode reward: [-1.61028786]
Agent gate_2 episode reward: [-1.62949439]
All agents episode reward: [-1.62949439]
Agent gate_2 episode reward: [-1.62422873]
All agents episode reward: [-1.62422873]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -212225136.000 | Total reward: -212225136.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81044008.000
  Average reward: -377885472.000 ± 81044008.000
  Total reward: -377885472.000 ± 81044008.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -407377344.000 | Total reward: -407377344.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -724314624.000 | Total reward: -724314624.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -805422336.000 | Total reward: -805422336.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1174821632.000 | Total reward: -1174821632.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1778629607424.000 | Total reward: -1778629607424.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -791052160.000 | Total reward: -791052160.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -822285120.000 | Total reward: -822285120.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2202740457472.000 | Total reward: -2202740457472.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -744597440.000 | Total reward: -744597440.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -499645216.000 | Total reward: -499645216.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -398733934592.000 ± 801605025792.000
  Average reward: -398733934592.000 ± 801605025792.000
  Total reward: -398733934592.000 ± 801605025792.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -212225136.000 | Total reward: -212225136.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81044008.000
  Average reward: -377885472.000 ± 81044008.000
  Total reward: -377885472.000 ± 81044008.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -377885472.000
Rule-based avg reward: -398733934592.000
No control avg reward: -377885472.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
