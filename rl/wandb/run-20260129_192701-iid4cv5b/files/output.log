Iteration 0: 100%|██████████| 10/10 [00:23<00:00,  2.33s/it, episode=10, norm_ret=-10.754, true_ret=-314976416.000, steps=600]
Agent gate_2 episode reward: [-73.25316983]
All agents episode reward: [-73.25316983]
Agent gate_2 episode reward: [-22.50554803]
All agents episode reward: [-22.50554803]
Agent gate_2 episode reward: [-4.13265755]
All agents episode reward: [-4.13265755]
Agent gate_2 episode reward: [-4.44917172]
All agents episode reward: [-4.44917172]
Agent gate_2 episode reward: [-0.38181999]
All agents episode reward: [-0.38181999]
Agent gate_2 episode reward: [-0.66873373]
All agents episode reward: [-0.66873373]
Agent gate_2 episode reward: [-0.57084403]
All agents episode reward: [-0.57084403]
Agent gate_2 episode reward: [-0.46429658]
All agents episode reward: [-0.46429658]
Agent gate_2 episode reward: [-0.5213513]
All agents episode reward: [-0.5213513]
Agent gate_2 episode reward: [-0.59534467]
All agents episode reward: [-0.59534467]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.22s/it, episode=20, norm_ret=-0.749, true_ret=-577569792.000, steps=600]
Agent gate_2 episode reward: [-0.64765721]
All agents episode reward: [-0.64765721]
Agent gate_2 episode reward: [-0.61249345]
All agents episode reward: [-0.61249345]
Agent gate_2 episode reward: [-0.56935656]
All agents episode reward: [-0.56935656]
Agent gate_2 episode reward: [-0.60920561]
All agents episode reward: [-0.60920561]
Agent gate_2 episode reward: [-0.60405994]
All agents episode reward: [-0.60405994]
Agent gate_2 episode reward: [-0.67251838]
All agents episode reward: [-0.67251838]
Agent gate_2 episode reward: [-0.80387113]
All agents episode reward: [-0.80387113]
Agent gate_2 episode reward: [-0.75103332]
All agents episode reward: [-0.75103332]
Agent gate_2 episode reward: [-0.72306205]
All agents episode reward: [-0.72306205]
Agent gate_2 episode reward: [-1.49689192]
All agents episode reward: [-1.49689192]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.34s/it, episode=30, norm_ret=-0.892, true_ret=-282103264.000, steps=600]
Agent gate_2 episode reward: [-0.85061166]
All agents episode reward: [-0.85061166]
Agent gate_2 episode reward: [-0.83427428]
All agents episode reward: [-0.83427428]
Agent gate_2 episode reward: [-0.92453218]
All agents episode reward: [-0.92453218]
Agent gate_2 episode reward: [-0.87113518]
All agents episode reward: [-0.87113518]
Agent gate_2 episode reward: [-0.84658575]
All agents episode reward: [-0.84658575]
Agent gate_2 episode reward: [-0.89519849]
All agents episode reward: [-0.89519849]
Agent gate_2 episode reward: [-0.90273202]
All agents episode reward: [-0.90273202]
Agent gate_2 episode reward: [-0.93122566]
All agents episode reward: [-0.93122566]
Agent gate_2 episode reward: [-0.97361672]
All agents episode reward: [-0.97361672]
Agent gate_2 episode reward: [-0.89274669]
All agents episode reward: [-0.89274669]
Iteration 3: 100%|██████████| 10/10 [00:23<00:00,  2.34s/it, episode=40, norm_ret=-1.143, true_ret=-315601728.000, steps=600]
Agent gate_2 episode reward: [-1.69609842]
All agents episode reward: [-1.69609842]
Agent gate_2 episode reward: [-0.89078232]
All agents episode reward: [-0.89078232]
Agent gate_2 episode reward: [-1.01802994]
All agents episode reward: [-1.01802994]
Agent gate_2 episode reward: [-1.48453262]
All agents episode reward: [-1.48453262]
Agent gate_2 episode reward: [-0.94582154]
All agents episode reward: [-0.94582154]
Agent gate_2 episode reward: [-1.05749588]
All agents episode reward: [-1.05749588]
Agent gate_2 episode reward: [-1.04347528]
All agents episode reward: [-1.04347528]
Agent gate_2 episode reward: [-0.96882483]
All agents episode reward: [-0.96882483]
Agent gate_2 episode reward: [-1.17450079]
All agents episode reward: [-1.17450079]
Agent gate_2 episode reward: [-1.146484]
All agents episode reward: [-1.146484]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.30s/it, episode=50, norm_ret=-1.188, true_ret=-283708832.000, steps=600]
Agent gate_2 episode reward: [-1.091774]
All agents episode reward: [-1.091774]
Agent gate_2 episode reward: [-1.3457069]
All agents episode reward: [-1.3457069]
Agent gate_2 episode reward: [-1.11131465]
All agents episode reward: [-1.11131465]
Agent gate_2 episode reward: [-1.22096977]
All agents episode reward: [-1.22096977]
Agent gate_2 episode reward: [-1.14041215]
All agents episode reward: [-1.14041215]
Agent gate_2 episode reward: [-1.18046121]
All agents episode reward: [-1.18046121]
Agent gate_2 episode reward: [-1.21440344]
All agents episode reward: [-1.21440344]
Agent gate_2 episode reward: [-1.2573203]
All agents episode reward: [-1.2573203]
Agent gate_2 episode reward: [-1.17029992]
All agents episode reward: [-1.17029992]
Agent gate_2 episode reward: [-1.14791405]
All agents episode reward: [-1.14791405]
Iteration 5: 100%|██████████| 10/10 [00:30<00:00,  3.07s/it, episode=60, norm_ret=-1.739, true_ret=-508364032.000, steps=600]
Agent gate_2 episode reward: [-1.21065932]
All agents episode reward: [-1.21065932]
Agent gate_2 episode reward: [-1.15413513]
All agents episode reward: [-1.15413513]
Agent gate_2 episode reward: [-1.20487937]
All agents episode reward: [-1.20487937]
Agent gate_2 episode reward: [-1.24762376]
All agents episode reward: [-1.24762376]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -342024736.000 at episode 55 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.2202666]
All agents episode reward: [-1.2202666]
Agent gate_2 episode reward: [-2.22840264]
All agents episode reward: [-2.22840264]
Agent gate_2 episode reward: [-2.34204077]
All agents episode reward: [-2.34204077]
Agent gate_2 episode reward: [-2.24662303]
All agents episode reward: [-2.24662303]
Agent gate_2 episode reward: [-2.19941231]
All agents episode reward: [-2.19941231]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -321775776.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.33454542]
All agents episode reward: [-2.33454542]
Iteration 6: 100%|██████████| 10/10 [00:29<00:00,  2.97s/it, episode=70, norm_ret=-1.394, true_ret=-224880304.000, steps=600]
Agent gate_2 episode reward: [-1.52211193]
All agents episode reward: [-1.52211193]
Agent gate_2 episode reward: [-1.66355825]
All agents episode reward: [-1.66355825]
Agent gate_2 episode reward: [-1.63948476]
All agents episode reward: [-1.63948476]
Agent gate_2 episode reward: [-1.57972455]
All agents episode reward: [-1.57972455]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -293638784.000 at episode 65 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.76248311]
All agents episode reward: [-1.76248311]
Agent gate_2 episode reward: [-1.12161226]
All agents episode reward: [-1.12161226]
Agent gate_2 episode reward: [-1.12638857]
All agents episode reward: [-1.12638857]
Agent gate_2 episode reward: [-1.22763684]
All agents episode reward: [-1.22763684]
Agent gate_2 episode reward: [-1.12501508]
All agents episode reward: [-1.12501508]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -163176080.000 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.17459353]
All agents episode reward: [-1.17459353]
Iteration 7: 100%|██████████| 10/10 [00:30<00:00,  3.07s/it, episode=80, norm_ret=-1.240, true_ret=-440036288.000, steps=600]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [-2.47204369]
All agents episode reward: [-2.47204369]
Agent gate_2 episode reward: [-2.43493749]
All agents episode reward: [-2.43493749]
Agent gate_2 episode reward: [-2.47720415]
All agents episode reward: [-2.47720415]
Agent gate_2 episode reward: [-2.47928322]
All agents episode reward: [-2.47928322]
Agent gate_2 episode reward: [-2.53745377]
All agents episode reward: [-2.53745377]
Iteration 8: 100%|██████████| 10/10 [00:29<00:00,  2.99s/it, episode=90, norm_ret=-2.155, true_ret=-380329408.000, steps=600]
Agent gate_2 episode reward: [-2.0165062]
All agents episode reward: [-2.0165062]
Agent gate_2 episode reward: [-2.11917615]
All agents episode reward: [-2.11917615]
Agent gate_2 episode reward: [-2.07314522]
All agents episode reward: [-2.07314522]
Agent gate_2 episode reward: [-2.10737106]
All agents episode reward: [-2.10737106]
Agent gate_2 episode reward: [-2.1573618]
All agents episode reward: [-2.1573618]
Agent gate_2 episode reward: [-2.25835055]
All agents episode reward: [-2.25835055]
Agent gate_2 episode reward: [-2.08837965]
All agents episode reward: [-2.08837965]
Agent gate_2 episode reward: [-2.10614445]
All agents episode reward: [-2.10614445]
Agent gate_2 episode reward: [-2.24436081]
All agents episode reward: [-2.24436081]
Agent gate_2 episode reward: [-2.3821231]
All agents episode reward: [-2.3821231]
Iteration 9: 100%|██████████| 10/10 [00:30<00:00,  3.02s/it, episode=100, norm_ret=-2.306, true_ret=-374057632.000, steps=600]
Agent gate_2 episode reward: [-2.08107747]
All agents episode reward: [-2.08107747]
Agent gate_2 episode reward: [-2.07925341]
All agents episode reward: [-2.07925341]
Agent gate_2 episode reward: [-2.1539681]
All agents episode reward: [-2.1539681]
Agent gate_2 episode reward: [-2.09848417]
All agents episode reward: [-2.09848417]
Agent gate_2 episode reward: [-2.12976758]
All agents episode reward: [-2.12976758]
Agent gate_2 episode reward: [-2.44945567]
All agents episode reward: [-2.44945567]
Agent gate_2 episode reward: [-2.52427908]
All agents episode reward: [-2.52427908]
Agent gate_2 episode reward: [-2.47827951]
All agents episode reward: [-2.47827951]
Agent gate_2 episode reward: [-2.54609506]
All agents episode reward: [-2.54609506]
Agent gate_2 episode reward: [-2.51476833]
All agents episode reward: [-2.51476833]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -212225136.000 | Total reward: -212225136.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81044008.000
  Average reward: -377885472.000 ± 81044008.000
  Total reward: -377885472.000 ± 81044008.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -407377344.000 | Total reward: -407377344.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -724314624.000 | Total reward: -724314624.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -805422336.000 | Total reward: -805422336.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1174821632.000 | Total reward: -1174821632.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1778629607424.000 | Total reward: -1778629607424.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -791052160.000 | Total reward: -791052160.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -822285120.000 | Total reward: -822285120.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2202740457472.000 | Total reward: -2202740457472.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -744597440.000 | Total reward: -744597440.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -499645216.000 | Total reward: -499645216.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -398733934592.000 ± 801605025792.000
  Average reward: -398733934592.000 ± 801605025792.000
  Total reward: -398733934592.000 ± 801605025792.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -212225136.000 | Total reward: -212225136.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -368379040.000 | Total reward: -368379040.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -424930720.000 | Total reward: -424930720.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -509151424.000 | Total reward: -509151424.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -340241952.000 | Total reward: -340241952.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -424589088.000 | Total reward: -424589088.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -454989280.000 | Total reward: -454989280.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -372457056.000 | Total reward: -372457056.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -388921664.000 | Total reward: -388921664.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -282969408.000 | Total reward: -282969408.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377885472.000 ± 81044008.000
  Average reward: -377885472.000 ± 81044008.000
  Total reward: -377885472.000 ± 81044008.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -377885472.000
Rule-based avg reward: -398733934592.000
No control avg reward: -377885472.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
