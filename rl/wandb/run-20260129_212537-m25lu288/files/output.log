Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.27s/it, episode=10, norm_ret=-18.945, true_ret=-2571311.750, steps=600]
Agent gate_2 episode reward: [-50.98817749]
All agents episode reward: [-50.98817749]
Agent gate_2 episode reward: [-12.5479194]
All agents episode reward: [-12.5479194]
Agent gate_2 episode reward: [-24.89293475]
All agents episode reward: [-24.89293475]
Agent gate_2 episode reward: [-45.15988599]
All agents episode reward: [-45.15988599]
Agent gate_2 episode reward: [-0.91279501]
All agents episode reward: [-0.91279501]
Agent gate_2 episode reward: [-0.9182094]
All agents episode reward: [-0.9182094]
Agent gate_2 episode reward: [-8.04614275]
All agents episode reward: [-8.04614275]
Agent gate_2 episode reward: [-43.54025262]
All agents episode reward: [-43.54025262]
Agent gate_2 episode reward: [-1.80237636]
All agents episode reward: [-1.80237636]
Agent gate_2 episode reward: [-0.63957742]
All agents episode reward: [-0.63957742]
Iteration 1: 100%|██████████| 10/10 [00:23<00:00,  2.34s/it, episode=20, norm_ret=-3.661, true_ret=-29622436.000, steps=600]
Agent gate_2 episode reward: [-12.37629752]
All agents episode reward: [-12.37629752]
Agent gate_2 episode reward: [-0.19700751]
All agents episode reward: [-0.19700751]
Agent gate_2 episode reward: [-0.08181798]
All agents episode reward: [-0.08181798]
Agent gate_2 episode reward: [-0.22940794]
All agents episode reward: [-0.22940794]
Agent gate_2 episode reward: [-0.34742768]
All agents episode reward: [-0.34742768]
Agent gate_2 episode reward: [-0.28658721]
All agents episode reward: [-0.28658721]
Agent gate_2 episode reward: [-7.03119719]
All agents episode reward: [-7.03119719]
Agent gate_2 episode reward: [-7.4274016]
All agents episode reward: [-7.4274016]
Agent gate_2 episode reward: [-0.24079989]
All agents episode reward: [-0.24079989]
Agent gate_2 episode reward: [-8.39295667]
All agents episode reward: [-8.39295667]
Iteration 2: 100%|██████████| 10/10 [00:24<00:00,  2.43s/it, episode=30, norm_ret=-1.610, true_ret=-675888.312, steps=600]
Agent gate_2 episode reward: [-0.84420132]
All agents episode reward: [-0.84420132]
Agent gate_2 episode reward: [-0.27074024]
All agents episode reward: [-0.27074024]
Agent gate_2 episode reward: [-0.24354666]
All agents episode reward: [-0.24354666]
Agent gate_2 episode reward: [-9.94870537]
All agents episode reward: [-9.94870537]
Agent gate_2 episode reward: [-0.59359387]
All agents episode reward: [-0.59359387]
Agent gate_2 episode reward: [-0.66450495]
All agents episode reward: [-0.66450495]
Agent gate_2 episode reward: [-0.66264159]
All agents episode reward: [-0.66264159]
Agent gate_2 episode reward: [-2.47945623]
All agents episode reward: [-2.47945623]
Agent gate_2 episode reward: [-0.17437261]
All agents episode reward: [-0.17437261]
Agent gate_2 episode reward: [-0.21513929]
All agents episode reward: [-0.21513929]
Iteration 3: 100%|██████████| 10/10 [00:21<00:00,  2.18s/it, episode=40, norm_ret=-0.784, true_ret=-750198.438, steps=600]
Agent gate_2 episode reward: [-0.27076872]
All agents episode reward: [-0.27076872]
Agent gate_2 episode reward: [-0.21125873]
All agents episode reward: [-0.21125873]
Agent gate_2 episode reward: [-0.26786929]
All agents episode reward: [-0.26786929]
Agent gate_2 episode reward: [-0.26263445]
All agents episode reward: [-0.26263445]
Agent gate_2 episode reward: [-0.2247314]
All agents episode reward: [-0.2247314]
Agent gate_2 episode reward: [-1.16230253]
All agents episode reward: [-1.16230253]
Agent gate_2 episode reward: [-0.32862081]
All agents episode reward: [-0.32862081]
Agent gate_2 episode reward: [-0.2076343]
All agents episode reward: [-0.2076343]
Agent gate_2 episode reward: [-4.6331748]
All agents episode reward: [-4.6331748]
Agent gate_2 episode reward: [-0.27033411]
All agents episode reward: [-0.27033411]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it, episode=50, norm_ret=-0.887, true_ret=-706637.125, steps=600]
Agent gate_2 episode reward: [-0.27059983]
All agents episode reward: [-0.27059983]
Agent gate_2 episode reward: [-0.22214414]
All agents episode reward: [-0.22214414]
Agent gate_2 episode reward: [-4.34337938]
All agents episode reward: [-4.34337938]
Agent gate_2 episode reward: [-0.1228759]
All agents episode reward: [-0.1228759]
Agent gate_2 episode reward: [-2.51899069]
All agents episode reward: [-2.51899069]
Agent gate_2 episode reward: [-0.27780665]
All agents episode reward: [-0.27780665]
Agent gate_2 episode reward: [-0.31811334]
All agents episode reward: [-0.31811334]
Agent gate_2 episode reward: [-0.22763007]
All agents episode reward: [-0.22763007]
Agent gate_2 episode reward: [-0.28842111]
All agents episode reward: [-0.28842111]
Agent gate_2 episode reward: [-0.28112482]
All agents episode reward: [-0.28112482]
Iteration 5: 100%|██████████| 10/10 [00:34<00:00,  3.46s/it, episode=60, norm_ret=-0.915, true_ret=-769719.562, steps=600]
Agent gate_2 episode reward: [-0.29092222]
All agents episode reward: [-0.29092222]
Agent gate_2 episode reward: [-0.2530203]
All agents episode reward: [-0.2530203]
Agent gate_2 episode reward: [-0.30339566]
All agents episode reward: [-0.30339566]
Agent gate_2 episode reward: [-4.5533245]
All agents episode reward: [-4.5533245]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -157254736.000 at episode 55 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.28113706]
All agents episode reward: [-0.28113706]
Agent gate_2 episode reward: [-0.02089829]
All agents episode reward: [-0.02089829]
Agent gate_2 episode reward: [-0.0311154]
All agents episode reward: [-0.0311154]
Agent gate_2 episode reward: [-3.11565513]
All agents episode reward: [-3.11565513]
Agent gate_2 episode reward: [-0.27639025]
All agents episode reward: [-0.27639025]
Agent gate_2 episode reward: [-0.02379889]
All agents episode reward: [-0.02379889]
Iteration 6: 100%|██████████| 10/10 [00:39<00:00,  3.91s/it, episode=70, norm_ret=-12.353, true_ret=-1029107.250, steps=600]
Agent gate_2 episode reward: [-2.54300409]
All agents episode reward: [-2.54300409]
Agent gate_2 episode reward: [-0.00401487]
All agents episode reward: [-0.00401487]
Agent gate_2 episode reward: [-120.572568]
All agents episode reward: [-120.572568]
Agent gate_2 episode reward: [-0.36833273]
All agents episode reward: [-0.36833273]
Agent gate_2 episode reward: [-0.01409252]
All agents episode reward: [-0.01409252]
Agent gate_2 episode reward: [-0.00723804]
All agents episode reward: [-0.00723804]
Agent gate_2 episode reward: [-0.00191328]
All agents episode reward: [-0.00191328]
Agent gate_2 episode reward: [-0.0103446]
All agents episode reward: [-0.0103446]
Agent gate_2 episode reward: [-0.00402677]
All agents episode reward: [-0.00402677]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -10028468.000 at episode 70 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.00083265]
All agents episode reward: [-0.00083265]
Iteration 7: 100%|██████████| 10/10 [00:36<00:00,  3.63s/it, episode=80, norm_ret=-0.006, true_ret=-627685.875, steps=600]
Agent gate_2 episode reward: [-0.00133724]
All agents episode reward: [-0.00133724]
Agent gate_2 episode reward: [-0.0004717]
All agents episode reward: [-0.0004717]
Agent gate_2 episode reward: [-0.0074897]
All agents episode reward: [-0.0074897]
Agent gate_2 episode reward: [-0.00263573]
All agents episode reward: [-0.00263573]
Agent gate_2 episode reward: [-0.00167732]
All agents episode reward: [-0.00167732]
Agent gate_2 episode reward: [-0.02734125]
All agents episode reward: [-0.02734125]
Agent gate_2 episode reward: [-0.00030923]
All agents episode reward: [-0.00030923]
Agent gate_2 episode reward: [-0.01806647]
All agents episode reward: [-0.01806647]
Agent gate_2 episode reward: [-0.00032472]
All agents episode reward: [-0.00032472]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -6836059.000 at episode 80 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.00057872]
All agents episode reward: [-0.00057872]
Iteration 8: 100%|██████████| 10/10 [00:39<00:00,  3.98s/it, episode=90, norm_ret=-0.012, true_ret=-34867128.000, steps=600]
Agent gate_2 episode reward: [-0.00045218]
All agents episode reward: [-0.00045218]
Agent gate_2 episode reward: [-0.05565845]
All agents episode reward: [-0.05565845]
Agent gate_2 episode reward: [-0.00655162]
All agents episode reward: [-0.00655162]
Agent gate_2 episode reward: [-0.00076767]
All agents episode reward: [-0.00076767]
Agent gate_2 episode reward: [-0.00097174]
All agents episode reward: [-0.00097174]
Agent gate_2 episode reward: [-0.0004972]
All agents episode reward: [-0.0004972]
Agent gate_2 episode reward: [-0.00791491]
All agents episode reward: [-0.00791491]
Agent gate_2 episode reward: [-0.01093151]
All agents episode reward: [-0.01093151]
Agent gate_2 episode reward: [-0.00072134]
All agents episode reward: [-0.00072134]
Agent gate_2 episode reward: [-0.03562235]
All agents episode reward: [-0.03562235]
Iteration 9: 100%|██████████| 10/10 [00:36<00:00,  3.68s/it, episode=100, norm_ret=-0.009, true_ret=-974987.312, steps=600]
Agent gate_2 episode reward: [-0.00056068]
All agents episode reward: [-0.00056068]
Agent gate_2 episode reward: [-0.002001]
All agents episode reward: [-0.002001]
Agent gate_2 episode reward: [-0.00084121]
All agents episode reward: [-0.00084121]
Agent gate_2 episode reward: [-0.08086484]
All agents episode reward: [-0.08086484]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -4643546.500 at episode 95 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.00094269]
All agents episode reward: [-0.00094269]
Agent gate_2 episode reward: [-0.00115703]
All agents episode reward: [-0.00115703]
Agent gate_2 episode reward: [-0.00036125]
All agents episode reward: [-0.00036125]
Agent gate_2 episode reward: [-0.00082706]
All agents episode reward: [-0.00082706]
Agent gate_2 episode reward: [-0.00056379]
All agents episode reward: [-0.00056379]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -3131346.500 at episode 100 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.0010849]
All agents episode reward: [-0.0010849]
Saved 1 agents to ppo_agents_butterfly_scC
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -3728712.000 | Total reward: -3728712.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -4094431.750 | Total reward: -4094431.750
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -3929371.500 | Total reward: -3929371.500
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -12641154.000 | Total reward: -12641154.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -5875933696.000 | Total reward: -5875933696.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -6287327.500 | Total reward: -6287327.500
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -3691412.000 | Total reward: -3691412.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -6396532736.000 | Total reward: -6396532736.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -4214039.500 | Total reward: -4214039.500
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -2669966.500 | Total reward: -2669966.500
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -1231372288.000 ± 2455193088.000
  Average reward: -1231372288.000 ± 2455193088.000
  Total reward: -1231372288.000 ± 2455193088.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -773379.438 | Total reward: -773379.438
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -1126116.750 | Total reward: -1126116.750
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -1192027.750 | Total reward: -1192027.750
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1531984.500 | Total reward: -1531984.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1647315840.000 | Total reward: -1647315840.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -1183640.875 | Total reward: -1183640.875
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -1207137.500 | Total reward: -1207137.500
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2040018304.000 | Total reward: -2040018304.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -1147738.125 | Total reward: -1147738.125
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -899541.812 | Total reward: -899541.812
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -369639584.000 ± 742226496.000
  Average reward: -369639584.000 ± 742226496.000
  Total reward: -369639584.000 ± 742226496.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.812 | Total reward: -967434.812
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.625 | Total reward: -867192.625
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902275.938 | Total reward: -902275.938
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808262.875 | Total reward: -808262.875
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.375 | Total reward: -714115.375
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.188
  Average reward: -815120.250 ± 93512.188
  Total reward: -815120.250 ± 93512.188
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -1231372288.000
Rule-based avg reward: -369639584.000
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
