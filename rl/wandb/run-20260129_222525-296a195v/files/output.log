Iteration 0: 100%|██████████| 10/10 [00:37<00:00,  3.72s/it, episode=10, norm_ret=-8.224, true_ret=-453846.406, steps=500]
Agent gate_23 episode reward: [-59.28265747]
All agents episode reward: [-59.28265747]
Agent gate_23 episode reward: [-2.24869561]
All agents episode reward: [-2.24869561]
Agent gate_23 episode reward: [-1.09461854]
All agents episode reward: [-1.09461854]
Agent gate_23 episode reward: [-5.12814448]
All agents episode reward: [-5.12814448]
Agent gate_23 episode reward: [-2.32368368]
All agents episode reward: [-2.32368368]
Agent gate_23 episode reward: [-4.77363444]
All agents episode reward: [-4.77363444]
Agent gate_23 episode reward: [-0.84866452]
All agents episode reward: [-0.84866452]
Agent gate_23 episode reward: [-0.76042144]
All agents episode reward: [-0.76042144]
Agent gate_23 episode reward: [-5.10643336]
All agents episode reward: [-5.10643336]
Agent gate_23 episode reward: [-0.67042927]
All agents episode reward: [-0.67042927]
Iteration 1: 100%|██████████| 10/10 [00:37<00:00,  3.72s/it, episode=20, norm_ret=-1.372, true_ret=-2066784.500, steps=500]
Agent gate_23 episode reward: [-0.66231713]
All agents episode reward: [-0.66231713]
Agent gate_23 episode reward: [-1.15419494]
All agents episode reward: [-1.15419494]
Agent gate_23 episode reward: [-1.80744911]
All agents episode reward: [-1.80744911]
Agent gate_23 episode reward: [-0.64372391]
All agents episode reward: [-0.64372391]
Agent gate_23 episode reward: [-1.19685001]
All agents episode reward: [-1.19685001]
Agent gate_23 episode reward: [-2.04202067]
All agents episode reward: [-2.04202067]
Agent gate_23 episode reward: [-0.84196775]
All agents episode reward: [-0.84196775]
Agent gate_23 episode reward: [-0.66801784]
All agents episode reward: [-0.66801784]
Agent gate_23 episode reward: [-0.6382769]
All agents episode reward: [-0.6382769]
Agent gate_23 episode reward: [-4.0608958]
All agents episode reward: [-4.0608958]
Iteration 2: 100%|██████████| 10/10 [00:37<00:00,  3.78s/it, episode=30, norm_ret=-0.985, true_ret=-413916.906, steps=500]
Agent gate_23 episode reward: [-3.41395532]
All agents episode reward: [-3.41395532]
Agent gate_23 episode reward: [-0.78832769]
All agents episode reward: [-0.78832769]
Agent gate_23 episode reward: [-0.94259538]
All agents episode reward: [-0.94259538]
Agent gate_23 episode reward: [-0.57240134]
All agents episode reward: [-0.57240134]
Agent gate_23 episode reward: [-0.49809808]
All agents episode reward: [-0.49809808]
Agent gate_23 episode reward: [-0.5630125]
All agents episode reward: [-0.5630125]
Agent gate_23 episode reward: [-0.5344354]
All agents episode reward: [-0.5344354]
Agent gate_23 episode reward: [-0.52417507]
All agents episode reward: [-0.52417507]
Agent gate_23 episode reward: [-1.05553972]
All agents episode reward: [-1.05553972]
Agent gate_23 episode reward: [-0.96242556]
All agents episode reward: [-0.96242556]
Iteration 3: 100%|██████████| 10/10 [00:37<00:00,  3.75s/it, episode=40, norm_ret=-1.256, true_ret=-952849.625, steps=500]
Agent gate_23 episode reward: [-0.9478184]
All agents episode reward: [-0.9478184]
Agent gate_23 episode reward: [-0.7845832]
All agents episode reward: [-0.7845832]
Agent gate_23 episode reward: [-3.18052864]
All agents episode reward: [-3.18052864]
Agent gate_23 episode reward: [-0.9730961]
All agents episode reward: [-0.9730961]
Agent gate_23 episode reward: [-0.72696776]
All agents episode reward: [-0.72696776]
Agent gate_23 episode reward: [-1.10234134]
All agents episode reward: [-1.10234134]
Agent gate_23 episode reward: [-0.94765264]
All agents episode reward: [-0.94765264]
Agent gate_23 episode reward: [-0.76714532]
All agents episode reward: [-0.76714532]
Agent gate_23 episode reward: [-0.60716252]
All agents episode reward: [-0.60716252]
Agent gate_23 episode reward: [-2.52367668]
All agents episode reward: [-2.52367668]
Iteration 4: 100%|██████████| 10/10 [00:37<00:00,  3.78s/it, episode=50, norm_ret=-1.226, true_ret=-325374.094, steps=500]
Agent gate_23 episode reward: [-3.30549142]
All agents episode reward: [-3.30549142]
Agent gate_23 episode reward: [-0.71725765]
All agents episode reward: [-0.71725765]
Agent gate_23 episode reward: [-1.13327823]
All agents episode reward: [-1.13327823]
Agent gate_23 episode reward: [-1.06572309]
All agents episode reward: [-1.06572309]
Agent gate_23 episode reward: [-0.85005468]
All agents episode reward: [-0.85005468]
Agent gate_23 episode reward: [-1.01136656]
All agents episode reward: [-1.01136656]
Agent gate_23 episode reward: [-1.02546062]
All agents episode reward: [-1.02546062]
Agent gate_23 episode reward: [-1.25774378]
All agents episode reward: [-1.25774378]
Agent gate_23 episode reward: [-0.93693386]
All agents episode reward: [-0.93693386]
Agent gate_23 episode reward: [-0.95246772]
All agents episode reward: [-0.95246772]
Iteration 5: 100%|██████████| 10/10 [01:26<00:00,  8.65s/it, episode=60, norm_ret=-1.464, true_ret=-265474.500, steps=500]
Agent gate_23 episode reward: [-0.96434466]
All agents episode reward: [-0.96434466]
Agent gate_23 episode reward: [-3.46294937]
All agents episode reward: [-3.46294937]
Agent gate_23 episode reward: [-2.66473612]
All agents episode reward: [-2.66473612]
Agent gate_23 episode reward: [-0.90826292]
All agents episode reward: [-0.90826292]
Saved 1 agents to ppo_agents_two_coordinators
[Validation] New best avg return: -336295.094 at episode 55 (over 10 val episodes, saved to ppo_agents_two_coordinators)
Agent gate_23 episode reward: [-0.93128021]
All agents episode reward: [-0.93128021]
Agent gate_23 episode reward: [-0.89470323]
All agents episode reward: [-0.89470323]
Agent gate_23 episode reward: [-1.37587229]
All agents episode reward: [-1.37587229]
Agent gate_23 episode reward: [-0.9204712]
All agents episode reward: [-0.9204712]
Agent gate_23 episode reward: [-1.6073834]
All agents episode reward: [-1.6073834]
Agent gate_23 episode reward: [-0.90733383]
All agents episode reward: [-0.90733383]
Iteration 6: 100%|██████████| 10/10 [01:25<00:00,  8.59s/it, episode=70, norm_ret=-1.810, true_ret=-358744.688, steps=500]
Agent gate_23 episode reward: [-1.41716218]
All agents episode reward: [-1.41716218]
Agent gate_23 episode reward: [-2.55197104]
All agents episode reward: [-2.55197104]
Agent gate_23 episode reward: [-1.04384486]
All agents episode reward: [-1.04384486]
Agent gate_23 episode reward: [-0.98035924]
All agents episode reward: [-0.98035924]
Agent gate_23 episode reward: [-1.11535854]
All agents episode reward: [-1.11535854]
Agent gate_23 episode reward: [-6.23788906]
All agents episode reward: [-6.23788906]
Agent gate_23 episode reward: [-1.68779978]
All agents episode reward: [-1.68779978]
Agent gate_23 episode reward: [-0.98901485]
All agents episode reward: [-0.98901485]
Agent gate_23 episode reward: [-0.97504935]
All agents episode reward: [-0.97504935]
Agent gate_23 episode reward: [-1.09974061]
All agents episode reward: [-1.09974061]
Iteration 7: 100%|██████████| 10/10 [01:25<00:00,  8.59s/it, episode=80, norm_ret=-1.419, true_ret=-387360.938, steps=500]
Agent gate_23 episode reward: [-1.26146143]
All agents episode reward: [-1.26146143]
Agent gate_23 episode reward: [-1.0865472]
All agents episode reward: [-1.0865472]
Agent gate_23 episode reward: [-1.57745865]
All agents episode reward: [-1.57745865]
Agent gate_23 episode reward: [-1.09537866]
All agents episode reward: [-1.09537866]
Agent gate_23 episode reward: [-0.82101001]
All agents episode reward: [-0.82101001]
Agent gate_23 episode reward: [-2.44613508]
All agents episode reward: [-2.44613508]
Agent gate_23 episode reward: [-0.96159637]
All agents episode reward: [-0.96159637]
Agent gate_23 episode reward: [-2.90984185]
All agents episode reward: [-2.90984185]
Agent gate_23 episode reward: [-0.76211904]
All agents episode reward: [-0.76211904]
Agent gate_23 episode reward: [-1.26744791]
All agents episode reward: [-1.26744791]
Iteration 8: 100%|██████████| 10/10 [01:25<00:00,  8.59s/it, episode=90, norm_ret=-1.750, true_ret=-1163169.875, steps=500]
Agent gate_23 episode reward: [-0.88655013]
All agents episode reward: [-0.88655013]
Agent gate_23 episode reward: [-1.07778253]
All agents episode reward: [-1.07778253]
Agent gate_23 episode reward: [-0.98894045]
All agents episode reward: [-0.98894045]
Agent gate_23 episode reward: [-1.48593092]
All agents episode reward: [-1.48593092]
Agent gate_23 episode reward: [-5.0355384]
All agents episode reward: [-5.0355384]
Agent gate_23 episode reward: [-0.81545512]
All agents episode reward: [-0.81545512]
Agent gate_23 episode reward: [-0.75635232]
All agents episode reward: [-0.75635232]
Agent gate_23 episode reward: [-1.49925366]
All agents episode reward: [-1.49925366]
Agent gate_23 episode reward: [-0.8070713]
All agents episode reward: [-0.8070713]
Agent gate_23 episode reward: [-4.14659251]
All agents episode reward: [-4.14659251]
Iteration 9: 100%|██████████| 10/10 [01:28<00:00,  8.88s/it, episode=100, norm_ret=-2.527, true_ret=-257929.203, steps=500]
Agent gate_23 episode reward: [-1.61913044]
All agents episode reward: [-1.61913044]
Agent gate_23 episode reward: [-1.3493342]
All agents episode reward: [-1.3493342]
Agent gate_23 episode reward: [-0.9567398]
All agents episode reward: [-0.9567398]
Agent gate_23 episode reward: [-1.16955973]
All agents episode reward: [-1.16955973]
Agent gate_23 episode reward: [-5.06140361]
All agents episode reward: [-5.06140361]
Agent gate_23 episode reward: [-4.16389574]
All agents episode reward: [-4.16389574]
Agent gate_23 episode reward: [-7.83355091]
All agents episode reward: [-7.83355091]
Agent gate_23 episode reward: [-1.11983408]
All agents episode reward: [-1.11983408]
Agent gate_23 episode reward: [-1.00514855]
All agents episode reward: [-1.00514855]
Agent gate_23 episode reward: [-0.98997468]
All agents episode reward: [-0.98997468]
Loaded 1 agents from ppo_agents_two_coordinators
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -275568.469 | Total reward: -275568.469
Saved run 1 to rl_training/two_coordinators/ppo_run1
  Run 2/10... Avg agent reward (episode): -301274.406 | Total reward: -301274.406
Saved run 2 to rl_training/two_coordinators/ppo_run2
  Run 3/10... Avg agent reward (episode): -310352.000 | Total reward: -310352.000
Saved run 3 to rl_training/two_coordinators/ppo_run3
  Run 4/10... Avg agent reward (episode): -245007.062 | Total reward: -245007.062
Saved run 4 to rl_training/two_coordinators/ppo_run4
  Run 5/10... Avg agent reward (episode): -1183394.875 | Total reward: -1183394.875
Saved run 5 to rl_training/two_coordinators/ppo_run5
  Run 6/10... Avg agent reward (episode): -362251.062 | Total reward: -362251.062
Saved run 6 to rl_training/two_coordinators/ppo_run6
  Run 7/10... Avg agent reward (episode): -385103.312 | Total reward: -385103.312
Saved run 7 to rl_training/two_coordinators/ppo_run7
  Run 8/10... Avg agent reward (episode): -436680.156 | Total reward: -436680.156
Saved run 8 to rl_training/two_coordinators/ppo_run8
  Run 9/10... Avg agent reward (episode): -431895.156 | Total reward: -431895.156
Saved run 9 to rl_training/two_coordinators/ppo_run9
  Run 10/10... Avg agent reward (episode): -354847.031 | Total reward: -354847.031
Saved run 10 to rl_training/two_coordinators/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_23: -428637.406 ± 258620.297
  Average reward: -428637.406 ± 258620.297
  Total reward: -428637.406 ± 258620.297
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -1984786.875 | Total reward: -1984786.875
Saved run 1 to rl_training/two_coordinators/rule_based_run1
  Run 2/10... Avg agent reward (episode): -5662002.000 | Total reward: -5662002.000
Saved run 2 to rl_training/two_coordinators/rule_based_run2
  Run 3/10... Avg agent reward (episode): -2867924.000 | Total reward: -2867924.000
Saved run 3 to rl_training/two_coordinators/rule_based_run3
  Run 4/10... Avg agent reward (episode): -11125779.000 | Total reward: -11125779.000
Saved run 4 to rl_training/two_coordinators/rule_based_run4
  Run 5/10... Avg agent reward (episode): -2962291.750 | Total reward: -2962291.750
Saved run 5 to rl_training/two_coordinators/rule_based_run5
  Run 6/10... Avg agent reward (episode): -70044992.000 | Total reward: -70044992.000
Saved run 6 to rl_training/two_coordinators/rule_based_run6
  Run 7/10... Avg agent reward (episode): -15779750.000 | Total reward: -15779750.000
Saved run 7 to rl_training/two_coordinators/rule_based_run7
  Run 8/10... Avg agent reward (episode): -8025430.000 | Total reward: -8025430.000
Saved run 8 to rl_training/two_coordinators/rule_based_run8
  Run 9/10... Avg agent reward (episode): -3996812.500 | Total reward: -3996812.500
Saved run 9 to rl_training/two_coordinators/rule_based_run9
  Run 10/10... Avg agent reward (episode): -69795632.000 | Total reward: -69795632.000
Saved run 10 to rl_training/two_coordinators/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_23: -19224540.000 ± 25667226.000
  Average reward: -19224540.000 ± 25667226.000
  Total reward: -19224540.000 ± 25667226.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -275932.500 | Total reward: -275932.500
Saved run 1 to rl_training/two_coordinators/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -314540.469 | Total reward: -314540.469
Saved run 2 to rl_training/two_coordinators/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -1210530.750 | Total reward: -1210530.750
Saved run 3 to rl_training/two_coordinators/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -245018.406 | Total reward: -245018.406
Saved run 4 to rl_training/two_coordinators/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -317550.844 | Total reward: -317550.844
Saved run 5 to rl_training/two_coordinators/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -362251.062 | Total reward: -362251.062
Saved run 6 to rl_training/two_coordinators/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -384460.938 | Total reward: -384460.938
Saved run 7 to rl_training/two_coordinators/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -403313.875 | Total reward: -403313.875
Saved run 8 to rl_training/two_coordinators/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -431895.156 | Total reward: -431895.156
Saved run 9 to rl_training/two_coordinators/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -357268.906 | Total reward: -357268.906
Saved run 10 to rl_training/two_coordinators/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_23: -430276.312 ± 265674.125
  Average reward: -430276.312 ± 265674.125
  Total reward: -430276.312 ± 265674.125
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -428637.406
Rule-based avg reward: -19224540.000
No control avg reward: -430276.312
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
