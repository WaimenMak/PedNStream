Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=10, norm_ret=-7.476, true_ret=-734213.688, steps=600]
Agent gate_2 episode reward: [-60.65328456]
All agents episode reward: [-60.65328456]
Agent gate_2 episode reward: [-2.27432935]
All agents episode reward: [-2.27432935]
Agent gate_2 episode reward: [-5.22715488]
All agents episode reward: [-5.22715488]
Agent gate_2 episode reward: [-2.30145083]
All agents episode reward: [-2.30145083]
Agent gate_2 episode reward: [-0.70015194]
All agents episode reward: [-0.70015194]
Agent gate_2 episode reward: [-0.6636267]
All agents episode reward: [-0.6636267]
Agent gate_2 episode reward: [-0.65372611]
All agents episode reward: [-0.65372611]
Agent gate_2 episode reward: [-0.70966118]
All agents episode reward: [-0.70966118]
Agent gate_2 episode reward: [-0.76357473]
All agents episode reward: [-0.76357473]
Agent gate_2 episode reward: [-0.80916669]
All agents episode reward: [-0.80916669]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.29s/it, episode=20, norm_ret=-1.091, true_ret=-1414050.875, steps=600]
Agent gate_2 episode reward: [-0.8030399]
All agents episode reward: [-0.8030399]
Agent gate_2 episode reward: [-0.8443146]
All agents episode reward: [-0.8443146]
Agent gate_2 episode reward: [-0.92688506]
All agents episode reward: [-0.92688506]
Agent gate_2 episode reward: [-0.94043069]
All agents episode reward: [-0.94043069]
Agent gate_2 episode reward: [-0.91765606]
All agents episode reward: [-0.91765606]
Agent gate_2 episode reward: [-0.98046435]
All agents episode reward: [-0.98046435]
Agent gate_2 episode reward: [-1.28053294]
All agents episode reward: [-1.28053294]
Agent gate_2 episode reward: [-1.01882923]
All agents episode reward: [-1.01882923]
Agent gate_2 episode reward: [-1.06867342]
All agents episode reward: [-1.06867342]
Agent gate_2 episode reward: [-2.12944399]
All agents episode reward: [-2.12944399]
Iteration 2: 100%|██████████| 10/10 [00:22<00:00,  2.27s/it, episode=30, norm_ret=-1.307, true_ret=-727352.125, steps=600]
Agent gate_2 episode reward: [-1.15503014]
All agents episode reward: [-1.15503014]
Agent gate_2 episode reward: [-1.18841977]
All agents episode reward: [-1.18841977]
Agent gate_2 episode reward: [-1.17631462]
All agents episode reward: [-1.17631462]
Agent gate_2 episode reward: [-1.16835976]
All agents episode reward: [-1.16835976]
Agent gate_2 episode reward: [-1.25436548]
All agents episode reward: [-1.25436548]
Agent gate_2 episode reward: [-1.24451212]
All agents episode reward: [-1.24451212]
Agent gate_2 episode reward: [-1.2484173]
All agents episode reward: [-1.2484173]
Agent gate_2 episode reward: [-1.99204748]
All agents episode reward: [-1.99204748]
Agent gate_2 episode reward: [-1.30964706]
All agents episode reward: [-1.30964706]
Agent gate_2 episode reward: [-1.32890971]
All agents episode reward: [-1.32890971]
Iteration 3: 100%|██████████| 10/10 [00:24<00:00,  2.42s/it, episode=40, norm_ret=-1.475, true_ret=-777838.062, steps=600]
Agent gate_2 episode reward: [-1.39176167]
All agents episode reward: [-1.39176167]
Agent gate_2 episode reward: [-1.37695154]
All agents episode reward: [-1.37695154]
Agent gate_2 episode reward: [-1.34729307]
All agents episode reward: [-1.34729307]
Agent gate_2 episode reward: [-1.44795276]
All agents episode reward: [-1.44795276]
Agent gate_2 episode reward: [-1.50629981]
All agents episode reward: [-1.50629981]
Agent gate_2 episode reward: [-1.51016161]
All agents episode reward: [-1.51016161]
Agent gate_2 episode reward: [-1.47659858]
All agents episode reward: [-1.47659858]
Agent gate_2 episode reward: [-1.54763596]
All agents episode reward: [-1.54763596]
Agent gate_2 episode reward: [-1.51254175]
All agents episode reward: [-1.51254175]
Agent gate_2 episode reward: [-1.63080325]
All agents episode reward: [-1.63080325]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.40s/it, episode=50, norm_ret=-1.664, true_ret=-735540.250, steps=600]
Agent gate_2 episode reward: [-1.61777876]
All agents episode reward: [-1.61777876]
Agent gate_2 episode reward: [-1.62052417]
All agents episode reward: [-1.62052417]
Agent gate_2 episode reward: [-1.60331666]
All agents episode reward: [-1.60331666]
Agent gate_2 episode reward: [-1.72701288]
All agents episode reward: [-1.72701288]
Agent gate_2 episode reward: [-1.65760716]
All agents episode reward: [-1.65760716]
Agent gate_2 episode reward: [-1.70507949]
All agents episode reward: [-1.70507949]
Agent gate_2 episode reward: [-1.5814445]
All agents episode reward: [-1.5814445]
Agent gate_2 episode reward: [-1.71904344]
All agents episode reward: [-1.71904344]
Agent gate_2 episode reward: [-1.68909294]
All agents episode reward: [-1.68909294]
Agent gate_2 episode reward: [-1.71702132]
All agents episode reward: [-1.71702132]
Iteration 5: 100%|██████████| 10/10 [00:38<00:00,  3.88s/it, episode=60, norm_ret=-1.775, true_ret=-653229.938, steps=600]
Agent gate_2 episode reward: [-1.69452527]
All agents episode reward: [-1.69452527]
Agent gate_2 episode reward: [-1.73024793]
All agents episode reward: [-1.73024793]
Agent gate_2 episode reward: [-1.8275233]
All agents episode reward: [-1.8275233]
Agent gate_2 episode reward: [-1.7419903]
All agents episode reward: [-1.7419903]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -795092.125 at episode 55 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.68861937]
All agents episode reward: [-1.68861937]
Agent gate_2 episode reward: [-1.92048587]
All agents episode reward: [-1.92048587]
Agent gate_2 episode reward: [-1.81701508]
All agents episode reward: [-1.81701508]
Agent gate_2 episode reward: [-1.81215762]
All agents episode reward: [-1.81215762]
Agent gate_2 episode reward: [-1.72196652]
All agents episode reward: [-1.72196652]
Agent gate_2 episode reward: [-1.79272841]
All agents episode reward: [-1.79272841]
Iteration 6: 100%|██████████| 10/10 [00:37<00:00,  3.79s/it, episode=70, norm_ret=-2.928, true_ret=-686204.562, steps=600]
Agent gate_2 episode reward: [-2.53214329]
All agents episode reward: [-2.53214329]
Agent gate_2 episode reward: [-5.03125085]
All agents episode reward: [-5.03125085]
Agent gate_2 episode reward: [-3.61648384]
All agents episode reward: [-3.61648384]
Agent gate_2 episode reward: [-2.72784095]
All agents episode reward: [-2.72784095]
Agent gate_2 episode reward: [-2.67672259]
All agents episode reward: [-2.67672259]
Agent gate_2 episode reward: [-2.53635652]
All agents episode reward: [-2.53635652]
Agent gate_2 episode reward: [-2.55053253]
All agents episode reward: [-2.55053253]
Agent gate_2 episode reward: [-2.57306781]
All agents episode reward: [-2.57306781]
Agent gate_2 episode reward: [-2.80907641]
All agents episode reward: [-2.80907641]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -728278.875 at episode 70 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.22768266]
All agents episode reward: [-2.22768266]
Iteration 7: 100%|██████████| 10/10 [00:37<00:00,  3.78s/it, episode=80, norm_ret=-2.864, true_ret=-870626.562, steps=600]
Agent gate_2 episode reward: [-2.47237029]
All agents episode reward: [-2.47237029]
Agent gate_2 episode reward: [-2.59441577]
All agents episode reward: [-2.59441577]
Agent gate_2 episode reward: [-2.54073786]
All agents episode reward: [-2.54073786]
Agent gate_2 episode reward: [-2.46233215]
All agents episode reward: [-2.46233215]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -686371.375 at episode 75 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.58064464]
All agents episode reward: [-2.58064464]
Agent gate_2 episode reward: [-3.30428282]
All agents episode reward: [-3.30428282]
Agent gate_2 episode reward: [-3.12333331]
All agents episode reward: [-3.12333331]
Agent gate_2 episode reward: [-3.16887482]
All agents episode reward: [-3.16887482]
Agent gate_2 episode reward: [-3.19424873]
All agents episode reward: [-3.19424873]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -669712.812 at episode 80 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-3.20190968]
All agents episode reward: [-3.20190968]
Iteration 8: 100%|██████████| 10/10 [00:36<00:00,  3.68s/it, episode=90, norm_ret=-2.771, true_ret=-643955.812, steps=600]
Agent gate_2 episode reward: [-3.18499508]
All agents episode reward: [-3.18499508]
Agent gate_2 episode reward: [-3.31258682]
All agents episode reward: [-3.31258682]
Agent gate_2 episode reward: [-2.48738003]
All agents episode reward: [-2.48738003]
Agent gate_2 episode reward: [-2.89193146]
All agents episode reward: [-2.89193146]
Agent gate_2 episode reward: [-2.84433906]
All agents episode reward: [-2.84433906]
Agent gate_2 episode reward: [-2.49851976]
All agents episode reward: [-2.49851976]
Agent gate_2 episode reward: [-2.66726313]
All agents episode reward: [-2.66726313]
Agent gate_2 episode reward: [-2.64113943]
All agents episode reward: [-2.64113943]
Agent gate_2 episode reward: [-2.5739589]
All agents episode reward: [-2.5739589]
Agent gate_2 episode reward: [-2.61193697]
All agents episode reward: [-2.61193697]
Iteration 9: 100%|██████████| 10/10 [00:37<00:00,  3.74s/it, episode=100, norm_ret=-3.248, true_ret=-626991.438, steps=600]
Agent gate_2 episode reward: [-3.5892786]
All agents episode reward: [-3.5892786]
Agent gate_2 episode reward: [-3.74528571]
All agents episode reward: [-3.74528571]
Agent gate_2 episode reward: [-3.61832508]
All agents episode reward: [-3.61832508]
Agent gate_2 episode reward: [-3.67646828]
All agents episode reward: [-3.67646828]
Agent gate_2 episode reward: [-3.62791046]
All agents episode reward: [-3.62791046]
Agent gate_2 episode reward: [-2.71430453]
All agents episode reward: [-2.71430453]
Agent gate_2 episode reward: [-3.00243366]
All agents episode reward: [-3.00243366]
Agent gate_2 episode reward: [-2.85526241]
All agents episode reward: [-2.85526241]
Agent gate_2 episode reward: [-2.9001372]
All agents episode reward: [-2.9001372]
Agent gate_2 episode reward: [-2.75550242]
All agents episode reward: [-2.75550242]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -594005.750 | Total reward: -594005.750
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -781512.000 | Total reward: -781512.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -838116.250 | Total reward: -838116.250
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -948137.188 | Total reward: -948137.188
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -754037.750 | Total reward: -754037.750
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -831822.750 | Total reward: -831822.750
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -884130.250 | Total reward: -884130.250
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -812444.625 | Total reward: -812444.625
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -805277.375 | Total reward: -805277.375
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -653688.688 | Total reward: -653688.688
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -790317.312 ± 98502.891
  Average reward: -790317.312 ± 98502.891
  Total reward: -790317.312 ± 98502.891
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -773379.438 | Total reward: -773379.438
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -1126116.750 | Total reward: -1126116.750
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -1192027.750 | Total reward: -1192027.750
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1531984.500 | Total reward: -1531984.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1647315840.000 | Total reward: -1647315840.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -1183640.875 | Total reward: -1183640.875
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -1207137.500 | Total reward: -1207137.500
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2040018304.000 | Total reward: -2040018304.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -1147738.125 | Total reward: -1147738.125
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -899541.812 | Total reward: -899541.812
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -369639584.000 ± 742226496.000
  Average reward: -369639584.000 ± 742226496.000
  Total reward: -369639584.000 ± 742226496.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.812 | Total reward: -967434.812
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.625 | Total reward: -867192.625
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902275.938 | Total reward: -902275.938
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808262.875 | Total reward: -808262.875
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.375 | Total reward: -714115.375
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.188
  Average reward: -815120.250 ± 93512.188
  Total reward: -815120.250 ± 93512.188
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -790317.312
Rule-based avg reward: -369639584.000
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
