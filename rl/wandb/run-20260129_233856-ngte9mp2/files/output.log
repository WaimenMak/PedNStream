Iteration 0: 100%|██████████| 10/10 [00:20<00:00,  2.00s/it, episode=10, norm_ret=-9.343, true_ret=-298348512.000, steps=600]
Agent gate_2 episode reward: [-83.27295214]
All agents episode reward: [-83.27295214]
Agent gate_2 episode reward: [-1.64367545]
All agents episode reward: [-1.64367545]
Agent gate_2 episode reward: [-5.43213164]
All agents episode reward: [-5.43213164]
Agent gate_2 episode reward: [-1.48879445]
All agents episode reward: [-1.48879445]
Agent gate_2 episode reward: [-0.26382884]
All agents episode reward: [-0.26382884]
Agent gate_2 episode reward: [-0.2499868]
All agents episode reward: [-0.2499868]
Agent gate_2 episode reward: [-0.24796957]
All agents episode reward: [-0.24796957]
Agent gate_2 episode reward: [-0.25369198]
All agents episode reward: [-0.25369198]
Agent gate_2 episode reward: [-0.27252635]
All agents episode reward: [-0.27252635]
Agent gate_2 episode reward: [-0.30140667]
All agents episode reward: [-0.30140667]
Iteration 1: 100%|██████████| 10/10 [00:19<00:00,  1.96s/it, episode=20, norm_ret=-0.350, true_ret=-291758784.000, steps=600]
Agent gate_2 episode reward: [-0.29515184]
All agents episode reward: [-0.29515184]
Agent gate_2 episode reward: [-0.33665944]
All agents episode reward: [-0.33665944]
Agent gate_2 episode reward: [-0.31030001]
All agents episode reward: [-0.31030001]
Agent gate_2 episode reward: [-0.35002441]
All agents episode reward: [-0.35002441]
Agent gate_2 episode reward: [-0.36064017]
All agents episode reward: [-0.36064017]
Agent gate_2 episode reward: [-0.35694279]
All agents episode reward: [-0.35694279]
Agent gate_2 episode reward: [-0.3720772]
All agents episode reward: [-0.3720772]
Agent gate_2 episode reward: [-0.35582087]
All agents episode reward: [-0.35582087]
Agent gate_2 episode reward: [-0.36179765]
All agents episode reward: [-0.36179765]
Agent gate_2 episode reward: [-0.40311743]
All agents episode reward: [-0.40311743]
Iteration 2: 100%|██████████| 10/10 [00:19<00:00,  2.00s/it, episode=30, norm_ret=-0.446, true_ret=-274031264.000, steps=600]
Agent gate_2 episode reward: [-0.42183375]
All agents episode reward: [-0.42183375]
Agent gate_2 episode reward: [-0.43814331]
All agents episode reward: [-0.43814331]
Agent gate_2 episode reward: [-0.3887284]
All agents episode reward: [-0.3887284]
Agent gate_2 episode reward: [-0.43320009]
All agents episode reward: [-0.43320009]
Agent gate_2 episode reward: [-0.4496891]
All agents episode reward: [-0.4496891]
Agent gate_2 episode reward: [-0.47133872]
All agents episode reward: [-0.47133872]
Agent gate_2 episode reward: [-0.49675101]
All agents episode reward: [-0.49675101]
Agent gate_2 episode reward: [-0.46279445]
All agents episode reward: [-0.46279445]
Agent gate_2 episode reward: [-0.44221795]
All agents episode reward: [-0.44221795]
Agent gate_2 episode reward: [-0.45891152]
All agents episode reward: [-0.45891152]
Iteration 3: 100%|██████████| 10/10 [00:19<00:00,  1.96s/it, episode=40, norm_ret=-0.540, true_ret=-288111168.000, steps=600]
Agent gate_2 episode reward: [-0.50012794]
All agents episode reward: [-0.50012794]
Agent gate_2 episode reward: [-0.56251453]
All agents episode reward: [-0.56251453]
Agent gate_2 episode reward: [-0.48433553]
All agents episode reward: [-0.48433553]
Agent gate_2 episode reward: [-0.50955636]
All agents episode reward: [-0.50955636]
Agent gate_2 episode reward: [-0.51572567]
All agents episode reward: [-0.51572567]
Agent gate_2 episode reward: [-0.59242148]
All agents episode reward: [-0.59242148]
Agent gate_2 episode reward: [-0.53643804]
All agents episode reward: [-0.53643804]
Agent gate_2 episode reward: [-0.557587]
All agents episode reward: [-0.557587]
Agent gate_2 episode reward: [-0.5899815]
All agents episode reward: [-0.5899815]
Agent gate_2 episode reward: [-0.55440352]
All agents episode reward: [-0.55440352]
Iteration 4: 100%|██████████| 10/10 [00:20<00:00,  2.02s/it, episode=50, norm_ret=-0.600, true_ret=-277613664.000, steps=600]
Agent gate_2 episode reward: [-0.54095059]
All agents episode reward: [-0.54095059]
Agent gate_2 episode reward: [-0.56506107]
All agents episode reward: [-0.56506107]
Agent gate_2 episode reward: [-0.63029455]
All agents episode reward: [-0.63029455]
Agent gate_2 episode reward: [-0.61180364]
All agents episode reward: [-0.61180364]
Agent gate_2 episode reward: [-0.593103]
All agents episode reward: [-0.593103]
Agent gate_2 episode reward: [-0.62395566]
All agents episode reward: [-0.62395566]
Agent gate_2 episode reward: [-0.58945815]
All agents episode reward: [-0.58945815]
Agent gate_2 episode reward: [-0.62346262]
All agents episode reward: [-0.62346262]
Agent gate_2 episode reward: [-0.6275487]
All agents episode reward: [-0.6275487]
Agent gate_2 episode reward: [-0.59537601]
All agents episode reward: [-0.59537601]
Iteration 5: 100%|██████████| 10/10 [00:34<00:00,  3.44s/it, episode=60, norm_ret=-0.827, true_ret=-402928576.000, steps=600]
Agent gate_2 episode reward: [-0.59703736]
All agents episode reward: [-0.59703736]
Agent gate_2 episode reward: [-0.60840665]
All agents episode reward: [-0.60840665]
Agent gate_2 episode reward: [-0.6298991]
All agents episode reward: [-0.6298991]
Agent gate_2 episode reward: [-0.64304805]
All agents episode reward: [-0.64304805]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -314171456.000 at episode 55 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.62464804]
All agents episode reward: [-0.62464804]
Agent gate_2 episode reward: [-1.09274593]
All agents episode reward: [-1.09274593]
Agent gate_2 episode reward: [-1.01159946]
All agents episode reward: [-1.01159946]
Agent gate_2 episode reward: [-1.01934868]
All agents episode reward: [-1.01934868]
Agent gate_2 episode reward: [-1.02169482]
All agents episode reward: [-1.02169482]
Agent gate_2 episode reward: [-1.01850192]
All agents episode reward: [-1.01850192]
Iteration 6: 100%|██████████| 10/10 [00:34<00:00,  3.44s/it, episode=70, norm_ret=-1.198, true_ret=-363567200.000, steps=600]
Agent gate_2 episode reward: [-1.24869627]
All agents episode reward: [-1.24869627]
Agent gate_2 episode reward: [-1.3092531]
All agents episode reward: [-1.3092531]
Agent gate_2 episode reward: [-1.2875114]
All agents episode reward: [-1.2875114]
Agent gate_2 episode reward: [-1.28288895]
All agents episode reward: [-1.28288895]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -314041056.000 at episode 65 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.27960166]
All agents episode reward: [-1.27960166]
Agent gate_2 episode reward: [-1.10765492]
All agents episode reward: [-1.10765492]
Agent gate_2 episode reward: [-1.10807878]
All agents episode reward: [-1.10807878]
Agent gate_2 episode reward: [-1.08585495]
All agents episode reward: [-1.08585495]
Agent gate_2 episode reward: [-1.17159724]
All agents episode reward: [-1.17159724]
Agent gate_2 episode reward: [-1.09495139]
All agents episode reward: [-1.09495139]
Iteration 7: 100%|██████████| 10/10 [00:36<00:00,  3.62s/it, episode=80, norm_ret=-1.033, true_ret=-209412336.000, steps=600]
Agent gate_2 episode reward: [-1.61272127]
All agents episode reward: [-1.61272127]
Agent gate_2 episode reward: [-1.63366956]
All agents episode reward: [-1.63366956]
Agent gate_2 episode reward: [-1.56537471]
All agents episode reward: [-1.56537471]
Agent gate_2 episode reward: [-2.16236149]
All agents episode reward: [-2.16236149]
Agent gate_2 episode reward: [-1.62996944]
All agents episode reward: [-1.62996944]
Agent gate_2 episode reward: [-0.20970758]
All agents episode reward: [-0.20970758]
Agent gate_2 episode reward: [-0.18465434]
All agents episode reward: [-0.18465434]
Agent gate_2 episode reward: [-0.39638677]
All agents episode reward: [-0.39638677]
Agent gate_2 episode reward: [-0.22055372]
All agents episode reward: [-0.22055372]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -250040928.000 at episode 80 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.71585206]
All agents episode reward: [-0.71585206]
Iteration 8: 100%|██████████| 10/10 [00:36<00:00,  3.61s/it, episode=90, norm_ret=-1.047, true_ret=-180323488.000, steps=600]
Agent gate_2 episode reward: [-1.63187097]
All agents episode reward: [-1.63187097]
Agent gate_2 episode reward: [-1.11444769]
All agents episode reward: [-1.11444769]
Agent gate_2 episode reward: [-1.00106575]
All agents episode reward: [-1.00106575]
Agent gate_2 episode reward: [-1.02015754]
All agents episode reward: [-1.02015754]
Agent gate_2 episode reward: [-0.8674661]
All agents episode reward: [-0.8674661]
Agent gate_2 episode reward: [-0.69450472]
All agents episode reward: [-0.69450472]
Agent gate_2 episode reward: [-0.45621974]
All agents episode reward: [-0.45621974]
Agent gate_2 episode reward: [-0.87002301]
All agents episode reward: [-0.87002301]
Agent gate_2 episode reward: [-2.13700276]
All agents episode reward: [-2.13700276]
Agent gate_2 episode reward: [-0.6821488]
All agents episode reward: [-0.6821488]
Iteration 9: 100%|██████████| 10/10 [00:36<00:00,  3.62s/it, episode=100, norm_ret=-1.579, true_ret=-461547712.000, steps=600]
Agent gate_2 episode reward: [-1.11435531]
All agents episode reward: [-1.11435531]
Agent gate_2 episode reward: [-1.02147029]
All agents episode reward: [-1.02147029]
Agent gate_2 episode reward: [-1.29903381]
All agents episode reward: [-1.29903381]
Agent gate_2 episode reward: [-1.50389282]
All agents episode reward: [-1.50389282]
Agent gate_2 episode reward: [-0.90517588]
All agents episode reward: [-0.90517588]
Agent gate_2 episode reward: [-2.17741101]
All agents episode reward: [-2.17741101]
Agent gate_2 episode reward: [-1.97614747]
All agents episode reward: [-1.97614747]
Agent gate_2 episode reward: [-1.96866346]
All agents episode reward: [-1.96866346]
Agent gate_2 episode reward: [-1.94027399]
All agents episode reward: [-1.94027399]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -219836160.000 at episode 100 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.8878736]
All agents episode reward: [-1.8878736]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -212221648.000 | Total reward: -212221648.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -368373984.000 | Total reward: -368373984.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -424925152.000 | Total reward: -424925152.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -509145024.000 | Total reward: -509145024.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -340236480.000 | Total reward: -340236480.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -424583296.000 | Total reward: -424583296.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -454983584.000 | Total reward: -454983584.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -372451584.000 | Total reward: -372451584.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -388916768.000 | Total reward: -388916768.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -282964896.000 | Total reward: -282964896.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377880256.000 ± 81043296.000
  Average reward: -377880256.000 ± 81043296.000
  Total reward: -377880256.000 ± 81043296.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -407374272.000 | Total reward: -407374272.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -724309632.000 | Total reward: -724309632.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -805417344.000 | Total reward: -805417344.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1174816000.000 | Total reward: -1174816000.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1778629607424.000 | Total reward: -1778629607424.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -791046144.000 | Total reward: -791046144.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -822279872.000 | Total reward: -822279872.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2202740457472.000 | Total reward: -2202740457472.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -744592000.000 | Total reward: -744592000.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -499640576.000 | Total reward: -499640576.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -398733934592.000 ± 801605025792.000
  Average reward: -398733934592.000 ± 801605025792.000
  Total reward: -398733934592.000 ± 801605025792.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -212221648.000 | Total reward: -212221648.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -368373984.000 | Total reward: -368373984.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -424925152.000 | Total reward: -424925152.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -509145024.000 | Total reward: -509145024.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -340236480.000 | Total reward: -340236480.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -424583296.000 | Total reward: -424583296.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -454983584.000 | Total reward: -454983584.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -372451584.000 | Total reward: -372451584.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -388916768.000 | Total reward: -388916768.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -282964896.000 | Total reward: -282964896.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -377880256.000 ± 81043296.000
  Average reward: -377880256.000 ± 81043296.000
  Total reward: -377880256.000 ± 81043296.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -377880256.000
Rule-based avg reward: -398733934592.000
No control avg reward: -377880256.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
