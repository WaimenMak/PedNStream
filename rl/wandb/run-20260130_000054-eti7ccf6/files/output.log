Iteration 0: 100%|██████████| 10/10 [00:24<00:00,  2.41s/it, episode=10, norm_ret=-7.486, true_ret=-846857.688, steps=600]
Agent gate_2 episode reward: [-60.65328456]
All agents episode reward: [-60.65328456]
Agent gate_2 episode reward: [-1.96965854]
All agents episode reward: [-1.96965854]
Agent gate_2 episode reward: [-5.51856444]
All agents episode reward: [-5.51856444]
Agent gate_2 episode reward: [-2.33710006]
All agents episode reward: [-2.33710006]
Agent gate_2 episode reward: [-0.27482029]
All agents episode reward: [-0.27482029]
Agent gate_2 episode reward: [-0.68947069]
All agents episode reward: [-0.68947069]
Agent gate_2 episode reward: [-0.70893371]
All agents episode reward: [-0.70893371]
Agent gate_2 episode reward: [-0.94587388]
All agents episode reward: [-0.94587388]
Agent gate_2 episode reward: [-0.84040971]
All agents episode reward: [-0.84040971]
Agent gate_2 episode reward: [-0.92278209]
All agents episode reward: [-0.92278209]
Iteration 1: 100%|██████████| 10/10 [00:24<00:00,  2.40s/it, episode=20, norm_ret=-0.891, true_ret=-1135672.250, steps=600]
Agent gate_2 episode reward: [-0.94174564]
All agents episode reward: [-0.94174564]
Agent gate_2 episode reward: [-0.87574178]
All agents episode reward: [-0.87574178]
Agent gate_2 episode reward: [-0.39912826]
All agents episode reward: [-0.39912826]
Agent gate_2 episode reward: [-0.41202919]
All agents episode reward: [-0.41202919]
Agent gate_2 episode reward: [-0.42459851]
All agents episode reward: [-0.42459851]
Agent gate_2 episode reward: [-0.98331589]
All agents episode reward: [-0.98331589]
Agent gate_2 episode reward: [-1.09570724]
All agents episode reward: [-1.09570724]
Agent gate_2 episode reward: [-1.04066777]
All agents episode reward: [-1.04066777]
Agent gate_2 episode reward: [-1.05644136]
All agents episode reward: [-1.05644136]
Agent gate_2 episode reward: [-1.68541957]
All agents episode reward: [-1.68541957]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.36s/it, episode=30, norm_ret=-1.271, true_ret=-899714.812, steps=600]
Agent gate_2 episode reward: [-1.61376522]
All agents episode reward: [-1.61376522]
Agent gate_2 episode reward: [-1.17799359]
All agents episode reward: [-1.17799359]
Agent gate_2 episode reward: [-1.12413718]
All agents episode reward: [-1.12413718]
Agent gate_2 episode reward: [-1.61283886]
All agents episode reward: [-1.61283886]
Agent gate_2 episode reward: [-1.23445303]
All agents episode reward: [-1.23445303]
Agent gate_2 episode reward: [-1.43295181]
All agents episode reward: [-1.43295181]
Agent gate_2 episode reward: [-0.85821498]
All agents episode reward: [-0.85821498]
Agent gate_2 episode reward: [-1.32140483]
All agents episode reward: [-1.32140483]
Agent gate_2 episode reward: [-0.71123818]
All agents episode reward: [-0.71123818]
Agent gate_2 episode reward: [-1.62072515]
All agents episode reward: [-1.62072515]
Iteration 3: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it, episode=40, norm_ret=-1.463, true_ret=-887287.500, steps=600]
Agent gate_2 episode reward: [-1.5313538]
All agents episode reward: [-1.5313538]
Agent gate_2 episode reward: [-2.03604275]
All agents episode reward: [-2.03604275]
Agent gate_2 episode reward: [-1.62048073]
All agents episode reward: [-1.62048073]
Agent gate_2 episode reward: [-1.10321872]
All agents episode reward: [-1.10321872]
Agent gate_2 episode reward: [-1.80226452]
All agents episode reward: [-1.80226452]
Agent gate_2 episode reward: [-1.4930986]
All agents episode reward: [-1.4930986]
Agent gate_2 episode reward: [-1.87355526]
All agents episode reward: [-1.87355526]
Agent gate_2 episode reward: [-0.66004349]
All agents episode reward: [-0.66004349]
Agent gate_2 episode reward: [-0.67674497]
All agents episode reward: [-0.67674497]
Agent gate_2 episode reward: [-1.83415146]
All agents episode reward: [-1.83415146]
Iteration 4: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it, episode=50, norm_ret=-1.767, true_ret=-830359.625, steps=600]
Agent gate_2 episode reward: [-1.73218046]
All agents episode reward: [-1.73218046]
Agent gate_2 episode reward: [-1.47790751]
All agents episode reward: [-1.47790751]
Agent gate_2 episode reward: [-1.34342735]
All agents episode reward: [-1.34342735]
Agent gate_2 episode reward: [-1.74553528]
All agents episode reward: [-1.74553528]
Agent gate_2 episode reward: [-1.69255716]
All agents episode reward: [-1.69255716]
Agent gate_2 episode reward: [-1.63358214]
All agents episode reward: [-1.63358214]
Agent gate_2 episode reward: [-1.88352187]
All agents episode reward: [-1.88352187]
Agent gate_2 episode reward: [-1.83961982]
All agents episode reward: [-1.83961982]
Agent gate_2 episode reward: [-2.40505331]
All agents episode reward: [-2.40505331]
Agent gate_2 episode reward: [-1.91191817]
All agents episode reward: [-1.91191817]
Iteration 5: 100%|██████████| 10/10 [00:40<00:00,  4.03s/it, episode=60, norm_ret=-1.960, true_ret=-533113.000, steps=600]
Agent gate_2 episode reward: [-2.38613091]
All agents episode reward: [-2.38613091]
Agent gate_2 episode reward: [-1.25213339]
All agents episode reward: [-1.25213339]
Agent gate_2 episode reward: [-1.18528889]
All agents episode reward: [-1.18528889]
Agent gate_2 episode reward: [-1.91179621]
All agents episode reward: [-1.91179621]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -697799.750 at episode 55 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.15882058]
All agents episode reward: [-2.15882058]
Agent gate_2 episode reward: [-2.19152398]
All agents episode reward: [-2.19152398]
Agent gate_2 episode reward: [-2.52590348]
All agents episode reward: [-2.52590348]
Agent gate_2 episode reward: [-2.18096741]
All agents episode reward: [-2.18096741]
Agent gate_2 episode reward: [-2.36361601]
All agents episode reward: [-2.36361601]
Agent gate_2 episode reward: [-1.44280539]
All agents episode reward: [-1.44280539]
Iteration 6: 100%|██████████| 10/10 [00:38<00:00,  3.89s/it, episode=70, norm_ret=-2.743, true_ret=-673452.500, steps=600]
Agent gate_2 episode reward: [-3.07829665]
All agents episode reward: [-3.07829665]
Agent gate_2 episode reward: [-6.54763349]
All agents episode reward: [-6.54763349]
Agent gate_2 episode reward: [-2.68167909]
All agents episode reward: [-2.68167909]
Agent gate_2 episode reward: [-2.24212079]
All agents episode reward: [-2.24212079]
Agent gate_2 episode reward: [-1.18793514]
All agents episode reward: [-1.18793514]
Agent gate_2 episode reward: [-1.74371018]
All agents episode reward: [-1.74371018]
Agent gate_2 episode reward: [-1.75492425]
All agents episode reward: [-1.75492425]
Agent gate_2 episode reward: [-2.91363336]
All agents episode reward: [-2.91363336]
Agent gate_2 episode reward: [-3.13049514]
All agents episode reward: [-3.13049514]
Agent gate_2 episode reward: [-2.15247951]
All agents episode reward: [-2.15247951]
Iteration 7: 100%|██████████| 10/10 [00:38<00:00,  3.83s/it, episode=80, norm_ret=-2.446, true_ret=-612373.188, steps=600]
Agent gate_2 episode reward: [-2.02375137]
All agents episode reward: [-2.02375137]
Agent gate_2 episode reward: [-2.27802681]
All agents episode reward: [-2.27802681]
Agent gate_2 episode reward: [-3.15107535]
All agents episode reward: [-3.15107535]
Agent gate_2 episode reward: [-2.65902967]
All agents episode reward: [-2.65902967]
Agent gate_2 episode reward: [-1.6451771]
All agents episode reward: [-1.6451771]
Agent gate_2 episode reward: [-3.00368586]
All agents episode reward: [-3.00368586]
Agent gate_2 episode reward: [-1.73003106]
All agents episode reward: [-1.73003106]
Agent gate_2 episode reward: [-3.20816932]
All agents episode reward: [-3.20816932]
Agent gate_2 episode reward: [-2.5392193]
All agents episode reward: [-2.5392193]
Agent gate_2 episode reward: [-2.21823591]
All agents episode reward: [-2.21823591]
Iteration 8: 100%|██████████| 10/10 [00:39<00:00,  3.93s/it, episode=90, norm_ret=-2.875, true_ret=-364631.875, steps=600]
Agent gate_2 episode reward: [-2.62114098]
All agents episode reward: [-2.62114098]
Agent gate_2 episode reward: [-2.72947195]
All agents episode reward: [-2.72947195]
Agent gate_2 episode reward: [-4.01901439]
All agents episode reward: [-4.01901439]
Agent gate_2 episode reward: [-2.83176403]
All agents episode reward: [-2.83176403]
Agent gate_2 episode reward: [-2.9558959]
All agents episode reward: [-2.9558959]
Agent gate_2 episode reward: [-3.23597936]
All agents episode reward: [-3.23597936]
Agent gate_2 episode reward: [-2.78503626]
All agents episode reward: [-2.78503626]
Agent gate_2 episode reward: [-2.68641296]
All agents episode reward: [-2.68641296]
Agent gate_2 episode reward: [-3.42757743]
All agents episode reward: [-3.42757743]
Agent gate_2 episode reward: [-1.45494568]
All agents episode reward: [-1.45494568]
Iteration 9: 100%|██████████| 10/10 [00:38<00:00,  3.89s/it, episode=100, norm_ret=-3.425, true_ret=-850038.688, steps=600]
Agent gate_2 episode reward: [-3.84726191]
All agents episode reward: [-3.84726191]
Agent gate_2 episode reward: [-4.05493402]
All agents episode reward: [-4.05493402]
Agent gate_2 episode reward: [-2.88513645]
All agents episode reward: [-2.88513645]
Agent gate_2 episode reward: [-3.37130425]
All agents episode reward: [-3.37130425]
Agent gate_2 episode reward: [-2.79411763]
All agents episode reward: [-2.79411763]
Agent gate_2 episode reward: [-3.34000863]
All agents episode reward: [-3.34000863]
Agent gate_2 episode reward: [-3.34526227]
All agents episode reward: [-3.34526227]
Agent gate_2 episode reward: [-3.50217294]
All agents episode reward: [-3.50217294]
Agent gate_2 episode reward: [-3.44198727]
All agents episode reward: [-3.44198727]
Agent gate_2 episode reward: [-3.66331258]
All agents episode reward: [-3.66331258]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -595822.188 | Total reward: -595822.188
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -807323.188 | Total reward: -807323.188
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -866318.125 | Total reward: -866318.125
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -996808.125 | Total reward: -996808.125
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -765863.500 | Total reward: -765863.500
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -870125.312 | Total reward: -870125.312
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -933761.938 | Total reward: -933761.938
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -810619.938 | Total reward: -810619.938
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -834192.375 | Total reward: -834192.375
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -687483.812 | Total reward: -687483.812
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -816831.875 ± 109525.125
  Average reward: -816831.875 ± 109525.125
  Total reward: -816831.875 ± 109525.125
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -773379.438 | Total reward: -773379.438
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -1126116.750 | Total reward: -1126116.750
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -1192027.750 | Total reward: -1192027.750
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1531984.500 | Total reward: -1531984.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1647315840.000 | Total reward: -1647315840.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -1183640.875 | Total reward: -1183640.875
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -1207137.500 | Total reward: -1207137.500
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2040018304.000 | Total reward: -2040018304.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -1147738.125 | Total reward: -1147738.125
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -899541.812 | Total reward: -899541.812
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -369639584.000 ± 742226496.000
  Average reward: -369639584.000 ± 742226496.000
  Total reward: -369639584.000 ± 742226496.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.812 | Total reward: -967434.812
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.625 | Total reward: -867192.625
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902275.938 | Total reward: -902275.938
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808262.875 | Total reward: -808262.875
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.375 | Total reward: -714115.375
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.188
  Average reward: -815120.250 ± 93512.188
  Total reward: -815120.250 ± 93512.188
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -816831.875
Rule-based avg reward: -369639584.000
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
