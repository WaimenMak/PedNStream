Iteration 0: 100%|██████████| 15/15 [00:29<00:00,  1.99s/it, episode=10, norm_ret=-8.463, true_ret=-865638.188, steps=600]
Agent gate_2 episode reward: [-56.42010965]
All agents episode reward: [-56.42010965]
Agent gate_2 episode reward: [-7.27086448]
All agents episode reward: [-7.27086448]
Agent gate_2 episode reward: [-9.73111179]
All agents episode reward: [-9.73111179]
Agent gate_2 episode reward: [-4.23660695]
All agents episode reward: [-4.23660695]
Agent gate_2 episode reward: [-1.21701498]
All agents episode reward: [-1.21701498]
Agent gate_2 episode reward: [-1.05069919]
All agents episode reward: [-1.05069919]
Agent gate_2 episode reward: [-1.00842153]
All agents episode reward: [-1.00842153]
Agent gate_2 episode reward: [-1.09755233]
All agents episode reward: [-1.09755233]
Agent gate_2 episode reward: [-1.16289386]
All agents episode reward: [-1.16289386]
Agent gate_2 episode reward: [-1.42989834]
All agents episode reward: [-1.42989834]
Agent gate_2 episode reward: [-1.6659126]
All agents episode reward: [-1.6659126]
Agent gate_2 episode reward: [-1.23286957]
All agents episode reward: [-1.23286957]
Agent gate_2 episode reward: [-1.28779061]
All agents episode reward: [-1.28779061]
Agent gate_2 episode reward: [-1.62240593]
All agents episode reward: [-1.62240593]
Agent gate_2 episode reward: [-1.3409931]
All agents episode reward: [-1.3409931]
Iteration 1: 100%|██████████| 15/15 [00:30<00:00,  2.00s/it, episode=25, norm_ret=-2.417, true_ret=-729649.188, steps=600]
Agent gate_2 episode reward: [-1.34971019]
All agents episode reward: [-1.34971019]
Agent gate_2 episode reward: [-6.65727303]
All agents episode reward: [-6.65727303]
Agent gate_2 episode reward: [-1.4469431]
All agents episode reward: [-1.4469431]
Agent gate_2 episode reward: [-1.74246394]
All agents episode reward: [-1.74246394]
Agent gate_2 episode reward: [-4.92870508]
All agents episode reward: [-4.92870508]
Agent gate_2 episode reward: [-1.75288202]
All agents episode reward: [-1.75288202]
Agent gate_2 episode reward: [-1.58476768]
All agents episode reward: [-1.58476768]
Agent gate_2 episode reward: [-1.42216037]
All agents episode reward: [-1.42216037]
Agent gate_2 episode reward: [-1.60629166]
All agents episode reward: [-1.60629166]
Agent gate_2 episode reward: [-1.67552277]
All agents episode reward: [-1.67552277]
Agent gate_2 episode reward: [-1.64478363]
All agents episode reward: [-1.64478363]
Agent gate_2 episode reward: [-1.91891458]
All agents episode reward: [-1.91891458]
Agent gate_2 episode reward: [-2.84245218]
All agents episode reward: [-2.84245218]
Agent gate_2 episode reward: [-1.48208786]
All agents episode reward: [-1.48208786]
Agent gate_2 episode reward: [-1.8387904]
All agents episode reward: [-1.8387904]
Iteration 2: 100%|██████████| 15/15 [00:30<00:00,  2.03s/it, episode=40, norm_ret=-1.945, true_ret=-715369.688, steps=600]
Agent gate_2 episode reward: [-1.87718142]
All agents episode reward: [-1.87718142]
Agent gate_2 episode reward: [-1.88441172]
All agents episode reward: [-1.88441172]
Agent gate_2 episode reward: [-1.84863373]
All agents episode reward: [-1.84863373]
Agent gate_2 episode reward: [-1.91447834]
All agents episode reward: [-1.91447834]
Agent gate_2 episode reward: [-2.0080859]
All agents episode reward: [-2.0080859]
Agent gate_2 episode reward: [-1.9342074]
All agents episode reward: [-1.9342074]
Agent gate_2 episode reward: [-1.95042178]
All agents episode reward: [-1.95042178]
Agent gate_2 episode reward: [-2.05111434]
All agents episode reward: [-2.05111434]
Agent gate_2 episode reward: [-1.95092335]
All agents episode reward: [-1.95092335]
Agent gate_2 episode reward: [-2.02754037]
All agents episode reward: [-2.02754037]
Agent gate_2 episode reward: [-1.99725234]
All agents episode reward: [-1.99725234]
Agent gate_2 episode reward: [-1.94046115]
All agents episode reward: [-1.94046115]
Agent gate_2 episode reward: [-1.84513473]
All agents episode reward: [-1.84513473]
Agent gate_2 episode reward: [-2.25286447]
All agents episode reward: [-2.25286447]
Agent gate_2 episode reward: [-2.17364658]
All agents episode reward: [-2.17364658]
Iteration 3: 100%|██████████| 15/15 [00:29<00:00,  1.99s/it, episode=55, norm_ret=-2.316, true_ret=-723665.375, steps=600]
Agent gate_2 episode reward: [-2.25734397]
All agents episode reward: [-2.25734397]
Agent gate_2 episode reward: [-2.23974481]
All agents episode reward: [-2.23974481]
Agent gate_2 episode reward: [-2.384042]
All agents episode reward: [-2.384042]
Agent gate_2 episode reward: [-2.12353164]
All agents episode reward: [-2.12353164]
Agent gate_2 episode reward: [-2.23518237]
All agents episode reward: [-2.23518237]
Agent gate_2 episode reward: [-2.36629739]
All agents episode reward: [-2.36629739]
Agent gate_2 episode reward: [-2.3838114]
All agents episode reward: [-2.3838114]
Agent gate_2 episode reward: [-2.39815031]
All agents episode reward: [-2.39815031]
Agent gate_2 episode reward: [-2.39895251]
All agents episode reward: [-2.39895251]
Agent gate_2 episode reward: [-2.37468484]
All agents episode reward: [-2.37468484]
Agent gate_2 episode reward: [-2.47175131]
All agents episode reward: [-2.47175131]
Agent gate_2 episode reward: [-2.52045295]
All agents episode reward: [-2.52045295]
Agent gate_2 episode reward: [-2.41591263]
All agents episode reward: [-2.41591263]
Agent gate_2 episode reward: [-2.37349232]
All agents episode reward: [-2.37349232]
Agent gate_2 episode reward: [-2.21645503]
All agents episode reward: [-2.21645503]
Iteration 4: 100%|██████████| 15/15 [00:30<00:00,  2.00s/it, episode=70, norm_ret=-2.640, true_ret=-725575.750, steps=600]
Agent gate_2 episode reward: [-2.63007378]
All agents episode reward: [-2.63007378]
Agent gate_2 episode reward: [-2.81235576]
All agents episode reward: [-2.81235576]
Agent gate_2 episode reward: [-2.58777136]
All agents episode reward: [-2.58777136]
Agent gate_2 episode reward: [-2.58406783]
All agents episode reward: [-2.58406783]
Agent gate_2 episode reward: [-2.62691993]
All agents episode reward: [-2.62691993]
Agent gate_2 episode reward: [-2.55892122]
All agents episode reward: [-2.55892122]
Agent gate_2 episode reward: [-2.64021334]
All agents episode reward: [-2.64021334]
Agent gate_2 episode reward: [-2.6350019]
All agents episode reward: [-2.6350019]
Agent gate_2 episode reward: [-2.65661793]
All agents episode reward: [-2.65661793]
Agent gate_2 episode reward: [-2.66406968]
All agents episode reward: [-2.66406968]
Agent gate_2 episode reward: [-2.71809291]
All agents episode reward: [-2.71809291]
Agent gate_2 episode reward: [-2.77861428]
All agents episode reward: [-2.77861428]
Agent gate_2 episode reward: [-2.74160098]
All agents episode reward: [-2.74160098]
Agent gate_2 episode reward: [-2.78962133]
All agents episode reward: [-2.78962133]
Agent gate_2 episode reward: [-2.85044495]
All agents episode reward: [-2.85044495]
Iteration 5:  93%|█████████▎| 14/15 [00:44<00:02,  2.90s/it, episode=85, norm_ret=-2.799, true_ret=-597770.062, steps=600]
Agent gate_2 episode reward: [-2.79159076]
All agents episode reward: [-2.79159076]
Agent gate_2 episode reward: [-2.91933306]
All agents episode reward: [-2.91933306]
Agent gate_2 episode reward: [-2.88289212]
All agents episode reward: [-2.88289212]
Agent gate_2 episode reward: [-2.81792087]
All agents episode reward: [-2.81792087]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -798165.062 at episode 80 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.8035809]
All agents episode reward: [-2.8035809]
Agent gate_2 episode reward: [-2.81710734]
All agents episode reward: [-2.81710734]
Agent gate_2 episode reward: [-2.90079247]
All agents episode reward: [-2.90079247]
Agent gate_2 episode reward: [-2.6948754]
All agents episode reward: [-2.6948754]
Agent gate_2 episode reward: [-2.83200837]
All agents episode reward: [-2.83200837]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -631522.312 at episode 85 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.53019339]
All agents episode reward: [-2.53019339]
Agent gate_2 episode reward: [-3.03933251]
All agents episode reward: [-3.03933251]
Agent gate_2 episode reward: [-3.29261968]
All agents episode reward: [-3.29261968]
Agent gate_2 episode reward: [-2.97546694]
All agents episode reward: [-2.97546694]
Agent gate_2 episode reward: [-3.43236539]
All agents episode reward: [-3.43236539]
Agent gate_2 episode reward: [-3.36310846]
All agents episode reward: [-3.36310846]
Iteration 6: 100%|██████████| 15/15 [00:52<00:00,  3.49s/it, episode=100, norm_ret=-3.654, true_ret=-1005032.938, steps=600]
Agent gate_2 episode reward: [-2.18864319]
All agents episode reward: [-2.18864319]
Agent gate_2 episode reward: [-2.19293364]
All agents episode reward: [-2.19293364]
Agent gate_2 episode reward: [-2.23688142]
All agents episode reward: [-2.23688142]
Agent gate_2 episode reward: [-1.98223973]
All agents episode reward: [-1.98223973]
Agent gate_2 episode reward: [-2.17474433]
All agents episode reward: [-2.17474433]
Agent gate_2 episode reward: [-5.12493965]
All agents episode reward: [-5.12493965]
Agent gate_2 episode reward: [-5.27656833]
All agents episode reward: [-5.27656833]
Agent gate_2 episode reward: [-5.07395061]
All agents episode reward: [-5.07395061]
Agent gate_2 episode reward: [-5.21502301]
All agents episode reward: [-5.21502301]
Agent gate_2 episode reward: [-5.07642444]
All agents episode reward: [-5.07642444]
Agent gate_2 episode reward: [-3.37288982]
All agents episode reward: [-3.37288982]
Agent gate_2 episode reward: [-3.55785602]
All agents episode reward: [-3.55785602]
Agent gate_2 episode reward: [-3.56735282]
All agents episode reward: [-3.56735282]
Agent gate_2 episode reward: [-3.45400211]
All agents episode reward: [-3.45400211]
Agent gate_2 episode reward: [-3.46774802]
All agents episode reward: [-3.46774802]
Iteration 7: 100%|██████████| 15/15 [00:52<00:00,  3.49s/it, episode=115, norm_ret=-4.503, true_ret=-759778.438, steps=600]
Agent gate_2 episode reward: [-4.76493369]
All agents episode reward: [-4.76493369]
Agent gate_2 episode reward: [-5.01049552]
All agents episode reward: [-5.01049552]
Agent gate_2 episode reward: [-4.7211267]
All agents episode reward: [-4.7211267]
Agent gate_2 episode reward: [-4.80041269]
All agents episode reward: [-4.80041269]
Agent gate_2 episode reward: [-4.96181737]
All agents episode reward: [-4.96181737]
Agent gate_2 episode reward: [-4.1175811]
All agents episode reward: [-4.1175811]
Agent gate_2 episode reward: [-4.0764906]
All agents episode reward: [-4.0764906]
Agent gate_2 episode reward: [-4.12003723]
All agents episode reward: [-4.12003723]
Agent gate_2 episode reward: [-4.09974192]
All agents episode reward: [-4.09974192]
Agent gate_2 episode reward: [-4.35281856]
All agents episode reward: [-4.35281856]
Agent gate_2 episode reward: [-1.92301416]
All agents episode reward: [-1.92301416]
Agent gate_2 episode reward: [-1.92703226]
All agents episode reward: [-1.92703226]
Agent gate_2 episode reward: [-1.93104334]
All agents episode reward: [-1.93104334]
Agent gate_2 episode reward: [-1.93504743]
All agents episode reward: [-1.93504743]
Agent gate_2 episode reward: [-1.93904453]
All agents episode reward: [-1.93904453]
Iteration 8: 100%|██████████| 15/15 [00:52<00:00,  3.52s/it, episode=130, norm_ret=-5.237, true_ret=-820458.625, steps=600]
Agent gate_2 episode reward: [-5.34696606]
All agents episode reward: [-5.34696606]
Agent gate_2 episode reward: [-5.34641932]
All agents episode reward: [-5.34641932]
Agent gate_2 episode reward: [-5.33562594]
All agents episode reward: [-5.33562594]
Agent gate_2 episode reward: [-5.34466775]
All agents episode reward: [-5.34466775]
Agent gate_2 episode reward: [-5.35102071]
All agents episode reward: [-5.35102071]
Agent gate_2 episode reward: [-5.07930473]
All agents episode reward: [-5.07930473]
Agent gate_2 episode reward: [-5.11138702]
All agents episode reward: [-5.11138702]
Agent gate_2 episode reward: [-5.17939854]
All agents episode reward: [-5.17939854]
Agent gate_2 episode reward: [-5.10913547]
All agents episode reward: [-5.10913547]
Agent gate_2 episode reward: [-5.16998876]
All agents episode reward: [-5.16998876]
Agent gate_2 episode reward: [-4.96307254]
All agents episode reward: [-4.96307254]
Agent gate_2 episode reward: [-4.98015554]
All agents episode reward: [-4.98015554]
Agent gate_2 episode reward: [-4.99489884]
All agents episode reward: [-4.99489884]
Agent gate_2 episode reward: [-4.98202325]
All agents episode reward: [-4.98202325]
Agent gate_2 episode reward: [-5.00031864]
All agents episode reward: [-5.00031864]
Iteration 9: 100%|██████████| 15/15 [00:52<00:00,  4.74s/it, episode=145, norm_ret=-5.122, true_ret=-626068.375, steps=600]
Agent gate_2 episode reward: [-5.94589875]
All agents episode reward: [-5.94589875]
Agent gate_2 episode reward: [-5.78964816]
All agents episode reward: [-5.78964816]
Agent gate_2 episode reward: [-5.9312174]
All agents episode reward: [-5.9312174]
Agent gate_2 episode reward: [-5.91839465]
All agents episode reward: [-5.91839465]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -603953.438 at episode 140 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-5.9165784]
All agents episode reward: [-5.9165784]
Agent gate_2 episode reward: [-4.33072674]
All agents episode reward: [-4.33072674]
Agent gate_2 episode reward: [-4.35684818]
All agents episode reward: [-4.35684818]
Agent gate_2 episode reward: [-4.39344379]
All agents episode reward: [-4.39344379]
Agent gate_2 episode reward: [-4.37269644]
All agents episode reward: [-4.37269644]
Agent gate_2 episode reward: [-4.26332652]
All agents episode reward: [-4.26332652]
Agent gate_2 episode reward: [-2.26714029]
All agents episode reward: [-2.26714029]
Agent gate_2 episode reward: [-2.26929738]
All agents episode reward: [-2.26929738]
Agent gate_2 episode reward: [-2.27257399]
All agents episode reward: [-2.27257399]
Agent gate_2 episode reward: [-2.27558533]
All agents episode reward: [-2.27558533]
Agent gate_2 episode reward: [-2.27872415]
All agents episode reward: [-2.27872415]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -967434.812 | Total reward: -967434.812
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -867192.625 | Total reward: -867192.625
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -902275.938 | Total reward: -902275.938
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -808262.875 | Total reward: -808262.875
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -714115.375 | Total reward: -714115.375
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.188
  Average reward: -815120.250 ± 93512.188
  Total reward: -815120.250 ± 93512.188
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -773379.438 | Total reward: -773379.438
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -1126116.750 | Total reward: -1126116.750
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -1192027.750 | Total reward: -1192027.750
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1531984.500 | Total reward: -1531984.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1647315840.000 | Total reward: -1647315840.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -1183640.875 | Total reward: -1183640.875
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -1207137.500 | Total reward: -1207137.500
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2040018304.000 | Total reward: -2040018304.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -1147738.125 | Total reward: -1147738.125
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -899541.812 | Total reward: -899541.812
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -369639584.000 ± 742226496.000
  Average reward: -369639584.000 ± 742226496.000
  Total reward: -369639584.000 ± 742226496.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.812 | Total reward: -967434.812
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.625 | Total reward: -867192.625
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902275.938 | Total reward: -902275.938
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808262.875 | Total reward: -808262.875
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.375 | Total reward: -714115.375
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.188
  Average reward: -815120.250 ± 93512.188
  Total reward: -815120.250 ± 93512.188
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -815120.250
Rule-based avg reward: -369639584.000
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
