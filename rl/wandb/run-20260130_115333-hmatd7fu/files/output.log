Iteration 0: 100%|██████████| 15/15 [00:36<00:00,  2.43s/it, episode=10, norm_ret=-7.476, true_ret=-734213.688, steps=600]
Agent gate_2 episode reward: [-60.65328456]
All agents episode reward: [-60.65328456]
Agent gate_2 episode reward: [-2.27432935]
All agents episode reward: [-2.27432935]
Agent gate_2 episode reward: [-5.22715488]
All agents episode reward: [-5.22715488]
Agent gate_2 episode reward: [-2.30145083]
All agents episode reward: [-2.30145083]
Agent gate_2 episode reward: [-0.70015194]
All agents episode reward: [-0.70015194]
Agent gate_2 episode reward: [-0.6636267]
All agents episode reward: [-0.6636267]
Agent gate_2 episode reward: [-0.65372611]
All agents episode reward: [-0.65372611]
Agent gate_2 episode reward: [-0.70966118]
All agents episode reward: [-0.70966118]
Agent gate_2 episode reward: [-0.76357473]
All agents episode reward: [-0.76357473]
Agent gate_2 episode reward: [-0.80916669]
All agents episode reward: [-0.80916669]
Agent gate_2 episode reward: [-0.8030399]
All agents episode reward: [-0.8030399]
Agent gate_2 episode reward: [-0.8443146]
All agents episode reward: [-0.8443146]
Agent gate_2 episode reward: [-0.92688506]
All agents episode reward: [-0.92688506]
Agent gate_2 episode reward: [-0.94043069]
All agents episode reward: [-0.94043069]
Agent gate_2 episode reward: [-0.91765606]
All agents episode reward: [-0.91765606]
Iteration 1: 100%|██████████| 15/15 [00:35<00:00,  2.36s/it, episode=25, norm_ret=-1.242, true_ret=-748542.812, steps=600]
Agent gate_2 episode reward: [-0.98046435]
All agents episode reward: [-0.98046435]
Agent gate_2 episode reward: [-1.28053294]
All agents episode reward: [-1.28053294]
Agent gate_2 episode reward: [-1.01882923]
All agents episode reward: [-1.01882923]
Agent gate_2 episode reward: [-1.06867342]
All agents episode reward: [-1.06867342]
Agent gate_2 episode reward: [-2.12944399]
All agents episode reward: [-2.12944399]
Agent gate_2 episode reward: [-1.15503014]
All agents episode reward: [-1.15503014]
Agent gate_2 episode reward: [-1.18841977]
All agents episode reward: [-1.18841977]
Agent gate_2 episode reward: [-1.17631462]
All agents episode reward: [-1.17631462]
Agent gate_2 episode reward: [-1.16835976]
All agents episode reward: [-1.16835976]
Agent gate_2 episode reward: [-1.25436548]
All agents episode reward: [-1.25436548]
Agent gate_2 episode reward: [-1.24451212]
All agents episode reward: [-1.24451212]
Agent gate_2 episode reward: [-1.2484173]
All agents episode reward: [-1.2484173]
Agent gate_2 episode reward: [-1.99204748]
All agents episode reward: [-1.99204748]
Agent gate_2 episode reward: [-1.30964706]
All agents episode reward: [-1.30964706]
Agent gate_2 episode reward: [-1.32890971]
All agents episode reward: [-1.32890971]
Iteration 2: 100%|██████████| 15/15 [00:35<00:00,  2.37s/it, episode=40, norm_ret=-1.475, true_ret=-777838.062, steps=600]
Agent gate_2 episode reward: [-1.39176167]
All agents episode reward: [-1.39176167]
Agent gate_2 episode reward: [-1.37695154]
All agents episode reward: [-1.37695154]
Agent gate_2 episode reward: [-1.34729307]
All agents episode reward: [-1.34729307]
Agent gate_2 episode reward: [-1.44795276]
All agents episode reward: [-1.44795276]
Agent gate_2 episode reward: [-1.50629981]
All agents episode reward: [-1.50629981]
Agent gate_2 episode reward: [-1.51016161]
All agents episode reward: [-1.51016161]
Agent gate_2 episode reward: [-1.47659858]
All agents episode reward: [-1.47659858]
Agent gate_2 episode reward: [-1.54763596]
All agents episode reward: [-1.54763596]
Agent gate_2 episode reward: [-1.51254175]
All agents episode reward: [-1.51254175]
Agent gate_2 episode reward: [-1.63080325]
All agents episode reward: [-1.63080325]
Agent gate_2 episode reward: [-1.61777876]
All agents episode reward: [-1.61777876]
Agent gate_2 episode reward: [-1.62052417]
All agents episode reward: [-1.62052417]
Agent gate_2 episode reward: [-1.60331666]
All agents episode reward: [-1.60331666]
Agent gate_2 episode reward: [-1.72701288]
All agents episode reward: [-1.72701288]
Agent gate_2 episode reward: [-1.65760716]
All agents episode reward: [-1.65760716]
Iteration 3: 100%|██████████| 15/15 [00:34<00:00,  2.31s/it, episode=55, norm_ret=-1.709, true_ret=-691041.875, steps=600]
Agent gate_2 episode reward: [-1.70507949]
All agents episode reward: [-1.70507949]
Agent gate_2 episode reward: [-1.5814445]
All agents episode reward: [-1.5814445]
Agent gate_2 episode reward: [-1.71904344]
All agents episode reward: [-1.71904344]
Agent gate_2 episode reward: [-1.68909294]
All agents episode reward: [-1.68909294]
Agent gate_2 episode reward: [-1.71702132]
All agents episode reward: [-1.71702132]
Agent gate_2 episode reward: [-1.69452527]
All agents episode reward: [-1.69452527]
Agent gate_2 episode reward: [-1.73024793]
All agents episode reward: [-1.73024793]
Agent gate_2 episode reward: [-1.8275233]
All agents episode reward: [-1.8275233]
Agent gate_2 episode reward: [-1.7419903]
All agents episode reward: [-1.7419903]
Agent gate_2 episode reward: [-1.68861937]
All agents episode reward: [-1.68861937]
Agent gate_2 episode reward: [-1.81426598]
All agents episode reward: [-1.81426598]
Agent gate_2 episode reward: [-1.8135778]
All agents episode reward: [-1.8135778]
Agent gate_2 episode reward: [-1.83948294]
All agents episode reward: [-1.83948294]
Agent gate_2 episode reward: [-1.75901521]
All agents episode reward: [-1.75901521]
Agent gate_2 episode reward: [-1.65388478]
All agents episode reward: [-1.65388478]
Iteration 4: 100%|██████████| 15/15 [00:35<00:00,  2.36s/it, episode=70, norm_ret=-2.355, true_ret=-710129.938, steps=600]
Agent gate_2 episode reward: [-1.94752549]
All agents episode reward: [-1.94752549]
Agent gate_2 episode reward: [-5.11308404]
All agents episode reward: [-5.11308404]
Agent gate_2 episode reward: [-2.66618527]
All agents episode reward: [-2.66618527]
Agent gate_2 episode reward: [-2.03268711]
All agents episode reward: [-2.03268711]
Agent gate_2 episode reward: [-1.98477965]
All agents episode reward: [-1.98477965]
Agent gate_2 episode reward: [-1.92260571]
All agents episode reward: [-1.92260571]
Agent gate_2 episode reward: [-1.89209167]
All agents episode reward: [-1.89209167]
Agent gate_2 episode reward: [-1.88557142]
All agents episode reward: [-1.88557142]
Agent gate_2 episode reward: [-2.16204336]
All agents episode reward: [-2.16204336]
Agent gate_2 episode reward: [-1.94189049]
All agents episode reward: [-1.94189049]
Agent gate_2 episode reward: [-2.05215025]
All agents episode reward: [-2.05215025]
Agent gate_2 episode reward: [-2.02011904]
All agents episode reward: [-2.02011904]
Agent gate_2 episode reward: [-2.02901729]
All agents episode reward: [-2.02901729]
Agent gate_2 episode reward: [-1.86987362]
All agents episode reward: [-1.86987362]
Agent gate_2 episode reward: [-1.80369866]
All agents episode reward: [-1.80369866]
Iteration 5: 100%|██████████| 15/15 [01:01<00:00,  5.42s/it, episode=85, norm_ret=-2.310, true_ret=-837625.812, steps=600]
Agent gate_2 episode reward: [-1.95608183]
All agents episode reward: [-1.95608183]
Agent gate_2 episode reward: [-2.02667186]
All agents episode reward: [-2.02667186]
Agent gate_2 episode reward: [-2.02268773]
All agents episode reward: [-2.02268773]
Agent gate_2 episode reward: [-2.05585195]
All agents episode reward: [-2.05585195]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -755533.875 at episode 80 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.84099312]
All agents episode reward: [-1.84099312]
Agent gate_2 episode reward: [-2.55866885]
All agents episode reward: [-2.55866885]
Agent gate_2 episode reward: [-2.70251652]
All agents episode reward: [-2.70251652]
Agent gate_2 episode reward: [-2.67904692]
All agents episode reward: [-2.67904692]
Agent gate_2 episode reward: [-2.60733228]
All agents episode reward: [-2.60733228]
Agent gate_2 episode reward: [-2.65296075]
All agents episode reward: [-2.65296075]
Agent gate_2 episode reward: [-2.52293251]
All agents episode reward: [-2.52293251]
Agent gate_2 episode reward: [-2.43278264]
All agents episode reward: [-2.43278264]
Agent gate_2 episode reward: [-2.94181014]
All agents episode reward: [-2.94181014]
Agent gate_2 episode reward: [-2.54459506]
All agents episode reward: [-2.54459506]
Agent gate_2 episode reward: [-2.57964632]
All agents episode reward: [-2.57964632]
Iteration 6: 100%|██████████| 15/15 [00:59<00:00,  3.97s/it, episode=100, norm_ret=-2.717, true_ret=-525257.688, steps=600]
Agent gate_2 episode reward: [-3.58354214]
All agents episode reward: [-3.58354214]
Agent gate_2 episode reward: [-3.24982057]
All agents episode reward: [-3.24982057]
Agent gate_2 episode reward: [-3.35278853]
All agents episode reward: [-3.35278853]
Agent gate_2 episode reward: [-3.53335543]
All agents episode reward: [-3.53335543]
Agent gate_2 episode reward: [-3.60080226]
All agents episode reward: [-3.60080226]
Agent gate_2 episode reward: [-1.96517755]
All agents episode reward: [-1.96517755]
Agent gate_2 episode reward: [-1.88422629]
All agents episode reward: [-1.88422629]
Agent gate_2 episode reward: [-2.03220657]
All agents episode reward: [-2.03220657]
Agent gate_2 episode reward: [-1.96723604]
All agents episode reward: [-1.96723604]
Agent gate_2 episode reward: [-1.99619574]
All agents episode reward: [-1.99619574]
Agent gate_2 episode reward: [-2.50135663]
All agents episode reward: [-2.50135663]
Agent gate_2 episode reward: [-2.68921014]
All agents episode reward: [-2.68921014]
Agent gate_2 episode reward: [-2.61600131]
All agents episode reward: [-2.61600131]
Agent gate_2 episode reward: [-2.61417825]
All agents episode reward: [-2.61417825]
Agent gate_2 episode reward: [-2.79936647]
All agents episode reward: [-2.79936647]
Iteration 7: 100%|██████████| 15/15 [01:01<00:00,  5.46s/it, episode=115, norm_ret=-2.766, true_ret=-688576.875, steps=600]
Agent gate_2 episode reward: [-2.51621182]
All agents episode reward: [-2.51621182]
Agent gate_2 episode reward: [-2.53248293]
All agents episode reward: [-2.53248293]
Agent gate_2 episode reward: [-2.53602313]
All agents episode reward: [-2.53602313]
Agent gate_2 episode reward: [-2.50679311]
All agents episode reward: [-2.50679311]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -708645.125 at episode 110 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.5050261]
All agents episode reward: [-2.5050261]
Agent gate_2 episode reward: [-3.0007653]
All agents episode reward: [-3.0007653]
Agent gate_2 episode reward: [-3.00067836]
All agents episode reward: [-3.00067836]
Agent gate_2 episode reward: [-3.04349365]
All agents episode reward: [-3.04349365]
Agent gate_2 episode reward: [-3.03779017]
All agents episode reward: [-3.03779017]
Agent gate_2 episode reward: [-2.98362967]
All agents episode reward: [-2.98362967]
Agent gate_2 episode reward: [-4.09921659]
All agents episode reward: [-4.09921659]
Agent gate_2 episode reward: [-3.98961467]
All agents episode reward: [-3.98961467]
Agent gate_2 episode reward: [-4.16458885]
All agents episode reward: [-4.16458885]
Agent gate_2 episode reward: [-4.0316232]
All agents episode reward: [-4.0316232]
Agent gate_2 episode reward: [-4.06461833]
All agents episode reward: [-4.06461833]
Iteration 8: 100%|██████████| 15/15 [01:00<00:00,  5.31s/it, episode=130, norm_ret=-2.392, true_ret=-581607.438, steps=600]
Agent gate_2 episode reward: [-1.90442407]
All agents episode reward: [-1.90442407]
Agent gate_2 episode reward: [-1.91191232]
All agents episode reward: [-1.91191232]
Agent gate_2 episode reward: [-1.89152359]
All agents episode reward: [-1.89152359]
Agent gate_2 episode reward: [-2.10544901]
All agents episode reward: [-2.10544901]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -662986.875 at episode 125 (over 10 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.96405805]
All agents episode reward: [-1.96405805]
Agent gate_2 episode reward: [-2.86404267]
All agents episode reward: [-2.86404267]
Agent gate_2 episode reward: [-2.87505809]
All agents episode reward: [-2.87505809]
Agent gate_2 episode reward: [-2.87766344]
All agents episode reward: [-2.87766344]
Agent gate_2 episode reward: [-2.73554183]
All agents episode reward: [-2.73554183]
Agent gate_2 episode reward: [-2.78788916]
All agents episode reward: [-2.78788916]
Agent gate_2 episode reward: [-1.60244729]
All agents episode reward: [-1.60244729]
Agent gate_2 episode reward: [-1.60634763]
All agents episode reward: [-1.60634763]
Agent gate_2 episode reward: [-1.6143836]
All agents episode reward: [-1.6143836]
Agent gate_2 episode reward: [-1.62979634]
All agents episode reward: [-1.62979634]
Agent gate_2 episode reward: [-1.63631732]
All agents episode reward: [-1.63631732]
Iteration 9: 100%|██████████| 15/15 [01:00<00:00,  4.04s/it, episode=145, norm_ret=-3.945, true_ret=-592600.125, steps=600]
Agent gate_2 episode reward: [-4.72416436]
All agents episode reward: [-4.72416436]
Agent gate_2 episode reward: [-4.74295035]
All agents episode reward: [-4.74295035]
Agent gate_2 episode reward: [-4.77716773]
All agents episode reward: [-4.77716773]
Agent gate_2 episode reward: [-5.07496384]
All agents episode reward: [-5.07496384]
Agent gate_2 episode reward: [-4.67535622]
All agents episode reward: [-4.67535622]
Agent gate_2 episode reward: [-2.94083303]
All agents episode reward: [-2.94083303]
Agent gate_2 episode reward: [-3.40644077]
All agents episode reward: [-3.40644077]
Agent gate_2 episode reward: [-3.18511901]
All agents episode reward: [-3.18511901]
Agent gate_2 episode reward: [-2.84455233]
All agents episode reward: [-2.84455233]
Agent gate_2 episode reward: [-3.07727022]
All agents episode reward: [-3.07727022]
Agent gate_2 episode reward: [-4.06894494]
All agents episode reward: [-4.06894494]
Agent gate_2 episode reward: [-4.15639855]
All agents episode reward: [-4.15639855]
Agent gate_2 episode reward: [-4.13794153]
All agents episode reward: [-4.13794153]
Agent gate_2 episode reward: [-4.15346457]
All agents episode reward: [-4.15346457]
Agent gate_2 episode reward: [-4.08527074]
All agents episode reward: [-4.08527074]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -590802.625 | Total reward: -590802.625
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -827120.062 | Total reward: -827120.062
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -901148.500 | Total reward: -901148.500
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -1078858.875 | Total reward: -1078858.875
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -780240.812 | Total reward: -780240.812
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -908759.438 | Total reward: -908759.438
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -1024777.875 | Total reward: -1024777.875
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -832038.750 | Total reward: -832038.750
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -871562.750 | Total reward: -871562.750
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -692064.938 | Total reward: -692064.938
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -850737.500 ± 136854.391
  Average reward: -850737.500 ± 136854.391
  Total reward: -850737.500 ± 136854.391
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -773379.438 | Total reward: -773379.438
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -1126116.750 | Total reward: -1126116.750
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -1192027.750 | Total reward: -1192027.750
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1531984.500 | Total reward: -1531984.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1647315840.000 | Total reward: -1647315840.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -1183640.875 | Total reward: -1183640.875
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -1207137.500 | Total reward: -1207137.500
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2040018304.000 | Total reward: -2040018304.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -1147738.125 | Total reward: -1147738.125
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -899541.812 | Total reward: -899541.812
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -369639584.000 ± 742226496.000
  Average reward: -369639584.000 ± 742226496.000
  Total reward: -369639584.000 ± 742226496.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.812 | Total reward: -967434.812
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.625 | Total reward: -867192.625
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902275.938 | Total reward: -902275.938
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808262.875 | Total reward: -808262.875
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.375 | Total reward: -714115.375
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.188
  Average reward: -815120.250 ± 93512.188
  Total reward: -815120.250 ± 93512.188
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -850737.500
Rule-based avg reward: -369639584.000
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
