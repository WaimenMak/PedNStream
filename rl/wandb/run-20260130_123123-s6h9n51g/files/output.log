Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.26s/it, episode=10, norm_ret=-8.877, true_ret=-363466208.000, steps=600]
Agent gate_2 episode reward: [-75.5139561]
All agents episode reward: [-75.5139561]
Agent gate_2 episode reward: [-2.09499401]
All agents episode reward: [-2.09499401]
Agent gate_2 episode reward: [-7.12856726]
All agents episode reward: [-7.12856726]
Agent gate_2 episode reward: [-2.03278585]
All agents episode reward: [-2.03278585]
Agent gate_2 episode reward: [-0.35389054]
All agents episode reward: [-0.35389054]
Agent gate_2 episode reward: [-0.31329547]
All agents episode reward: [-0.31329547]
Agent gate_2 episode reward: [-0.30180404]
All agents episode reward: [-0.30180404]
Agent gate_2 episode reward: [-0.32682243]
All agents episode reward: [-0.32682243]
Agent gate_2 episode reward: [-0.35228519]
All agents episode reward: [-0.35228519]
Agent gate_2 episode reward: [-0.35484978]
All agents episode reward: [-0.35484978]
Iteration 1: 100%|██████████| 10/10 [00:23<00:00,  2.32s/it, episode=20, norm_ret=-0.438, true_ret=-310635008.000, steps=600]
Agent gate_2 episode reward: [-0.37917303]
All agents episode reward: [-0.37917303]
Agent gate_2 episode reward: [-0.38931138]
All agents episode reward: [-0.38931138]
Agent gate_2 episode reward: [-0.41836184]
All agents episode reward: [-0.41836184]
Agent gate_2 episode reward: [-0.44982062]
All agents episode reward: [-0.44982062]
Agent gate_2 episode reward: [-0.46090981]
All agents episode reward: [-0.46090981]
Agent gate_2 episode reward: [-0.45198759]
All agents episode reward: [-0.45198759]
Agent gate_2 episode reward: [-0.4943002]
All agents episode reward: [-0.4943002]
Agent gate_2 episode reward: [-0.45809777]
All agents episode reward: [-0.45809777]
Agent gate_2 episode reward: [-0.47018418]
All agents episode reward: [-0.47018418]
Agent gate_2 episode reward: [-0.41255715]
All agents episode reward: [-0.41255715]
Iteration 2: 100%|██████████| 10/10 [00:22<00:00,  2.29s/it, episode=30, norm_ret=-0.546, true_ret=-361014656.000, steps=600]
Agent gate_2 episode reward: [-0.51133604]
All agents episode reward: [-0.51133604]
Agent gate_2 episode reward: [-0.51746337]
All agents episode reward: [-0.51746337]
Agent gate_2 episode reward: [-0.49332153]
All agents episode reward: [-0.49332153]
Agent gate_2 episode reward: [-0.55017159]
All agents episode reward: [-0.55017159]
Agent gate_2 episode reward: [-0.54901562]
All agents episode reward: [-0.54901562]
Agent gate_2 episode reward: [-0.54975949]
All agents episode reward: [-0.54975949]
Agent gate_2 episode reward: [-0.55510378]
All agents episode reward: [-0.55510378]
Agent gate_2 episode reward: [-0.5677131]
All agents episode reward: [-0.5677131]
Agent gate_2 episode reward: [-0.58885185]
All agents episode reward: [-0.58885185]
Agent gate_2 episode reward: [-0.58019377]
All agents episode reward: [-0.58019377]
Iteration 3: 100%|██████████| 10/10 [00:23<00:00,  2.39s/it, episode=40, norm_ret=-0.699, true_ret=-520556288.000, steps=600]
Agent gate_2 episode reward: [-0.59425912]
All agents episode reward: [-0.59425912]
Agent gate_2 episode reward: [-0.66067158]
All agents episode reward: [-0.66067158]
Agent gate_2 episode reward: [-0.65172528]
All agents episode reward: [-0.65172528]
Agent gate_2 episode reward: [-0.62605912]
All agents episode reward: [-0.62605912]
Agent gate_2 episode reward: [-0.6770021]
All agents episode reward: [-0.6770021]
Agent gate_2 episode reward: [-0.71343808]
All agents episode reward: [-0.71343808]
Agent gate_2 episode reward: [-0.7197801]
All agents episode reward: [-0.7197801]
Agent gate_2 episode reward: [-0.72434213]
All agents episode reward: [-0.72434213]
Agent gate_2 episode reward: [-0.6616988]
All agents episode reward: [-0.6616988]
Agent gate_2 episode reward: [-0.96113025]
All agents episode reward: [-0.96113025]
Iteration 4: 100%|██████████| 10/10 [00:24<00:00,  2.41s/it, episode=50, norm_ret=-0.814, true_ret=-409680192.000, steps=600]
Agent gate_2 episode reward: [-0.78558416]
All agents episode reward: [-0.78558416]
Agent gate_2 episode reward: [-0.8130303]
All agents episode reward: [-0.8130303]
Agent gate_2 episode reward: [-0.7595187]
All agents episode reward: [-0.7595187]
Agent gate_2 episode reward: [-0.8421905]
All agents episode reward: [-0.8421905]
Agent gate_2 episode reward: [-0.8409288]
All agents episode reward: [-0.8409288]
Agent gate_2 episode reward: [-0.87737484]
All agents episode reward: [-0.87737484]
Agent gate_2 episode reward: [-0.81514029]
All agents episode reward: [-0.81514029]
Agent gate_2 episode reward: [-0.80638388]
All agents episode reward: [-0.80638388]
Agent gate_2 episode reward: [-0.76091899]
All agents episode reward: [-0.76091899]
Agent gate_2 episode reward: [-0.84216252]
All agents episode reward: [-0.84216252]
Iteration 5: 100%|██████████| 10/10 [00:27<00:00,  2.71s/it, episode=60, norm_ret=-0.851, true_ret=-363808448.000, steps=600]
Agent gate_2 episode reward: [-0.81983044]
All agents episode reward: [-0.81983044]
Agent gate_2 episode reward: [-0.78193151]
All agents episode reward: [-0.78193151]
Agent gate_2 episode reward: [-0.81156588]
All agents episode reward: [-0.81156588]
Agent gate_2 episode reward: [-0.80299545]
All agents episode reward: [-0.80299545]
Agent gate_2 episode reward: [-0.78852276]
All agents episode reward: [-0.78852276]
Agent gate_2 episode reward: [-0.98151471]
All agents episode reward: [-0.98151471]
Agent gate_2 episode reward: [-0.90283324]
All agents episode reward: [-0.90283324]
Agent gate_2 episode reward: [-0.90574384]
All agents episode reward: [-0.90574384]
Agent gate_2 episode reward: [-0.90153055]
All agents episode reward: [-0.90153055]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -469154400.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.81722087]
All agents episode reward: [-0.81722087]
Iteration 6: 100%|██████████| 10/10 [00:28<00:00,  2.81s/it, episode=70, norm_ret=-1.238, true_ret=-409961888.000, steps=600]
Agent gate_2 episode reward: [-1.13070877]
All agents episode reward: [-1.13070877]
Agent gate_2 episode reward: [-1.74945817]
All agents episode reward: [-1.74945817]
Agent gate_2 episode reward: [-1.19286404]
All agents episode reward: [-1.19286404]
Agent gate_2 episode reward: [-1.19568187]
All agents episode reward: [-1.19568187]
Agent gate_2 episode reward: [-1.18428548]
All agents episode reward: [-1.18428548]
Agent gate_2 episode reward: [-1.16524897]
All agents episode reward: [-1.16524897]
Agent gate_2 episode reward: [-1.21605807]
All agents episode reward: [-1.21605807]
Agent gate_2 episode reward: [-1.23263244]
All agents episode reward: [-1.23263244]
Agent gate_2 episode reward: [-1.28309137]
All agents episode reward: [-1.28309137]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -448831328.000 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.02647695]
All agents episode reward: [-1.02647695]
Iteration 7: 100%|██████████| 10/10 [00:26<00:00,  2.66s/it, episode=80, norm_ret=-0.759, true_ret=-412921280.000, steps=600]
Agent gate_2 episode reward: [-0.83069759]
All agents episode reward: [-0.83069759]
Agent gate_2 episode reward: [-0.7345763]
All agents episode reward: [-0.7345763]
Agent gate_2 episode reward: [-0.56773364]
All agents episode reward: [-0.56773364]
Agent gate_2 episode reward: [-0.95765932]
All agents episode reward: [-0.95765932]
Agent gate_2 episode reward: [-0.65461594]
All agents episode reward: [-0.65461594]
Agent gate_2 episode reward: [-0.64808523]
All agents episode reward: [-0.64808523]
Agent gate_2 episode reward: [-0.73897694]
All agents episode reward: [-0.73897694]
Agent gate_2 episode reward: [-0.66789528]
All agents episode reward: [-0.66789528]
Agent gate_2 episode reward: [-0.65816414]
All agents episode reward: [-0.65816414]
Agent gate_2 episode reward: [-1.12915457]
All agents episode reward: [-1.12915457]
Iteration 8: 100%|██████████| 10/10 [00:27<00:00,  2.77s/it, episode=90, norm_ret=-1.484, true_ret=-467182464.000, steps=600]
Agent gate_2 episode reward: [-1.77843653]
All agents episode reward: [-1.77843653]
Agent gate_2 episode reward: [-1.55755468]
All agents episode reward: [-1.55755468]
Agent gate_2 episode reward: [-1.30549807]
All agents episode reward: [-1.30549807]
Agent gate_2 episode reward: [-1.38609647]
All agents episode reward: [-1.38609647]
Agent gate_2 episode reward: [-1.34888397]
All agents episode reward: [-1.34888397]
Agent gate_2 episode reward: [-1.36846862]
All agents episode reward: [-1.36846862]
Agent gate_2 episode reward: [-1.44835825]
All agents episode reward: [-1.44835825]
Agent gate_2 episode reward: [-1.7845584]
All agents episode reward: [-1.7845584]
Agent gate_2 episode reward: [-1.48607828]
All agents episode reward: [-1.48607828]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -362927712.000 at episode 90 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.37827652]
All agents episode reward: [-1.37827652]
Iteration 9: 100%|██████████| 10/10 [00:27<00:00,  2.73s/it, episode=100, norm_ret=-1.109, true_ret=-347440192.000, steps=600]
Agent gate_2 episode reward: [-1.05315711]
All agents episode reward: [-1.05315711]
Agent gate_2 episode reward: [-1.12841245]
All agents episode reward: [-1.12841245]
Agent gate_2 episode reward: [-1.08106369]
All agents episode reward: [-1.08106369]
Agent gate_2 episode reward: [-1.09033067]
All agents episode reward: [-1.09033067]
Agent gate_2 episode reward: [-1.12534751]
All agents episode reward: [-1.12534751]
Agent gate_2 episode reward: [-1.08922079]
All agents episode reward: [-1.08922079]
Agent gate_2 episode reward: [-1.13272558]
All agents episode reward: [-1.13272558]
Agent gate_2 episode reward: [-1.1616779]
All agents episode reward: [-1.1616779]
Agent gate_2 episode reward: [-1.13889192]
All agents episode reward: [-1.13889192]
Agent gate_2 episode reward: [-1.09381401]
All agents episode reward: [-1.09381401]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -398116320.000 | Total reward: -398116320.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -468400224.000 | Total reward: -468400224.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -553754048.000 | Total reward: -553754048.000
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -764002048.000 | Total reward: -764002048.000
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -520231072.000 | Total reward: -520231072.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -554268544.000 | Total reward: -554268544.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -722602368.000 | Total reward: -722602368.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -510459904.000 | Total reward: -510459904.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -500518976.000 | Total reward: -500518976.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -397191936.000 | Total reward: -397191936.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -538954560.000 ± 115054856.000
  Average reward: -538954560.000 ± 115054856.000
  Total reward: -538954560.000 ± 115054856.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -532353664.000 | Total reward: -532353664.000
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -798209984.000 | Total reward: -798209984.000
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -900830528.000 | Total reward: -900830528.000
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1446963968.000 | Total reward: -1446963968.000
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -1436398518272.000 | Total reward: -1436398518272.000
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -946699200.000 | Total reward: -946699200.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -1034241344.000 | Total reward: -1034241344.000
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -2097243619328.000 | Total reward: -2097243619328.000
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -828239168.000 | Total reward: -828239168.000
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -582239936.000 | Total reward: -582239936.000
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -354071183360.000 ± 721665720320.000
  Average reward: -354071183360.000 ± 721665720320.000
  Total reward: -354071183360.000 ± 721665720320.000
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -284972160.000 | Total reward: -284972160.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -461498592.000 | Total reward: -461498592.000
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -521870880.000 | Total reward: -521870880.000
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -614536768.000 | Total reward: -614536768.000
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -428394432.000 | Total reward: -428394432.000
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -523360512.000 | Total reward: -523360512.000
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -555276480.000 | Total reward: -555276480.000
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -465481600.000 | Total reward: -465481600.000
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -485360800.000 | Total reward: -485360800.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -368947584.000 | Total reward: -368947584.000
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -470970016.000 ± 89553360.000
  Average reward: -470970016.000 ± 89553360.000
  Total reward: -470970016.000 ± 89553360.000
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -538954560.000
Rule-based avg reward: -354071183360.000
No control avg reward: -470970016.000
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
