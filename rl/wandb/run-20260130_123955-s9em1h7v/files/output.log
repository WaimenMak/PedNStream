Iteration 0: 100%|██████████| 10/10 [00:23<00:00,  2.37s/it, episode=10, norm_ret=-7.476, true_ret=-734213.688, steps=600]
Agent gate_2 episode reward: [-60.65328456]
All agents episode reward: [-60.65328456]
Agent gate_2 episode reward: [-2.27432935]
All agents episode reward: [-2.27432935]
Agent gate_2 episode reward: [-5.22715488]
All agents episode reward: [-5.22715488]
Agent gate_2 episode reward: [-2.30145083]
All agents episode reward: [-2.30145083]
Agent gate_2 episode reward: [-0.70015194]
All agents episode reward: [-0.70015194]
Agent gate_2 episode reward: [-0.6636267]
All agents episode reward: [-0.6636267]
Agent gate_2 episode reward: [-0.65372611]
All agents episode reward: [-0.65372611]
Agent gate_2 episode reward: [-0.70966118]
All agents episode reward: [-0.70966118]
Agent gate_2 episode reward: [-0.76357473]
All agents episode reward: [-0.76357473]
Agent gate_2 episode reward: [-0.80916669]
All agents episode reward: [-0.80916669]
Iteration 1: 100%|██████████| 10/10 [00:23<00:00,  2.39s/it, episode=20, norm_ret=-1.091, true_ret=-1414050.875, steps=600]
Agent gate_2 episode reward: [-0.8030399]
All agents episode reward: [-0.8030399]
Agent gate_2 episode reward: [-0.8443146]
All agents episode reward: [-0.8443146]
Agent gate_2 episode reward: [-0.92688506]
All agents episode reward: [-0.92688506]
Agent gate_2 episode reward: [-0.94043069]
All agents episode reward: [-0.94043069]
Agent gate_2 episode reward: [-0.91765606]
All agents episode reward: [-0.91765606]
Agent gate_2 episode reward: [-0.98046435]
All agents episode reward: [-0.98046435]
Agent gate_2 episode reward: [-1.28053294]
All agents episode reward: [-1.28053294]
Agent gate_2 episode reward: [-1.01882923]
All agents episode reward: [-1.01882923]
Agent gate_2 episode reward: [-1.06867342]
All agents episode reward: [-1.06867342]
Agent gate_2 episode reward: [-2.12944399]
All agents episode reward: [-2.12944399]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.37s/it, episode=30, norm_ret=-1.307, true_ret=-727352.125, steps=600]
Agent gate_2 episode reward: [-1.15503014]
All agents episode reward: [-1.15503014]
Agent gate_2 episode reward: [-1.18841977]
All agents episode reward: [-1.18841977]
Agent gate_2 episode reward: [-1.17631462]
All agents episode reward: [-1.17631462]
Agent gate_2 episode reward: [-1.16835976]
All agents episode reward: [-1.16835976]
Agent gate_2 episode reward: [-1.25436548]
All agents episode reward: [-1.25436548]
Agent gate_2 episode reward: [-1.24451212]
All agents episode reward: [-1.24451212]
Agent gate_2 episode reward: [-1.2484173]
All agents episode reward: [-1.2484173]
Agent gate_2 episode reward: [-1.99204748]
All agents episode reward: [-1.99204748]
Agent gate_2 episode reward: [-1.30964706]
All agents episode reward: [-1.30964706]
Agent gate_2 episode reward: [-1.32890971]
All agents episode reward: [-1.32890971]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.29s/it, episode=40, norm_ret=-1.475, true_ret=-777838.062, steps=600]
Agent gate_2 episode reward: [-1.39176167]
All agents episode reward: [-1.39176167]
Agent gate_2 episode reward: [-1.37695154]
All agents episode reward: [-1.37695154]
Agent gate_2 episode reward: [-1.34729307]
All agents episode reward: [-1.34729307]
Agent gate_2 episode reward: [-1.44795276]
All agents episode reward: [-1.44795276]
Agent gate_2 episode reward: [-1.50629981]
All agents episode reward: [-1.50629981]
Agent gate_2 episode reward: [-1.51016161]
All agents episode reward: [-1.51016161]
Agent gate_2 episode reward: [-1.47659858]
All agents episode reward: [-1.47659858]
Agent gate_2 episode reward: [-1.54763596]
All agents episode reward: [-1.54763596]
Agent gate_2 episode reward: [-1.51254175]
All agents episode reward: [-1.51254175]
Agent gate_2 episode reward: [-1.63080325]
All agents episode reward: [-1.63080325]
Iteration 4: 100%|██████████| 10/10 [00:24<00:00,  2.43s/it, episode=50, norm_ret=-1.664, true_ret=-735540.250, steps=600]
Agent gate_2 episode reward: [-1.61777876]
All agents episode reward: [-1.61777876]
Agent gate_2 episode reward: [-1.62052417]
All agents episode reward: [-1.62052417]
Agent gate_2 episode reward: [-1.60331666]
All agents episode reward: [-1.60331666]
Agent gate_2 episode reward: [-1.72701288]
All agents episode reward: [-1.72701288]
Agent gate_2 episode reward: [-1.65760716]
All agents episode reward: [-1.65760716]
Agent gate_2 episode reward: [-1.70507949]
All agents episode reward: [-1.70507949]
Agent gate_2 episode reward: [-1.5814445]
All agents episode reward: [-1.5814445]
Agent gate_2 episode reward: [-1.71904344]
All agents episode reward: [-1.71904344]
Agent gate_2 episode reward: [-1.68909294]
All agents episode reward: [-1.68909294]
Agent gate_2 episode reward: [-1.71702132]
All agents episode reward: [-1.71702132]
Iteration 5: 100%|██████████| 10/10 [00:28<00:00,  2.89s/it, episode=60, norm_ret=-1.756, true_ret=-649076.062, steps=600]
Agent gate_2 episode reward: [-1.69452527]
All agents episode reward: [-1.69452527]
Agent gate_2 episode reward: [-1.73024793]
All agents episode reward: [-1.73024793]
Agent gate_2 episode reward: [-1.8275233]
All agents episode reward: [-1.8275233]
Agent gate_2 episode reward: [-1.7419903]
All agents episode reward: [-1.7419903]
Agent gate_2 episode reward: [-1.68861937]
All agents episode reward: [-1.68861937]
Agent gate_2 episode reward: [-1.81426598]
All agents episode reward: [-1.81426598]
Agent gate_2 episode reward: [-1.8135778]
All agents episode reward: [-1.8135778]
Agent gate_2 episode reward: [-1.83948294]
All agents episode reward: [-1.83948294]
Agent gate_2 episode reward: [-1.75901521]
All agents episode reward: [-1.75901521]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -703102.875 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.65388478]
All agents episode reward: [-1.65388478]
Iteration 6: 100%|██████████| 10/10 [00:28<00:00,  2.81s/it, episode=70, norm_ret=-1.094, true_ret=-364888.781, steps=600]
Agent gate_2 episode reward: [-0.91574987]
All agents episode reward: [-0.91574987]
Agent gate_2 episode reward: [-1.19666555]
All agents episode reward: [-1.19666555]
Agent gate_2 episode reward: [-1.35868043]
All agents episode reward: [-1.35868043]
Agent gate_2 episode reward: [-1.00421286]
All agents episode reward: [-1.00421286]
Agent gate_2 episode reward: [-1.08844537]
All agents episode reward: [-1.08844537]
Agent gate_2 episode reward: [-1.23275445]
All agents episode reward: [-1.23275445]
Agent gate_2 episode reward: [-0.94744775]
All agents episode reward: [-0.94744775]
Agent gate_2 episode reward: [-1.06134862]
All agents episode reward: [-1.06134862]
Agent gate_2 episode reward: [-1.10444582]
All agents episode reward: [-1.10444582]
Agent gate_2 episode reward: [-1.03263289]
All agents episode reward: [-1.03263289]
Iteration 7: 100%|██████████| 10/10 [00:27<00:00,  2.77s/it, episode=80, norm_ret=-2.776, true_ret=-1006681.562, steps=600]
Agent gate_2 episode reward: [-2.77065472]
All agents episode reward: [-2.77065472]
Agent gate_2 episode reward: [-2.10030565]
All agents episode reward: [-2.10030565]
Agent gate_2 episode reward: [-5.25040236]
All agents episode reward: [-5.25040236]
Agent gate_2 episode reward: [-3.66331012]
All agents episode reward: [-3.66331012]
Agent gate_2 episode reward: [-3.1507135]
All agents episode reward: [-3.1507135]
Agent gate_2 episode reward: [-1.9680853]
All agents episode reward: [-1.9680853]
Agent gate_2 episode reward: [-1.97424069]
All agents episode reward: [-1.97424069]
Agent gate_2 episode reward: [-1.84628496]
All agents episode reward: [-1.84628496]
Agent gate_2 episode reward: [-1.93188567]
All agents episode reward: [-1.93188567]
Agent gate_2 episode reward: [-3.10068063]
All agents episode reward: [-3.10068063]
Iteration 8: 100%|██████████| 10/10 [00:26<00:00,  2.62s/it, episode=90, norm_ret=-2.875, true_ret=-743774.875, steps=600]
Agent gate_2 episode reward: [-3.4753004]
All agents episode reward: [-3.4753004]
Agent gate_2 episode reward: [-2.55816782]
All agents episode reward: [-2.55816782]
Agent gate_2 episode reward: [-2.289099]
All agents episode reward: [-2.289099]
Agent gate_2 episode reward: [-2.27695798]
All agents episode reward: [-2.27695798]
Agent gate_2 episode reward: [-4.65355787]
All agents episode reward: [-4.65355787]
Agent gate_2 episode reward: [-4.05559363]
All agents episode reward: [-4.05559363]
Agent gate_2 episode reward: [-2.42224684]
All agents episode reward: [-2.42224684]
Agent gate_2 episode reward: [-2.24612191]
All agents episode reward: [-2.24612191]
Agent gate_2 episode reward: [-2.31820798]
All agents episode reward: [-2.31820798]
Agent gate_2 episode reward: [-2.45665631]
All agents episode reward: [-2.45665631]
Iteration 9: 100%|██████████| 10/10 [00:26<00:00,  2.69s/it, episode=100, norm_ret=-3.032, true_ret=-845119.562, steps=600]
Agent gate_2 episode reward: [-2.94516188]
All agents episode reward: [-2.94516188]
Agent gate_2 episode reward: [-3.05870559]
All agents episode reward: [-3.05870559]
Agent gate_2 episode reward: [-3.1696076]
All agents episode reward: [-3.1696076]
Agent gate_2 episode reward: [-2.91873419]
All agents episode reward: [-2.91873419]
Agent gate_2 episode reward: [-2.93449684]
All agents episode reward: [-2.93449684]
Agent gate_2 episode reward: [-3.19046639]
All agents episode reward: [-3.19046639]
Agent gate_2 episode reward: [-3.01272205]
All agents episode reward: [-3.01272205]
Agent gate_2 episode reward: [-3.00270495]
All agents episode reward: [-3.00270495]
Agent gate_2 episode reward: [-3.1103493]
All agents episode reward: [-3.1103493]
Agent gate_2 episode reward: [-2.97552927]
All agents episode reward: [-2.97552927]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -686883.188 | Total reward: -686883.188
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -814598.000 | Total reward: -814598.000
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -857496.625 | Total reward: -857496.625
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -957944.438 | Total reward: -957944.438
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -807897.812 | Total reward: -807897.812
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -836985.250 | Total reward: -836985.250
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -916964.625 | Total reward: -916964.625
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -785385.750 | Total reward: -785385.750
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -843410.750 | Total reward: -843410.750
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -764181.562 | Total reward: -764181.562
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -827174.875 ± 72365.844
  Average reward: -827174.875 ± 72365.844
  Total reward: -827174.875 ± 72365.844
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -643709.938 | Total reward: -643709.938
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -851560.312 | Total reward: -851560.312
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -920434.062 | Total reward: -920434.062
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1048110.500 | Total reward: -1048110.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -791232.562 | Total reward: -791232.562
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -907931.000 | Total reward: -907931.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -959172.375 | Total reward: -959172.375
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -854216.688 | Total reward: -854216.688
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -870864.875 | Total reward: -870864.875
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -711501.500 | Total reward: -711501.500
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -855873.375 ± 111707.195
  Average reward: -855873.375 ± 111707.195
  Total reward: -855873.375 ± 111707.195
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.812 | Total reward: -967434.812
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.625 | Total reward: -867192.625
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902275.938 | Total reward: -902275.938
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808262.875 | Total reward: -808262.875
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.375 | Total reward: -714115.375
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.188
  Average reward: -815120.250 ± 93512.188
  Total reward: -815120.250 ± 93512.188
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -827174.875
Rule-based avg reward: -855873.375
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
