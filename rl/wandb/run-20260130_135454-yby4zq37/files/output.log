Iteration 0: 100%|██████████| 10/10 [00:24<00:00,  2.45s/it, episode=10, norm_ret=-8.093, true_ret=-795877.688, steps=600]
Agent gate_2 episode reward: [-61.91344159]
All agents episode reward: [-61.91344159]
Agent gate_2 episode reward: [-9.26635674]
All agents episode reward: [-9.26635674]
Agent gate_2 episode reward: [-3.51771164]
All agents episode reward: [-3.51771164]
Agent gate_2 episode reward: [-1.75888684]
All agents episode reward: [-1.75888684]
Agent gate_2 episode reward: [-0.77425339]
All agents episode reward: [-0.77425339]
Agent gate_2 episode reward: [-0.56071812]
All agents episode reward: [-0.56071812]
Agent gate_2 episode reward: [-0.59629343]
All agents episode reward: [-0.59629343]
Agent gate_2 episode reward: [-1.17254277]
All agents episode reward: [-1.17254277]
Agent gate_2 episode reward: [-0.6315645]
All agents episode reward: [-0.6315645]
Agent gate_2 episode reward: [-0.73693072]
All agents episode reward: [-0.73693072]
Iteration 1: 100%|██████████| 10/10 [00:25<00:00,  2.51s/it, episode=20, norm_ret=-0.804, true_ret=-714477.688, steps=600]
Agent gate_2 episode reward: [-0.65071116]
All agents episode reward: [-0.65071116]
Agent gate_2 episode reward: [-0.70948081]
All agents episode reward: [-0.70948081]
Agent gate_2 episode reward: [-0.74752312]
All agents episode reward: [-0.74752312]
Agent gate_2 episode reward: [-0.76604522]
All agents episode reward: [-0.76604522]
Agent gate_2 episode reward: [-0.7860643]
All agents episode reward: [-0.7860643]
Agent gate_2 episode reward: [-0.82845956]
All agents episode reward: [-0.82845956]
Agent gate_2 episode reward: [-0.82557701]
All agents episode reward: [-0.82557701]
Agent gate_2 episode reward: [-0.92705024]
All agents episode reward: [-0.92705024]
Agent gate_2 episode reward: [-0.90833435]
All agents episode reward: [-0.90833435]
Agent gate_2 episode reward: [-0.88630605]
All agents episode reward: [-0.88630605]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.35s/it, episode=30, norm_ret=-1.001, true_ret=-715791.938, steps=600]
Agent gate_2 episode reward: [-0.93068619]
All agents episode reward: [-0.93068619]
Agent gate_2 episode reward: [-0.9109022]
All agents episode reward: [-0.9109022]
Agent gate_2 episode reward: [-0.96286263]
All agents episode reward: [-0.96286263]
Agent gate_2 episode reward: [-0.95489784]
All agents episode reward: [-0.95489784]
Agent gate_2 episode reward: [-1.00232134]
All agents episode reward: [-1.00232134]
Agent gate_2 episode reward: [-1.01425191]
All agents episode reward: [-1.01425191]
Agent gate_2 episode reward: [-1.02922822]
All agents episode reward: [-1.02922822]
Agent gate_2 episode reward: [-1.03815096]
All agents episode reward: [-1.03815096]
Agent gate_2 episode reward: [-1.09392436]
All agents episode reward: [-1.09392436]
Agent gate_2 episode reward: [-1.0699369]
All agents episode reward: [-1.0699369]
Iteration 3: 100%|██████████| 10/10 [00:23<00:00,  2.40s/it, episode=40, norm_ret=-1.165, true_ret=-711481.125, steps=600]
Agent gate_2 episode reward: [-1.0988506]
All agents episode reward: [-1.0988506]
Agent gate_2 episode reward: [-1.15018813]
All agents episode reward: [-1.15018813]
Agent gate_2 episode reward: [-1.09061485]
All agents episode reward: [-1.09061485]
Agent gate_2 episode reward: [-1.15602633]
All agents episode reward: [-1.15602633]
Agent gate_2 episode reward: [-1.15609448]
All agents episode reward: [-1.15609448]
Agent gate_2 episode reward: [-1.16486152]
All agents episode reward: [-1.16486152]
Agent gate_2 episode reward: [-1.20658829]
All agents episode reward: [-1.20658829]
Agent gate_2 episode reward: [-1.19214136]
All agents episode reward: [-1.19214136]
Agent gate_2 episode reward: [-1.2199505]
All agents episode reward: [-1.2199505]
Agent gate_2 episode reward: [-1.21810974]
All agents episode reward: [-1.21810974]
Iteration 4: 100%|██████████| 10/10 [00:24<00:00,  2.46s/it, episode=50, norm_ret=-1.328, true_ret=-730677.312, steps=600]
Agent gate_2 episode reward: [-1.25117]
All agents episode reward: [-1.25117]
Agent gate_2 episode reward: [-1.24547141]
All agents episode reward: [-1.24547141]
Agent gate_2 episode reward: [-1.26563897]
All agents episode reward: [-1.26563897]
Agent gate_2 episode reward: [-1.33803887]
All agents episode reward: [-1.33803887]
Agent gate_2 episode reward: [-1.31158379]
All agents episode reward: [-1.31158379]
Agent gate_2 episode reward: [-1.33128069]
All agents episode reward: [-1.33128069]
Agent gate_2 episode reward: [-1.38141741]
All agents episode reward: [-1.38141741]
Agent gate_2 episode reward: [-1.36423671]
All agents episode reward: [-1.36423671]
Agent gate_2 episode reward: [-1.39797073]
All agents episode reward: [-1.39797073]
Agent gate_2 episode reward: [-1.39163499]
All agents episode reward: [-1.39163499]
Iteration 5: 100%|██████████| 10/10 [00:28<00:00,  2.86s/it, episode=60, norm_ret=-1.432, true_ret=-707600.125, steps=600]
Agent gate_2 episode reward: [-1.34470487]
All agents episode reward: [-1.34470487]
Agent gate_2 episode reward: [-1.41017056]
All agents episode reward: [-1.41017056]
Agent gate_2 episode reward: [-1.38695276]
All agents episode reward: [-1.38695276]
Agent gate_2 episode reward: [-1.46853048]
All agents episode reward: [-1.46853048]
Agent gate_2 episode reward: [-1.4436911]
All agents episode reward: [-1.4436911]
Agent gate_2 episode reward: [-1.44570251]
All agents episode reward: [-1.44570251]
Agent gate_2 episode reward: [-1.46869192]
All agents episode reward: [-1.46869192]
Agent gate_2 episode reward: [-1.4070143]
All agents episode reward: [-1.4070143]
Agent gate_2 episode reward: [-1.46949295]
All agents episode reward: [-1.46949295]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -740758.375 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.47099053]
All agents episode reward: [-1.47099053]
Iteration 6: 100%|██████████| 10/10 [00:28<00:00,  2.85s/it, episode=70, norm_ret=-1.248, true_ret=-543514.688, steps=600]
Agent gate_2 episode reward: [-1.15636889]
All agents episode reward: [-1.15636889]
Agent gate_2 episode reward: [-1.11690628]
All agents episode reward: [-1.11690628]
Agent gate_2 episode reward: [-1.12360907]
All agents episode reward: [-1.12360907]
Agent gate_2 episode reward: [-1.04542854]
All agents episode reward: [-1.04542854]
Agent gate_2 episode reward: [-1.26882466]
All agents episode reward: [-1.26882466]
Agent gate_2 episode reward: [-1.81969327]
All agents episode reward: [-1.81969327]
Agent gate_2 episode reward: [-1.18241617]
All agents episode reward: [-1.18241617]
Agent gate_2 episode reward: [-1.25605667]
All agents episode reward: [-1.25605667]
Agent gate_2 episode reward: [-1.25064348]
All agents episode reward: [-1.25064348]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -537848.375 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-1.25662578]
All agents episode reward: [-1.25662578]
Iteration 7: 100%|██████████| 10/10 [00:27<00:00,  2.78s/it, episode=80, norm_ret=-1.791, true_ret=-718653.250, steps=600]
Agent gate_2 episode reward: [-1.74002452]
All agents episode reward: [-1.74002452]
Agent gate_2 episode reward: [-1.74032462]
All agents episode reward: [-1.74032462]
Agent gate_2 episode reward: [-1.78198712]
All agents episode reward: [-1.78198712]
Agent gate_2 episode reward: [-1.75916388]
All agents episode reward: [-1.75916388]
Agent gate_2 episode reward: [-1.82219245]
All agents episode reward: [-1.82219245]
Agent gate_2 episode reward: [-1.81284557]
All agents episode reward: [-1.81284557]
Agent gate_2 episode reward: [-1.78238551]
All agents episode reward: [-1.78238551]
Agent gate_2 episode reward: [-1.83331475]
All agents episode reward: [-1.83331475]
Agent gate_2 episode reward: [-1.81928888]
All agents episode reward: [-1.81928888]
Agent gate_2 episode reward: [-1.81375036]
All agents episode reward: [-1.81375036]
Iteration 8: 100%|██████████| 10/10 [00:28<00:00,  2.81s/it, episode=90, norm_ret=-2.572, true_ret=-960212.750, steps=600]
Agent gate_2 episode reward: [-2.57185363]
All agents episode reward: [-2.57185363]
Agent gate_2 episode reward: [-2.53073108]
All agents episode reward: [-2.53073108]
Agent gate_2 episode reward: [-2.49883516]
All agents episode reward: [-2.49883516]
Agent gate_2 episode reward: [-2.5488546]
All agents episode reward: [-2.5488546]
Agent gate_2 episode reward: [-2.53097031]
All agents episode reward: [-2.53097031]
Agent gate_2 episode reward: [-2.57243421]
All agents episode reward: [-2.57243421]
Agent gate_2 episode reward: [-2.66452141]
All agents episode reward: [-2.66452141]
Agent gate_2 episode reward: [-2.563068]
All agents episode reward: [-2.563068]
Agent gate_2 episode reward: [-2.63180871]
All agents episode reward: [-2.63180871]
Agent gate_2 episode reward: [-2.61095328]
All agents episode reward: [-2.61095328]
Iteration 9: 100%|██████████| 10/10 [00:27<00:00,  2.80s/it, episode=100, norm_ret=-2.316, true_ret=-804123.875, steps=600]
Agent gate_2 episode reward: [-2.26278868]
All agents episode reward: [-2.26278868]
Agent gate_2 episode reward: [-2.28051208]
All agents episode reward: [-2.28051208]
Agent gate_2 episode reward: [-2.29428514]
All agents episode reward: [-2.29428514]
Agent gate_2 episode reward: [-2.27408982]
All agents episode reward: [-2.27408982]
Agent gate_2 episode reward: [-2.28473287]
All agents episode reward: [-2.28473287]
Agent gate_2 episode reward: [-2.33807853]
All agents episode reward: [-2.33807853]
Agent gate_2 episode reward: [-2.35498803]
All agents episode reward: [-2.35498803]
Agent gate_2 episode reward: [-2.37314178]
All agents episode reward: [-2.37314178]
Agent gate_2 episode reward: [-2.36497825]
All agents episode reward: [-2.36497825]
Agent gate_2 episode reward: [-2.33275564]
All agents episode reward: [-2.33275564]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -967434.812 | Total reward: -967434.812
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -867192.625 | Total reward: -867192.625
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -902275.938 | Total reward: -902275.938
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -808262.875 | Total reward: -808262.875
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -714115.375 | Total reward: -714115.375
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.188
  Average reward: -815120.250 ± 93512.188
  Total reward: -815120.250 ± 93512.188
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -643709.938 | Total reward: -643709.938
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -851560.312 | Total reward: -851560.312
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -920434.062 | Total reward: -920434.062
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1048110.500 | Total reward: -1048110.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -791232.562 | Total reward: -791232.562
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -907931.000 | Total reward: -907931.000
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -959172.375 | Total reward: -959172.375
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -854216.688 | Total reward: -854216.688
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -870864.875 | Total reward: -870864.875
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -711501.500 | Total reward: -711501.500
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -855873.375 ± 111707.195
  Average reward: -855873.375 ± 111707.195
  Total reward: -855873.375 ± 111707.195
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.812 | Total reward: -967434.812
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.625 | Total reward: -867192.625
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902275.938 | Total reward: -902275.938
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808262.875 | Total reward: -808262.875
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.375 | Total reward: -714115.375
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.188
  Average reward: -815120.250 ± 93512.188
  Total reward: -815120.250 ± 93512.188
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -815120.250
Rule-based avg reward: -855873.375
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
