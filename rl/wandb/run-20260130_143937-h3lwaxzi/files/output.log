Iteration 0: 100%|██████████| 10/10 [00:20<00:00,  2.08s/it, episode=10, norm_ret=-17.748, true_ret=-18129.904, steps=600]
Agent gate_2 episode reward: [-62.85522389]
All agents episode reward: [-62.85522389]
Agent gate_2 episode reward: [-12.05469524]
All agents episode reward: [-12.05469524]
Agent gate_2 episode reward: [-12.2400962]
All agents episode reward: [-12.2400962]
Agent gate_2 episode reward: [-16.48263805]
All agents episode reward: [-16.48263805]
Agent gate_2 episode reward: [-11.67717988]
All agents episode reward: [-11.67717988]
Agent gate_2 episode reward: [-13.79996543]
All agents episode reward: [-13.79996543]
Agent gate_2 episode reward: [-12.20656841]
All agents episode reward: [-12.20656841]
Agent gate_2 episode reward: [-11.31505363]
All agents episode reward: [-11.31505363]
Agent gate_2 episode reward: [-10.86481116]
All agents episode reward: [-10.86481116]
Agent gate_2 episode reward: [-13.98578584]
All agents episode reward: [-13.98578584]
Iteration 1: 100%|██████████| 10/10 [00:20<00:00,  2.05s/it, episode=20, norm_ret=-13.327, true_ret=-21294.852, steps=600]
Agent gate_2 episode reward: [-10.45335844]
All agents episode reward: [-10.45335844]
Agent gate_2 episode reward: [-15.36401243]
All agents episode reward: [-15.36401243]
Agent gate_2 episode reward: [-9.64379221]
All agents episode reward: [-9.64379221]
Agent gate_2 episode reward: [-16.17462365]
All agents episode reward: [-16.17462365]
Agent gate_2 episode reward: [-14.87806234]
All agents episode reward: [-14.87806234]
Agent gate_2 episode reward: [-12.35827907]
All agents episode reward: [-12.35827907]
Agent gate_2 episode reward: [-11.31244245]
All agents episode reward: [-11.31244245]
Agent gate_2 episode reward: [-14.75060248]
All agents episode reward: [-14.75060248]
Agent gate_2 episode reward: [-13.34293875]
All agents episode reward: [-13.34293875]
Agent gate_2 episode reward: [-14.99193424]
All agents episode reward: [-14.99193424]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.32s/it, episode=30, norm_ret=-13.591, true_ret=-20390.932, steps=600]
Agent gate_2 episode reward: [-13.98480279]
All agents episode reward: [-13.98480279]
Agent gate_2 episode reward: [-13.17509166]
All agents episode reward: [-13.17509166]
Agent gate_2 episode reward: [-15.54303203]
All agents episode reward: [-15.54303203]
Agent gate_2 episode reward: [-13.04652991]
All agents episode reward: [-13.04652991]
Agent gate_2 episode reward: [-13.74482945]
All agents episode reward: [-13.74482945]
Agent gate_2 episode reward: [-12.92868315]
All agents episode reward: [-12.92868315]
Agent gate_2 episode reward: [-13.38575333]
All agents episode reward: [-13.38575333]
Agent gate_2 episode reward: [-13.84882513]
All agents episode reward: [-13.84882513]
Agent gate_2 episode reward: [-13.03733154]
All agents episode reward: [-13.03733154]
Agent gate_2 episode reward: [-13.21969886]
All agents episode reward: [-13.21969886]
Iteration 3: 100%|██████████| 10/10 [00:20<00:00,  2.03s/it, episode=40, norm_ret=-12.862, true_ret=-21678.061, steps=600]
Agent gate_2 episode reward: [-12.89960833]
All agents episode reward: [-12.89960833]
Agent gate_2 episode reward: [-12.95933852]
All agents episode reward: [-12.95933852]
Agent gate_2 episode reward: [-12.94273137]
All agents episode reward: [-12.94273137]
Agent gate_2 episode reward: [-12.87514506]
All agents episode reward: [-12.87514506]
Agent gate_2 episode reward: [-12.77252303]
All agents episode reward: [-12.77252303]
Agent gate_2 episode reward: [-12.93347817]
All agents episode reward: [-12.93347817]
Agent gate_2 episode reward: [-13.02773124]
All agents episode reward: [-13.02773124]
Agent gate_2 episode reward: [-11.15736596]
All agents episode reward: [-11.15736596]
Agent gate_2 episode reward: [-13.50395746]
All agents episode reward: [-13.50395746]
Agent gate_2 episode reward: [-13.55058264]
All agents episode reward: [-13.55058264]
Iteration 4: 100%|██████████| 10/10 [00:20<00:00,  2.07s/it, episode=50, norm_ret=-10.851, true_ret=-21081.975, steps=600]
Agent gate_2 episode reward: [-10.84343017]
All agents episode reward: [-10.84343017]
Agent gate_2 episode reward: [-9.5202241]
All agents episode reward: [-9.5202241]
Agent gate_2 episode reward: [-10.81548058]
All agents episode reward: [-10.81548058]
Agent gate_2 episode reward: [-9.44147581]
All agents episode reward: [-9.44147581]
Agent gate_2 episode reward: [-10.11042563]
All agents episode reward: [-10.11042563]
Agent gate_2 episode reward: [-11.52070424]
All agents episode reward: [-11.52070424]
Agent gate_2 episode reward: [-11.27288749]
All agents episode reward: [-11.27288749]
Agent gate_2 episode reward: [-10.00414269]
All agents episode reward: [-10.00414269]
Agent gate_2 episode reward: [-11.70881885]
All agents episode reward: [-11.70881885]
Agent gate_2 episode reward: [-13.27641557]
All agents episode reward: [-13.27641557]
Iteration 5: 100%|██████████| 10/10 [00:25<00:00,  2.51s/it, episode=60, norm_ret=-12.240, true_ret=-19875.010, steps=600]
Agent gate_2 episode reward: [-12.63308225]
All agents episode reward: [-12.63308225]
Agent gate_2 episode reward: [-12.47441915]
All agents episode reward: [-12.47441915]
Agent gate_2 episode reward: [-10.41303298]
All agents episode reward: [-10.41303298]
Agent gate_2 episode reward: [-12.49747182]
All agents episode reward: [-12.49747182]
Agent gate_2 episode reward: [-12.61472628]
All agents episode reward: [-12.61472628]
Agent gate_2 episode reward: [-13.02417389]
All agents episode reward: [-13.02417389]
Agent gate_2 episode reward: [-11.88584828]
All agents episode reward: [-11.88584828]
Agent gate_2 episode reward: [-13.12319142]
All agents episode reward: [-13.12319142]
Agent gate_2 episode reward: [-11.41573257]
All agents episode reward: [-11.41573257]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -22308.475 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-12.32287829]
All agents episode reward: [-12.32287829]
Iteration 6: 100%|██████████| 10/10 [00:24<00:00,  2.49s/it, episode=70, norm_ret=-13.434, true_ret=-21195.840, steps=600]
Agent gate_2 episode reward: [-14.31853874]
All agents episode reward: [-14.31853874]
Agent gate_2 episode reward: [-13.52396883]
All agents episode reward: [-13.52396883]
Agent gate_2 episode reward: [-13.48448122]
All agents episode reward: [-13.48448122]
Agent gate_2 episode reward: [-13.0587794]
All agents episode reward: [-13.0587794]
Agent gate_2 episode reward: [-13.43961687]
All agents episode reward: [-13.43961687]
Agent gate_2 episode reward: [-13.7429298]
All agents episode reward: [-13.7429298]
Agent gate_2 episode reward: [-13.60959737]
All agents episode reward: [-13.60959737]
Agent gate_2 episode reward: [-13.36485956]
All agents episode reward: [-13.36485956]
Agent gate_2 episode reward: [-13.27134133]
All agents episode reward: [-13.27134133]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -19835.141 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-12.52948324]
All agents episode reward: [-12.52948324]
Iteration 7: 100%|██████████| 10/10 [00:17<00:00,  1.72s/it, episode=80, norm_ret=-14.063, true_ret=-24235.807, steps=600]
Agent gate_2 episode reward: [-14.23923133]
All agents episode reward: [-14.23923133]
Agent gate_2 episode reward: [-14.23310543]
All agents episode reward: [-14.23310543]
Agent gate_2 episode reward: [-14.22550112]
All agents episode reward: [-14.22550112]
Agent gate_2 episode reward: [-14.47380615]
All agents episode reward: [-14.47380615]
Agent gate_2 episode reward: [-13.92621262]
All agents episode reward: [-13.92621262]
Agent gate_2 episode reward: [-13.94830517]
All agents episode reward: [-13.94830517]
Agent gate_2 episode reward: [-13.8310503]
All agents episode reward: [-13.8310503]
Agent gate_2 episode reward: [-13.88687505]
All agents episode reward: [-13.88687505]
Agent gate_2 episode reward: [-14.01951525]
All agents episode reward: [-14.01951525]
Agent gate_2 episode reward: [-13.84682121]
All agents episode reward: [-13.84682121]
Iteration 8: 100%|██████████| 10/10 [00:16<00:00,  1.66s/it, episode=90, norm_ret=-13.334, true_ret=-24058.725, steps=600]
Agent gate_2 episode reward: [-13.38496642]
All agents episode reward: [-13.38496642]
Agent gate_2 episode reward: [-13.3948947]
All agents episode reward: [-13.3948947]
Agent gate_2 episode reward: [-13.38446757]
All agents episode reward: [-13.38446757]
Agent gate_2 episode reward: [-13.46792427]
All agents episode reward: [-13.46792427]
Agent gate_2 episode reward: [-13.56588393]
All agents episode reward: [-13.56588393]
Agent gate_2 episode reward: [-13.28396704]
All agents episode reward: [-13.28396704]
Agent gate_2 episode reward: [-12.79921152]
All agents episode reward: [-12.79921152]
Agent gate_2 episode reward: [-13.53433185]
All agents episode reward: [-13.53433185]
Agent gate_2 episode reward: [-13.22136858]
All agents episode reward: [-13.22136858]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -15674.271 at episode 90 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-13.30010212]
All agents episode reward: [-13.30010212]
Iteration 9: 100%|██████████| 10/10 [00:14<00:00,  1.43s/it, episode=100, norm_ret=-0.043, true_ret=-24.534, steps=600]
Agent gate_2 episode reward: [-0.03443363]
All agents episode reward: [-0.03443363]
Agent gate_2 episode reward: [-0.01196842]
All agents episode reward: [-0.01196842]
Agent gate_2 episode reward: [-0.01372798]
All agents episode reward: [-0.01372798]
Agent gate_2 episode reward: [-0.2873103]
All agents episode reward: [-0.2873103]
Agent gate_2 episode reward: [-0.01187629]
All agents episode reward: [-0.01187629]
Agent gate_2 episode reward: [-0.01204798]
All agents episode reward: [-0.01204798]
Agent gate_2 episode reward: [-0.01239149]
All agents episode reward: [-0.01239149]
Agent gate_2 episode reward: [-0.01280777]
All agents episode reward: [-0.01280777]
Agent gate_2 episode reward: [-0.01583371]
All agents episode reward: [-0.01583371]
Agent gate_2 episode reward: [-0.01295143]
All agents episode reward: [-0.01295143]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -15312.278 | Total reward: -15312.278
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -22983.721 | Total reward: -22983.721
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -24433.121 | Total reward: -24433.121
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -27657.367 | Total reward: -27657.367
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -20686.971 | Total reward: -20686.971
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -24292.615 | Total reward: -24292.615
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -25372.223 | Total reward: -25372.223
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -22347.697 | Total reward: -22347.697
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -23266.508 | Total reward: -23266.508
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -20834.553 | Total reward: -20834.553
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -22718.705 ± 3160.523
  Average reward: -22718.705 ± 3160.523
  Total reward: -22718.705 ± 3160.523
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -18228.846 | Total reward: -18228.846
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -27080.467 | Total reward: -27080.467
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -28433.316 | Total reward: -28433.316
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -31755.723 | Total reward: -31755.723
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -23379.447 | Total reward: -23379.447
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -28577.039 | Total reward: -28577.039
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -29532.271 | Total reward: -29532.271
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -26048.355 | Total reward: -26048.355
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -27711.088 | Total reward: -27711.088
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -22501.801 | Total reward: -22501.801
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -26324.838 ± 3751.071
  Average reward: -26324.838 ± 3751.071
  Total reward: -26324.838 ± 3751.071
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -15409.040 | Total reward: -15409.040
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -22815.664 | Total reward: -22815.664
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -24393.207 | Total reward: -24393.207
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -27657.367 | Total reward: -27657.367
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -20686.971 | Total reward: -20686.971
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -24292.615 | Total reward: -24292.615
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -25372.223 | Total reward: -25372.223
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -22347.697 | Total reward: -22347.697
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -23405.082 | Total reward: -23405.082
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -20409.414 | Total reward: -20409.414
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -22678.928 ± 3165.549
  Average reward: -22678.928 ± 3165.549
  Total reward: -22678.928 ± 3165.549
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -22718.705
Rule-based avg reward: -26324.838
No control avg reward: -22678.928
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
