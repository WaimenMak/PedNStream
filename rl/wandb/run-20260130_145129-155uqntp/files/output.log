Iteration 0: 100%|██████████| 10/10 [00:22<00:00,  2.22s/it, episode=10, norm_ret=-9.274, true_ret=-236332.250, steps=600]
Agent gate_2 episode reward: [-78.98901099]
All agents episode reward: [-78.98901099]
Agent gate_2 episode reward: [-3.75736971]
All agents episode reward: [-3.75736971]
Agent gate_2 episode reward: [-1.63447246]
All agents episode reward: [-1.63447246]
Agent gate_2 episode reward: [-1.42561066]
All agents episode reward: [-1.42561066]
Agent gate_2 episode reward: [-1.46346693]
All agents episode reward: [-1.46346693]
Agent gate_2 episode reward: [-0.92327333]
All agents episode reward: [-0.92327333]
Agent gate_2 episode reward: [-0.95275591]
All agents episode reward: [-0.95275591]
Agent gate_2 episode reward: [-1.05690202]
All agents episode reward: [-1.05690202]
Agent gate_2 episode reward: [-1.18761332]
All agents episode reward: [-1.18761332]
Agent gate_2 episode reward: [-1.3516999]
All agents episode reward: [-1.3516999]
Iteration 1: 100%|██████████| 10/10 [00:21<00:00,  2.19s/it, episode=20, norm_ret=-1.377, true_ret=-214077.016, steps=600]
Agent gate_2 episode reward: [-1.10751583]
All agents episode reward: [-1.10751583]
Agent gate_2 episode reward: [-1.2627534]
All agents episode reward: [-1.2627534]
Agent gate_2 episode reward: [-1.30081223]
All agents episode reward: [-1.30081223]
Agent gate_2 episode reward: [-1.2498032]
All agents episode reward: [-1.2498032]
Agent gate_2 episode reward: [-1.40777524]
All agents episode reward: [-1.40777524]
Agent gate_2 episode reward: [-1.44749146]
All agents episode reward: [-1.44749146]
Agent gate_2 episode reward: [-1.39437632]
All agents episode reward: [-1.39437632]
Agent gate_2 episode reward: [-1.43034678]
All agents episode reward: [-1.43034678]
Agent gate_2 episode reward: [-1.49377804]
All agents episode reward: [-1.49377804]
Agent gate_2 episode reward: [-1.67488884]
All agents episode reward: [-1.67488884]
Iteration 2: 100%|██████████| 10/10 [00:22<00:00,  2.25s/it, episode=30, norm_ret=-1.796, true_ret=-202324.172, steps=600]
Agent gate_2 episode reward: [-1.59782932]
All agents episode reward: [-1.59782932]
Agent gate_2 episode reward: [-1.63714816]
All agents episode reward: [-1.63714816]
Agent gate_2 episode reward: [-1.71626043]
All agents episode reward: [-1.71626043]
Agent gate_2 episode reward: [-1.82903829]
All agents episode reward: [-1.82903829]
Agent gate_2 episode reward: [-1.84512554]
All agents episode reward: [-1.84512554]
Agent gate_2 episode reward: [-1.79802422]
All agents episode reward: [-1.79802422]
Agent gate_2 episode reward: [-1.79531628]
All agents episode reward: [-1.79531628]
Agent gate_2 episode reward: [-1.80248315]
All agents episode reward: [-1.80248315]
Agent gate_2 episode reward: [-2.02764821]
All agents episode reward: [-2.02764821]
Agent gate_2 episode reward: [-1.91387794]
All agents episode reward: [-1.91387794]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.22s/it, episode=40, norm_ret=-2.032, true_ret=-191960.828, steps=600]
Agent gate_2 episode reward: [-1.91196295]
All agents episode reward: [-1.91196295]
Agent gate_2 episode reward: [-1.90495261]
All agents episode reward: [-1.90495261]
Agent gate_2 episode reward: [-1.96822097]
All agents episode reward: [-1.96822097]
Agent gate_2 episode reward: [-2.02414958]
All agents episode reward: [-2.02414958]
Agent gate_2 episode reward: [-2.05140933]
All agents episode reward: [-2.05140933]
Agent gate_2 episode reward: [-2.07569967]
All agents episode reward: [-2.07569967]
Agent gate_2 episode reward: [-2.10488506]
All agents episode reward: [-2.10488506]
Agent gate_2 episode reward: [-2.05215842]
All agents episode reward: [-2.05215842]
Agent gate_2 episode reward: [-2.14941293]
All agents episode reward: [-2.14941293]
Agent gate_2 episode reward: [-2.07861443]
All agents episode reward: [-2.07861443]
Iteration 4: 100%|██████████| 10/10 [00:21<00:00,  2.19s/it, episode=50, norm_ret=-2.331, true_ret=-210561.609, steps=600]
Agent gate_2 episode reward: [-2.15772198]
All agents episode reward: [-2.15772198]
Agent gate_2 episode reward: [-2.27484648]
All agents episode reward: [-2.27484648]
Agent gate_2 episode reward: [-2.2838988]
All agents episode reward: [-2.2838988]
Agent gate_2 episode reward: [-2.25783292]
All agents episode reward: [-2.25783292]
Agent gate_2 episode reward: [-2.30572288]
All agents episode reward: [-2.30572288]
Agent gate_2 episode reward: [-2.1974667]
All agents episode reward: [-2.1974667]
Agent gate_2 episode reward: [-2.37596134]
All agents episode reward: [-2.37596134]
Agent gate_2 episode reward: [-2.41159614]
All agents episode reward: [-2.41159614]
Agent gate_2 episode reward: [-2.5174926]
All agents episode reward: [-2.5174926]
Agent gate_2 episode reward: [-2.53123539]
All agents episode reward: [-2.53123539]
Iteration 5: 100%|██████████| 10/10 [00:26<00:00,  2.61s/it, episode=60, norm_ret=-2.575, true_ret=-208398.188, steps=600]
Agent gate_2 episode reward: [-2.47650551]
All agents episode reward: [-2.47650551]
Agent gate_2 episode reward: [-2.45248843]
All agents episode reward: [-2.45248843]
Agent gate_2 episode reward: [-2.39756295]
All agents episode reward: [-2.39756295]
Agent gate_2 episode reward: [-2.49165657]
All agents episode reward: [-2.49165657]
Agent gate_2 episode reward: [-2.66913385]
All agents episode reward: [-2.66913385]
Agent gate_2 episode reward: [-2.54511312]
All agents episode reward: [-2.54511312]
Agent gate_2 episode reward: [-2.62817515]
All agents episode reward: [-2.62817515]
Agent gate_2 episode reward: [-2.76342107]
All agents episode reward: [-2.76342107]
Agent gate_2 episode reward: [-2.59664861]
All agents episode reward: [-2.59664861]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -196943.531 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.72669241]
All agents episode reward: [-2.72669241]
Iteration 6: 100%|██████████| 10/10 [00:28<00:00,  2.82s/it, episode=70, norm_ret=-3.670, true_ret=-257004.047, steps=600]
Agent gate_2 episode reward: [-3.61391872]
All agents episode reward: [-3.61391872]
Agent gate_2 episode reward: [-3.5406709]
All agents episode reward: [-3.5406709]
Agent gate_2 episode reward: [-3.5840036]
All agents episode reward: [-3.5840036]
Agent gate_2 episode reward: [-3.63527416]
All agents episode reward: [-3.63527416]
Agent gate_2 episode reward: [-3.62546072]
All agents episode reward: [-3.62546072]
Agent gate_2 episode reward: [-3.85287287]
All agents episode reward: [-3.85287287]
Agent gate_2 episode reward: [-3.58201167]
All agents episode reward: [-3.58201167]
Agent gate_2 episode reward: [-3.73943808]
All agents episode reward: [-3.73943808]
Agent gate_2 episode reward: [-3.81138174]
All agents episode reward: [-3.81138174]
Agent gate_2 episode reward: [-3.71362741]
All agents episode reward: [-3.71362741]
Iteration 7: 100%|██████████| 10/10 [00:30<00:00,  3.01s/it, episode=80, norm_ret=-3.770, true_ret=-242691.672, steps=600]
Agent gate_2 episode reward: [-3.75254139]
All agents episode reward: [-3.75254139]
Agent gate_2 episode reward: [-3.70243153]
All agents episode reward: [-3.70243153]
Agent gate_2 episode reward: [-3.67464076]
All agents episode reward: [-3.67464076]
Agent gate_2 episode reward: [-3.6669008]
All agents episode reward: [-3.6669008]
Agent gate_2 episode reward: [-3.75242749]
All agents episode reward: [-3.75242749]
Agent gate_2 episode reward: [-3.73334103]
All agents episode reward: [-3.73334103]
Agent gate_2 episode reward: [-3.83612756]
All agents episode reward: [-3.83612756]
Agent gate_2 episode reward: [-3.99287381]
All agents episode reward: [-3.99287381]
Agent gate_2 episode reward: [-3.78285162]
All agents episode reward: [-3.78285162]
Agent gate_2 episode reward: [-3.80906041]
All agents episode reward: [-3.80906041]
Iteration 8: 100%|██████████| 10/10 [00:28<00:00,  2.85s/it, episode=90, norm_ret=-2.333, true_ret=-149610.406, steps=600]
Agent gate_2 episode reward: [-2.30867532]
All agents episode reward: [-2.30867532]
Agent gate_2 episode reward: [-2.13923125]
All agents episode reward: [-2.13923125]
Agent gate_2 episode reward: [-2.22449762]
All agents episode reward: [-2.22449762]
Agent gate_2 episode reward: [-2.42766865]
All agents episode reward: [-2.42766865]
Agent gate_2 episode reward: [-2.58998826]
All agents episode reward: [-2.58998826]
Agent gate_2 episode reward: [-2.2483262]
All agents episode reward: [-2.2483262]
Agent gate_2 episode reward: [-2.27435466]
All agents episode reward: [-2.27435466]
Agent gate_2 episode reward: [-2.38597555]
All agents episode reward: [-2.38597555]
Agent gate_2 episode reward: [-2.21438408]
All agents episode reward: [-2.21438408]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -191568.188 at episode 90 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.51417544]
All agents episode reward: [-2.51417544]
Iteration 9: 100%|██████████| 10/10 [00:27<00:00,  2.80s/it, episode=100, norm_ret=0.000, true_ret=0.000, steps=600]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Agent gate_2 episode reward: [0.]
All agents episode reward: [0.]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -145926.047 | Total reward: -145926.047
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -239516.969 | Total reward: -239516.969
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -270717.062 | Total reward: -270717.062
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -320081.188 | Total reward: -320081.188
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -220814.250 | Total reward: -220814.250
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -269959.844 | Total reward: -269959.844
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -287501.812 | Total reward: -287501.812
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -240495.188 | Total reward: -240495.188
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -250804.000 | Total reward: -250804.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -193421.469 | Total reward: -193421.469
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -243923.797 ± 46756.129
  Average reward: -243923.797 ± 46756.129
  Total reward: -243923.797 ± 46756.129
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -158218.641 | Total reward: -158218.641
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -262143.781 | Total reward: -262143.781
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -296580.844 | Total reward: -296580.844
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -360419.031 | Total reward: -360419.031
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -231979.766 | Total reward: -231979.766
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -290329.094 | Total reward: -290329.094
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -315949.750 | Total reward: -315949.750
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -263472.062 | Total reward: -263472.062
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -271796.312 | Total reward: -271796.312
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -192114.359 | Total reward: -192114.359
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -264300.344 ± 55853.629
  Average reward: -264300.344 ± 55853.629
  Total reward: -264300.344 ± 55853.629
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -145926.047 | Total reward: -145926.047
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -239516.969 | Total reward: -239516.969
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -270717.062 | Total reward: -270717.062
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -320081.188 | Total reward: -320081.188
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -220814.250 | Total reward: -220814.250
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -269959.844 | Total reward: -269959.844
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -287501.812 | Total reward: -287501.812
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -240495.188 | Total reward: -240495.188
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -250804.000 | Total reward: -250804.000
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -193421.469 | Total reward: -193421.469
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -243923.797 ± 46756.129
  Average reward: -243923.797 ± 46756.129
  Total reward: -243923.797 ± 46756.129
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -243923.797
Rule-based avg reward: -264300.344
No control avg reward: -243923.797
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
