Iteration 0: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it, episode=10, norm_ret=-7.471, true_ret=-705860.438, steps=600]
Agent gate_2 episode reward: [-60.65328966]
All agents episode reward: [-60.65328966]
Agent gate_2 episode reward: [-2.27432937]
All agents episode reward: [-2.27432937]
Agent gate_2 episode reward: [-5.22715492]
All agents episode reward: [-5.22715492]
Agent gate_2 episode reward: [-2.30145076]
All agents episode reward: [-2.30145076]
Agent gate_2 episode reward: [-0.70015197]
All agents episode reward: [-0.70015197]
Agent gate_2 episode reward: [-0.66362674]
All agents episode reward: [-0.66362674]
Agent gate_2 episode reward: [-0.65372614]
All agents episode reward: [-0.65372614]
Agent gate_2 episode reward: [-0.70583653]
All agents episode reward: [-0.70583653]
Agent gate_2 episode reward: [-0.75209147]
All agents episode reward: [-0.75209147]
Agent gate_2 episode reward: [-0.77781369]
All agents episode reward: [-0.77781369]
Iteration 1: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it, episode=20, norm_ret=-1.115, true_ret=-1676008.000, steps=600]
Agent gate_2 episode reward: [-0.81744635]
All agents episode reward: [-0.81744635]
Agent gate_2 episode reward: [-0.83525859]
All agents episode reward: [-0.83525859]
Agent gate_2 episode reward: [-0.93006433]
All agents episode reward: [-0.93006433]
Agent gate_2 episode reward: [-0.92649919]
All agents episode reward: [-0.92649919]
Agent gate_2 episode reward: [-0.95687714]
All agents episode reward: [-0.95687714]
Agent gate_2 episode reward: [-0.99868263]
All agents episode reward: [-0.99868263]
Agent gate_2 episode reward: [-1.12967608]
All agents episode reward: [-1.12967608]
Agent gate_2 episode reward: [-1.00549326]
All agents episode reward: [-1.00549326]
Agent gate_2 episode reward: [-1.02943953]
All agents episode reward: [-1.02943953]
Agent gate_2 episode reward: [-2.52414088]
All agents episode reward: [-2.52414088]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.31s/it, episode=30, norm_ret=-1.236, true_ret=-750601.625, steps=600]
Agent gate_2 episode reward: [-1.20219049]
All agents episode reward: [-1.20219049]
Agent gate_2 episode reward: [-1.13620974]
All agents episode reward: [-1.13620974]
Agent gate_2 episode reward: [-1.14121868]
All agents episode reward: [-1.14121868]
Agent gate_2 episode reward: [-1.19757269]
All agents episode reward: [-1.19757269]
Agent gate_2 episode reward: [-1.21776528]
All agents episode reward: [-1.21776528]
Agent gate_2 episode reward: [-1.21362943]
All agents episode reward: [-1.21362943]
Agent gate_2 episode reward: [-1.24845453]
All agents episode reward: [-1.24845453]
Agent gate_2 episode reward: [-1.34839593]
All agents episode reward: [-1.34839593]
Agent gate_2 episode reward: [-1.28433665]
All agents episode reward: [-1.28433665]
Agent gate_2 episode reward: [-1.37058838]
All agents episode reward: [-1.37058838]
Iteration 3: 100%|██████████| 10/10 [00:23<00:00,  2.32s/it, episode=40, norm_ret=-1.449, true_ret=-794420.250, steps=600]
Agent gate_2 episode reward: [-1.34859239]
All agents episode reward: [-1.34859239]
Agent gate_2 episode reward: [-1.38103415]
All agents episode reward: [-1.38103415]
Agent gate_2 episode reward: [-1.34770324]
All agents episode reward: [-1.34770324]
Agent gate_2 episode reward: [-1.39113347]
All agents episode reward: [-1.39113347]
Agent gate_2 episode reward: [-1.48606814]
All agents episode reward: [-1.48606814]
Agent gate_2 episode reward: [-1.42471177]
All agents episode reward: [-1.42471177]
Agent gate_2 episode reward: [-1.46207021]
All agents episode reward: [-1.46207021]
Agent gate_2 episode reward: [-1.51363222]
All agents episode reward: [-1.51363222]
Agent gate_2 episode reward: [-1.47121712]
All agents episode reward: [-1.47121712]
Agent gate_2 episode reward: [-1.66510437]
All agents episode reward: [-1.66510437]
Iteration 4: 100%|██████████| 10/10 [00:22<00:00,  2.29s/it, episode=50, norm_ret=-1.660, true_ret=-712061.938, steps=600]
Agent gate_2 episode reward: [-1.54407002]
All agents episode reward: [-1.54407002]
Agent gate_2 episode reward: [-1.50440049]
All agents episode reward: [-1.50440049]
Agent gate_2 episode reward: [-1.41781894]
All agents episode reward: [-1.41781894]
Agent gate_2 episode reward: [-1.6942444]
All agents episode reward: [-1.6942444]
Agent gate_2 episode reward: [-1.78815217]
All agents episode reward: [-1.78815217]
Agent gate_2 episode reward: [-1.99093685]
All agents episode reward: [-1.99093685]
Agent gate_2 episode reward: [-1.69992268]
All agents episode reward: [-1.69992268]
Agent gate_2 episode reward: [-1.68387101]
All agents episode reward: [-1.68387101]
Agent gate_2 episode reward: [-1.61323774]
All agents episode reward: [-1.61323774]
Agent gate_2 episode reward: [-1.66119154]
All agents episode reward: [-1.66119154]
Iteration 5: 100%|██████████| 10/10 [00:26<00:00,  2.64s/it, episode=60, norm_ret=-1.777, true_ret=-920311.938, steps=600]
Agent gate_2 episode reward: [-1.66928975]
All agents episode reward: [-1.66928975]
Agent gate_2 episode reward: [-1.68219936]
All agents episode reward: [-1.68219936]
Agent gate_2 episode reward: [-1.64813286]
All agents episode reward: [-1.64813286]
Agent gate_2 episode reward: [-1.71404615]
All agents episode reward: [-1.71404615]
Agent gate_2 episode reward: [-1.59641277]
All agents episode reward: [-1.59641277]
Agent gate_2 episode reward: [-1.84205317]
All agents episode reward: [-1.84205317]
Agent gate_2 episode reward: [-1.82624714]
All agents episode reward: [-1.82624714]
Agent gate_2 episode reward: [-1.7591743]
All agents episode reward: [-1.7591743]
Agent gate_2 episode reward: [-1.6909766]
All agents episode reward: [-1.6909766]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -1072372.750 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.34490178]
All agents episode reward: [-2.34490178]
Iteration 6: 100%|██████████| 10/10 [00:26<00:00,  2.69s/it, episode=70, norm_ret=-4.150, true_ret=-828703.688, steps=600]
Agent gate_2 episode reward: [-2.42755516]
All agents episode reward: [-2.42755516]
Agent gate_2 episode reward: [-14.73883903]
All agents episode reward: [-14.73883903]
Agent gate_2 episode reward: [-7.40984076]
All agents episode reward: [-7.40984076]
Agent gate_2 episode reward: [-2.30504716]
All agents episode reward: [-2.30504716]
Agent gate_2 episode reward: [-2.36751423]
All agents episode reward: [-2.36751423]
Agent gate_2 episode reward: [-2.54237227]
All agents episode reward: [-2.54237227]
Agent gate_2 episode reward: [-2.33553295]
All agents episode reward: [-2.33553295]
Agent gate_2 episode reward: [-2.41061492]
All agents episode reward: [-2.41061492]
Agent gate_2 episode reward: [-2.75791823]
All agents episode reward: [-2.75791823]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -790124.438 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.20783675]
All agents episode reward: [-2.20783675]
Iteration 7: 100%|██████████| 10/10 [00:26<00:00,  2.70s/it, episode=80, norm_ret=-2.819, true_ret=-984186.125, steps=600]
Agent gate_2 episode reward: [-2.5484441]
All agents episode reward: [-2.5484441]
Agent gate_2 episode reward: [-2.89478962]
All agents episode reward: [-2.89478962]
Agent gate_2 episode reward: [-2.58107748]
All agents episode reward: [-2.58107748]
Agent gate_2 episode reward: [-3.00848776]
All agents episode reward: [-3.00848776]
Agent gate_2 episode reward: [-2.83406469]
All agents episode reward: [-2.83406469]
Agent gate_2 episode reward: [-2.95099902]
All agents episode reward: [-2.95099902]
Agent gate_2 episode reward: [-2.84062464]
All agents episode reward: [-2.84062464]
Agent gate_2 episode reward: [-2.93867146]
All agents episode reward: [-2.93867146]
Agent gate_2 episode reward: [-2.72606965]
All agents episode reward: [-2.72606965]
Agent gate_2 episode reward: [-2.86271542]
All agents episode reward: [-2.86271542]
Iteration 8: 100%|██████████| 10/10 [00:27<00:00,  2.72s/it, episode=90, norm_ret=-2.076, true_ret=-643002.562, steps=600]
Agent gate_2 episode reward: [-1.83288543]
All agents episode reward: [-1.83288543]
Agent gate_2 episode reward: [-2.11676627]
All agents episode reward: [-2.11676627]
Agent gate_2 episode reward: [-1.88485773]
All agents episode reward: [-1.88485773]
Agent gate_2 episode reward: [-1.93957781]
All agents episode reward: [-1.93957781]
Agent gate_2 episode reward: [-2.0387155]
All agents episode reward: [-2.0387155]
Agent gate_2 episode reward: [-2.01776973]
All agents episode reward: [-2.01776973]
Agent gate_2 episode reward: [-2.1018657]
All agents episode reward: [-2.1018657]
Agent gate_2 episode reward: [-2.62772045]
All agents episode reward: [-2.62772045]
Agent gate_2 episode reward: [-2.18855142]
All agents episode reward: [-2.18855142]
Agent gate_2 episode reward: [-2.01176815]
All agents episode reward: [-2.01176815]
Iteration 9: 100%|██████████| 10/10 [00:26<00:00,  2.68s/it, episode=100, norm_ret=-3.566, true_ret=-757418.812, steps=600]
Agent gate_2 episode reward: [-2.792028]
All agents episode reward: [-2.792028]
Agent gate_2 episode reward: [-6.35986525]
All agents episode reward: [-6.35986525]
Agent gate_2 episode reward: [-3.2765313]
All agents episode reward: [-3.2765313]
Agent gate_2 episode reward: [-2.96480609]
All agents episode reward: [-2.96480609]
Agent gate_2 episode reward: [-2.92287903]
All agents episode reward: [-2.92287903]
Agent gate_2 episode reward: [-6.65659778]
All agents episode reward: [-6.65659778]
Agent gate_2 episode reward: [-2.84725366]
All agents episode reward: [-2.84725366]
Agent gate_2 episode reward: [-2.800324]
All agents episode reward: [-2.800324]
Agent gate_2 episode reward: [-2.52799093]
All agents episode reward: [-2.52799093]
Agent gate_2 episode reward: [-2.50869484]
All agents episode reward: [-2.50869484]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -665404.312 | Total reward: -665404.312
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -771593.062 | Total reward: -771593.062
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -807445.250 | Total reward: -807445.250
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -972930.688 | Total reward: -972930.688
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -757957.750 | Total reward: -757957.750
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -836727.250 | Total reward: -836727.250
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -917378.188 | Total reward: -917378.188
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -792368.500 | Total reward: -792368.500
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -806624.188 | Total reward: -806624.188
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -695627.312 | Total reward: -695627.312
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -802405.625 ± 87587.320
  Average reward: -802405.625 ± 87587.320
  Total reward: -802405.625 ± 87587.320
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -643709.938 | Total reward: -643709.938
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -851560.312 | Total reward: -851560.312
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -920434.188 | Total reward: -920434.188
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1048110.500 | Total reward: -1048110.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -791232.562 | Total reward: -791232.562
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -907931.062 | Total reward: -907931.062
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -959172.375 | Total reward: -959172.375
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -854216.688 | Total reward: -854216.688
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -870864.938 | Total reward: -870864.938
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -711501.500 | Total reward: -711501.500
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -855873.375 ± 111707.203
  Average reward: -855873.375 ± 111707.203
  Total reward: -855873.375 ± 111707.203
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.938 | Total reward: -967434.938
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.688 | Total reward: -867192.688
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902276.062 | Total reward: -902276.062
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808263.062 | Total reward: -808263.062
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.438 | Total reward: -714115.438
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.219
  Average reward: -815120.250 ± 93512.219
  Total reward: -815120.250 ± 93512.219
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -802405.625
Rule-based avg reward: -855873.375
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
