Iteration 0:  80%|████████  | 16/20 [00:36<00:08,  2.16s/it, episode=10, norm_ret=-12.595, true_ret=-55933252.000, steps=600]
Agent gate_2 episode reward: [-57.47444239]
All agents episode reward: [-57.47444239]
Agent gate_2 episode reward: [-0.66167943]
All agents episode reward: [-0.66167943]
Agent gate_2 episode reward: [-6.17400847]
All agents episode reward: [-6.17400847]
Agent gate_2 episode reward: [-0.64124695]
All agents episode reward: [-0.64124695]
Agent gate_2 episode reward: [-1.31071986]
All agents episode reward: [-1.31071986]
Agent gate_2 episode reward: [-1.17790661]
All agents episode reward: [-1.17790661]
Agent gate_2 episode reward: [-36.99342552]
All agents episode reward: [-36.99342552]
Agent gate_2 episode reward: [-0.37639719]
All agents episode reward: [-0.37639719]
Agent gate_2 episode reward: [-0.32432891]
All agents episode reward: [-0.32432891]
Agent gate_2 episode reward: [-20.81728979]
All agents episode reward: [-20.81728979]
Agent gate_2 episode reward: [-2.48981983]
All agents episode reward: [-2.48981983]
Agent gate_2 episode reward: [-0.27424304]
All agents episode reward: [-0.27424304]
Agent gate_2 episode reward: [-0.10408387]
All agents episode reward: [-0.10408387]
Agent gate_2 episode reward: [-20.49251852]
All agents episode reward: [-20.49251852]
Agent gate_2 episode reward: [-1.14162246]
All agents episode reward: [-1.14162246]
Agent gate_2 episode reward: [-0.28874442]
All agents episode reward: [-0.28874442]
Agent gate_2 episode reward: [-1.73152604]
All agents episode reward: [-1.73152604]
Agent gate_2 episode reward: [-0.91899318]
All agents episode reward: [-0.91899318]
Agent gate_2 episode reward: [-0.24425462]
All agents episode reward: [-0.24425462]
Agent gate_2 episode reward: [-0.22340494]
All agents episode reward: [-0.22340494]
Iteration 1:  80%|████████  | 16/20 [00:35<00:08,  2.24s/it, episode=30, norm_ret=-2.886, true_ret=-1058182.125, steps=600]
Agent gate_2 episode reward: [-0.5695852]
All agents episode reward: [-0.5695852]
Agent gate_2 episode reward: [-0.25919158]
All agents episode reward: [-0.25919158]
Agent gate_2 episode reward: [-0.35635443]
All agents episode reward: [-0.35635443]
Agent gate_2 episode reward: [-1.94824849]
All agents episode reward: [-1.94824849]
Agent gate_2 episode reward: [-0.29971175]
All agents episode reward: [-0.29971175]
Agent gate_2 episode reward: [-3.39091439]
All agents episode reward: [-3.39091439]
Agent gate_2 episode reward: [-0.32621712]
All agents episode reward: [-0.32621712]
Agent gate_2 episode reward: [-9.43297614]
All agents episode reward: [-9.43297614]
Agent gate_2 episode reward: [-11.90745352]
All agents episode reward: [-11.90745352]
Agent gate_2 episode reward: [-0.36780747]
All agents episode reward: [-0.36780747]
Agent gate_2 episode reward: [-0.26563046]
All agents episode reward: [-0.26563046]
Agent gate_2 episode reward: [-0.34456066]
All agents episode reward: [-0.34456066]
Agent gate_2 episode reward: [-8.5521879]
All agents episode reward: [-8.5521879]
Agent gate_2 episode reward: [-0.25080234]
All agents episode reward: [-0.25080234]
Agent gate_2 episode reward: [-0.99594258]
All agents episode reward: [-0.99594258]
Agent gate_2 episode reward: [-3.1729538]
All agents episode reward: [-3.1729538]
Agent gate_2 episode reward: [-0.33024191]
All agents episode reward: [-0.33024191]
Agent gate_2 episode reward: [-0.39242563]
All agents episode reward: [-0.39242563]
Agent gate_2 episode reward: [-0.3336073]
All agents episode reward: [-0.3336073]
Agent gate_2 episode reward: [-110.61399917]
All agents episode reward: [-110.61399917]
Iteration 2:  80%|████████  | 16/20 [00:34<00:08,  2.04s/it, episode=50, norm_ret=-0.008, true_ret=-851858.125, steps=600]
Agent gate_2 episode reward: [-0.00226589]
All agents episode reward: [-0.00226589]
Agent gate_2 episode reward: [-0.01465486]
All agents episode reward: [-0.01465486]
Agent gate_2 episode reward: [-0.00218564]
All agents episode reward: [-0.00218564]
Agent gate_2 episode reward: [-0.00381718]
All agents episode reward: [-0.00381718]
Agent gate_2 episode reward: [-0.00258997]
All agents episode reward: [-0.00258997]
Agent gate_2 episode reward: [-0.01992438]
All agents episode reward: [-0.01992438]
Agent gate_2 episode reward: [-0.00244887]
All agents episode reward: [-0.00244887]
Agent gate_2 episode reward: [-0.00258797]
All agents episode reward: [-0.00258797]
Agent gate_2 episode reward: [-0.02358633]
All agents episode reward: [-0.02358633]
Agent gate_2 episode reward: [-0.00324106]
All agents episode reward: [-0.00324106]
Agent gate_2 episode reward: [-0.00822425]
All agents episode reward: [-0.00822425]
Agent gate_2 episode reward: [-0.00316849]
All agents episode reward: [-0.00316849]
Agent gate_2 episode reward: [-0.00353653]
All agents episode reward: [-0.00353653]
Agent gate_2 episode reward: [-0.00314023]
All agents episode reward: [-0.00314023]
Agent gate_2 episode reward: [-0.00361477]
All agents episode reward: [-0.00361477]
Agent gate_2 episode reward: [-0.00393457]
All agents episode reward: [-0.00393457]
Agent gate_2 episode reward: [-0.08055328]
All agents episode reward: [-0.08055328]
Agent gate_2 episode reward: [-0.00782677]
All agents episode reward: [-0.00782677]
Agent gate_2 episode reward: [-0.00341569]
All agents episode reward: [-0.00341569]
Agent gate_2 episode reward: [-0.00363932]
All agents episode reward: [-0.00363932]
Iteration 3:  80%|████████  | 16/20 [00:34<00:08,  2.17s/it, episode=70, norm_ret=-0.020, true_ret=-2245392.500, steps=600]
Agent gate_2 episode reward: [-0.00816781]
All agents episode reward: [-0.00816781]
Agent gate_2 episode reward: [-0.00679319]
All agents episode reward: [-0.00679319]
Agent gate_2 episode reward: [-0.00303895]
All agents episode reward: [-0.00303895]
Agent gate_2 episode reward: [-0.03214119]
All agents episode reward: [-0.03214119]
Agent gate_2 episode reward: [-0.00405019]
All agents episode reward: [-0.00405019]
Agent gate_2 episode reward: [-0.0030621]
All agents episode reward: [-0.0030621]
Agent gate_2 episode reward: [-0.00347235]
All agents episode reward: [-0.00347235]
Agent gate_2 episode reward: [-0.07911771]
All agents episode reward: [-0.07911771]
Agent gate_2 episode reward: [-0.0502487]
All agents episode reward: [-0.0502487]
Agent gate_2 episode reward: [-0.01010548]
All agents episode reward: [-0.01010548]
Agent gate_2 episode reward: [-0.02713634]
All agents episode reward: [-0.02713634]
Agent gate_2 episode reward: [-0.00912035]
All agents episode reward: [-0.00912035]
Agent gate_2 episode reward: [-0.00504698]
All agents episode reward: [-0.00504698]
Agent gate_2 episode reward: [-0.01989927]
All agents episode reward: [-0.01989927]
Agent gate_2 episode reward: [-0.00398554]
All agents episode reward: [-0.00398554]
Agent gate_2 episode reward: [-0.00388929]
All agents episode reward: [-0.00388929]
Agent gate_2 episode reward: [-0.00403236]
All agents episode reward: [-0.00403236]
Agent gate_2 episode reward: [-0.06280533]
All agents episode reward: [-0.06280533]
Agent gate_2 episode reward: [-0.01166107]
All agents episode reward: [-0.01166107]
Agent gate_2 episode reward: [-0.00321979]
All agents episode reward: [-0.00321979]
Iteration 4:  80%|████████  | 16/20 [00:33<00:07,  2.00s/it, episode=90, norm_ret=-0.018, true_ret=-684721.625, steps=600]
Agent gate_2 episode reward: [-0.03374307]
All agents episode reward: [-0.03374307]
Agent gate_2 episode reward: [-0.0053104]
All agents episode reward: [-0.0053104]
Agent gate_2 episode reward: [-0.01097808]
All agents episode reward: [-0.01097808]
Agent gate_2 episode reward: [-0.00308082]
All agents episode reward: [-0.00308082]
Agent gate_2 episode reward: [-0.00162234]
All agents episode reward: [-0.00162234]
Agent gate_2 episode reward: [-0.01117383]
All agents episode reward: [-0.01117383]
Agent gate_2 episode reward: [-0.08772419]
All agents episode reward: [-0.08772419]
Agent gate_2 episode reward: [-0.00415275]
All agents episode reward: [-0.00415275]
Agent gate_2 episode reward: [-0.01511816]
All agents episode reward: [-0.01511816]
Agent gate_2 episode reward: [-0.00349331]
All agents episode reward: [-0.00349331]
Agent gate_2 episode reward: [-0.01591694]
All agents episode reward: [-0.01591694]
Agent gate_2 episode reward: [-0.02923091]
All agents episode reward: [-0.02923091]
Agent gate_2 episode reward: [-0.00440756]
All agents episode reward: [-0.00440756]
Agent gate_2 episode reward: [-0.00677869]
All agents episode reward: [-0.00677869]
Agent gate_2 episode reward: [-0.0017151]
All agents episode reward: [-0.0017151]
Agent gate_2 episode reward: [-0.00343506]
All agents episode reward: [-0.00343506]
Agent gate_2 episode reward: [-0.01911126]
All agents episode reward: [-0.01911126]
Agent gate_2 episode reward: [-0.0422441]
All agents episode reward: [-0.0422441]
Agent gate_2 episode reward: [-0.00756327]
All agents episode reward: [-0.00756327]
Agent gate_2 episode reward: [-0.00365638]
All agents episode reward: [-0.00365638]
Iteration 5:  75%|███████▌  | 15/20 [00:37<00:12,  2.47s/it, episode=110, norm_ret=-0.064, true_ret=-16250783.000, steps=600]
Agent gate_2 episode reward: [-0.10883233]
All agents episode reward: [-0.10883233]
Agent gate_2 episode reward: [-0.00835272]
All agents episode reward: [-0.00835272]
Agent gate_2 episode reward: [-0.03785994]
All agents episode reward: [-0.03785994]
Agent gate_2 episode reward: [-0.11259177]
All agents episode reward: [-0.11259177]
Agent gate_2 episode reward: [-0.03815795]
All agents episode reward: [-0.03815795]
Agent gate_2 episode reward: [-0.02215883]
All agents episode reward: [-0.02215883]
Agent gate_2 episode reward: [-0.21394108]
All agents episode reward: [-0.21394108]
Agent gate_2 episode reward: [-0.0053291]
All agents episode reward: [-0.0053291]
Agent gate_2 episode reward: [-0.00441785]
All agents episode reward: [-0.00441785]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -15750219776.000 at episode 110 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.09164168]
All agents episode reward: [-0.09164168]
Agent gate_2 episode reward: [-0.00217051]
All agents episode reward: [-0.00217051]
Agent gate_2 episode reward: [-0.00658404]
All agents episode reward: [-0.00658404]
Agent gate_2 episode reward: [-0.00203197]
All agents episode reward: [-0.00203197]
Agent gate_2 episode reward: [-0.00174125]
All agents episode reward: [-0.00174125]
Agent gate_2 episode reward: [-0.00084981]
All agents episode reward: [-0.00084981]
Agent gate_2 episode reward: [-0.00064848]
All agents episode reward: [-0.00064848]
Agent gate_2 episode reward: [-0.00024756]
All agents episode reward: [-0.00024756]
Agent gate_2 episode reward: [-0.99602624]
All agents episode reward: [-0.99602624]
Agent gate_2 episode reward: [-0.00114013]
All agents episode reward: [-0.00114013]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -9533206.000 at episode 120 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.00189961]
All agents episode reward: [-0.00189961]
Iteration 6:  80%|████████  | 16/20 [00:37<00:09,  2.42s/it, episode=130, norm_ret=-0.326, true_ret=-775799.000, steps=600]
Agent gate_2 episode reward: [-0.00386759]
All agents episode reward: [-0.00386759]
Agent gate_2 episode reward: [-0.00063667]
All agents episode reward: [-0.00063667]
Agent gate_2 episode reward: [-3.23251514]
All agents episode reward: [-3.23251514]
Agent gate_2 episode reward: [-0.00060799]
All agents episode reward: [-0.00060799]
Agent gate_2 episode reward: [-0.00068505]
All agents episode reward: [-0.00068505]
Agent gate_2 episode reward: [-0.00377082]
All agents episode reward: [-0.00377082]
Agent gate_2 episode reward: [-0.01102486]
All agents episode reward: [-0.01102486]
Agent gate_2 episode reward: [-0.00258989]
All agents episode reward: [-0.00258989]
Agent gate_2 episode reward: [-0.00678559]
All agents episode reward: [-0.00678559]
Agent gate_2 episode reward: [-0.00062767]
All agents episode reward: [-0.00062767]
Agent gate_2 episode reward: [-0.00433109]
All agents episode reward: [-0.00433109]
Agent gate_2 episode reward: [-0.00163544]
All agents episode reward: [-0.00163544]
Agent gate_2 episode reward: [-0.01322132]
All agents episode reward: [-0.01322132]
Agent gate_2 episode reward: [-0.00356896]
All agents episode reward: [-0.00356896]
Agent gate_2 episode reward: [-0.00220448]
All agents episode reward: [-0.00220448]
Agent gate_2 episode reward: [-0.01404923]
All agents episode reward: [-0.01404923]
Agent gate_2 episode reward: [-0.00076677]
All agents episode reward: [-0.00076677]
Agent gate_2 episode reward: [-0.00095967]
All agents episode reward: [-0.00095967]
Agent gate_2 episode reward: [-0.00036924]
All agents episode reward: [-0.00036924]
Agent gate_2 episode reward: [-0.00079386]
All agents episode reward: [-0.00079386]
Iteration 7:  75%|███████▌  | 15/20 [00:33<00:08,  1.66s/it, episode=150, norm_ret=-0.006, true_ret=-9474262.000, steps=600]
Agent gate_2 episode reward: [-0.00831756]
All agents episode reward: [-0.00831756]
Agent gate_2 episode reward: [-0.00531435]
All agents episode reward: [-0.00531435]
Agent gate_2 episode reward: [-0.00411238]
All agents episode reward: [-0.00411238]
Agent gate_2 episode reward: [-0.00459364]
All agents episode reward: [-0.00459364]
Agent gate_2 episode reward: [-0.01442317]
All agents episode reward: [-0.01442317]
Agent gate_2 episode reward: [-0.00125068]
All agents episode reward: [-0.00125068]
Agent gate_2 episode reward: [-0.00789065]
All agents episode reward: [-0.00789065]
Agent gate_2 episode reward: [-0.00382911]
All agents episode reward: [-0.00382911]
Agent gate_2 episode reward: [-0.00467207]
All agents episode reward: [-0.00467207]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -5918677.500 at episode 150 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.00844422]
All agents episode reward: [-0.00844422]
Agent gate_2 episode reward: [-0.00572583]
All agents episode reward: [-0.00572583]
Agent gate_2 episode reward: [-3.8870146]
All agents episode reward: [-3.8870146]
Agent gate_2 episode reward: [-0.00118971]
All agents episode reward: [-0.00118971]
Agent gate_2 episode reward: [-0.00498381]
All agents episode reward: [-0.00498381]
Agent gate_2 episode reward: [-0.0011642]
All agents episode reward: [-0.0011642]
Agent gate_2 episode reward: [-0.00058257]
All agents episode reward: [-0.00058257]
Agent gate_2 episode reward: [-0.01489867]
All agents episode reward: [-0.01489867]
Agent gate_2 episode reward: [-0.00077273]
All agents episode reward: [-0.00077273]
Agent gate_2 episode reward: [-0.00208848]
All agents episode reward: [-0.00208848]
Agent gate_2 episode reward: [-0.01942493]
All agents episode reward: [-0.01942493]
Iteration 8:  80%|████████  | 16/20 [00:41<00:09,  2.42s/it, episode=170, norm_ret=-0.004, true_ret=-5237359.000, steps=600]
Agent gate_2 episode reward: [-0.00089979]
All agents episode reward: [-0.00089979]
Agent gate_2 episode reward: [-0.00173771]
All agents episode reward: [-0.00173771]
Agent gate_2 episode reward: [-0.00526548]
All agents episode reward: [-0.00526548]
Agent gate_2 episode reward: [-0.00215957]
All agents episode reward: [-0.00215957]
Agent gate_2 episode reward: [-0.00918126]
All agents episode reward: [-0.00918126]
Agent gate_2 episode reward: [-0.01300863]
All agents episode reward: [-0.01300863]
Agent gate_2 episode reward: [-0.00360245]
All agents episode reward: [-0.00360245]
Agent gate_2 episode reward: [-0.00304342]
All agents episode reward: [-0.00304342]
Agent gate_2 episode reward: [-0.00127841]
All agents episode reward: [-0.00127841]
Agent gate_2 episode reward: [-0.00458854]
All agents episode reward: [-0.00458854]
Agent gate_2 episode reward: [-0.00318762]
All agents episode reward: [-0.00318762]
Agent gate_2 episode reward: [-0.00205821]
All agents episode reward: [-0.00205821]
Agent gate_2 episode reward: [-0.00795801]
All agents episode reward: [-0.00795801]
Agent gate_2 episode reward: [-0.0046291]
All agents episode reward: [-0.0046291]
Agent gate_2 episode reward: [-0.00370855]
All agents episode reward: [-0.00370855]
Agent gate_2 episode reward: [-0.00421798]
All agents episode reward: [-0.00421798]
Agent gate_2 episode reward: [-0.00186988]
All agents episode reward: [-0.00186988]
Agent gate_2 episode reward: [-0.0011115]
All agents episode reward: [-0.0011115]
Agent gate_2 episode reward: [-0.00486353]
All agents episode reward: [-0.00486353]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -5333609.000 at episode 180 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.00440995]
All agents episode reward: [-0.00440995]
Iteration 9:  75%|███████▌  | 15/20 [00:38<00:12,  2.47s/it, episode=190, norm_ret=-0.004, true_ret=-9199141.000, steps=600]
Agent gate_2 episode reward: [-0.00394105]
All agents episode reward: [-0.00394105]
Agent gate_2 episode reward: [-0.0065233]
All agents episode reward: [-0.0065233]
Agent gate_2 episode reward: [-0.00390555]
All agents episode reward: [-0.00390555]
Agent gate_2 episode reward: [-0.00388138]
All agents episode reward: [-0.00388138]
Agent gate_2 episode reward: [-0.00528191]
All agents episode reward: [-0.00528191]
Agent gate_2 episode reward: [-0.00187381]
All agents episode reward: [-0.00187381]
Agent gate_2 episode reward: [-0.00353497]
All agents episode reward: [-0.00353497]
Agent gate_2 episode reward: [-0.00172491]
All agents episode reward: [-0.00172491]
Agent gate_2 episode reward: [-0.00102528]
All agents episode reward: [-0.00102528]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -4814083.500 at episode 190 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.00671268]
All agents episode reward: [-0.00671268]
Agent gate_2 episode reward: [-0.00133647]
All agents episode reward: [-0.00133647]
Agent gate_2 episode reward: [-0.00183921]
All agents episode reward: [-0.00183921]
Agent gate_2 episode reward: [-0.00530588]
All agents episode reward: [-0.00530588]
Agent gate_2 episode reward: [-0.00301307]
All agents episode reward: [-0.00301307]
Agent gate_2 episode reward: [-0.00537355]
All agents episode reward: [-0.00537355]
Agent gate_2 episode reward: [-0.00209007]
All agents episode reward: [-0.00209007]
Agent gate_2 episode reward: [-0.00270738]
All agents episode reward: [-0.00270738]
Agent gate_2 episode reward: [-0.00244648]
All agents episode reward: [-0.00244648]
Agent gate_2 episode reward: [-0.0032057]
All agents episode reward: [-0.0032057]
Agent gate_2 episode reward: [-0.00174865]
All agents episode reward: [-0.00174865]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -4845350.500 | Total reward: -4845350.500
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -4856406.500 | Total reward: -4856406.500
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -4961440.500 | Total reward: -4961440.500
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -5388729.500 | Total reward: -5388729.500
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -73214926848.000 | Total reward: -73214926848.000
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -5005624.000 | Total reward: -5005624.000
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -4958804.000 | Total reward: -4958804.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -36609753088.000 | Total reward: -36609753088.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -5898617.000 | Total reward: -5898617.000
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -6380623.000 | Total reward: -6380623.000
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -10986698752.000 ± 23438483456.000
  Average reward: -10986698752.000 ± 23438483456.000
  Total reward: -10986698752.000 ± 23438483456.000
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -643709.938 | Total reward: -643709.938
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -851560.312 | Total reward: -851560.312
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -920434.188 | Total reward: -920434.188
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1048110.500 | Total reward: -1048110.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -791232.562 | Total reward: -791232.562
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -907931.062 | Total reward: -907931.062
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -959172.375 | Total reward: -959172.375
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -854216.688 | Total reward: -854216.688
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -870864.938 | Total reward: -870864.938
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -711501.500 | Total reward: -711501.500
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -855873.375 ± 111707.203
  Average reward: -855873.375 ± 111707.203
  Total reward: -855873.375 ± 111707.203
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.938 | Total reward: -967434.938
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.688 | Total reward: -867192.688
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902276.062 | Total reward: -902276.062
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808263.062 | Total reward: -808263.062
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.438 | Total reward: -714115.438
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.219
  Average reward: -815120.250 ± 93512.219
  Total reward: -815120.250 ± 93512.219
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -10986698752.000
Rule-based avg reward: -855873.375
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
