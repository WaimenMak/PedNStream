Iteration 0: 100%|██████████| 10/10 [00:25<00:00,  2.53s/it, episode=10, norm_ret=-7.778, true_ret=-720998.938, steps=600]
Agent gate_2 episode reward: [-56.81497729]
All agents episode reward: [-56.81497729]
Agent gate_2 episode reward: [-11.40477554]
All agents episode reward: [-11.40477554]
Agent gate_2 episode reward: [-1.10028001]
All agents episode reward: [-1.10028001]
Agent gate_2 episode reward: [-0.83466126]
All agents episode reward: [-0.83466126]
Agent gate_2 episode reward: [-1.59311857]
All agents episode reward: [-1.59311857]
Agent gate_2 episode reward: [-1.11424309]
All agents episode reward: [-1.11424309]
Agent gate_2 episode reward: [-1.18051812]
All agents episode reward: [-1.18051812]
Agent gate_2 episode reward: [-1.21361725]
All agents episode reward: [-1.21361725]
Agent gate_2 episode reward: [-1.21873092]
All agents episode reward: [-1.21873092]
Agent gate_2 episode reward: [-1.30902704]
All agents episode reward: [-1.30902704]
Iteration 1: 100%|██████████| 10/10 [00:25<00:00,  2.52s/it, episode=20, norm_ret=-1.610, true_ret=-737337.500, steps=600]
Agent gate_2 episode reward: [-1.40127609]
All agents episode reward: [-1.40127609]
Agent gate_2 episode reward: [-1.39980347]
All agents episode reward: [-1.39980347]
Agent gate_2 episode reward: [-1.52461855]
All agents episode reward: [-1.52461855]
Agent gate_2 episode reward: [-1.58341268]
All agents episode reward: [-1.58341268]
Agent gate_2 episode reward: [-1.58702927]
All agents episode reward: [-1.58702927]
Agent gate_2 episode reward: [-1.63920448]
All agents episode reward: [-1.63920448]
Agent gate_2 episode reward: [-1.64823892]
All agents episode reward: [-1.64823892]
Agent gate_2 episode reward: [-1.70610103]
All agents episode reward: [-1.70610103]
Agent gate_2 episode reward: [-1.77262325]
All agents episode reward: [-1.77262325]
Agent gate_2 episode reward: [-1.84139158]
All agents episode reward: [-1.84139158]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.38s/it, episode=30, norm_ret=-2.039, true_ret=-732452.250, steps=600]
Agent gate_2 episode reward: [-1.88117873]
All agents episode reward: [-1.88117873]
Agent gate_2 episode reward: [-1.96756069]
All agents episode reward: [-1.96756069]
Agent gate_2 episode reward: [-1.91104761]
All agents episode reward: [-1.91104761]
Agent gate_2 episode reward: [-1.96374903]
All agents episode reward: [-1.96374903]
Agent gate_2 episode reward: [-1.9451337]
All agents episode reward: [-1.9451337]
Agent gate_2 episode reward: [-2.03616763]
All agents episode reward: [-2.03616763]
Agent gate_2 episode reward: [-2.15197776]
All agents episode reward: [-2.15197776]
Agent gate_2 episode reward: [-2.12090924]
All agents episode reward: [-2.12090924]
Agent gate_2 episode reward: [-2.19413783]
All agents episode reward: [-2.19413783]
Agent gate_2 episode reward: [-2.216212]
All agents episode reward: [-2.216212]
Iteration 3: 100%|██████████| 10/10 [00:25<00:00,  2.55s/it, episode=40, norm_ret=-2.358, true_ret=-721510.062, steps=600]
Agent gate_2 episode reward: [-2.21531896]
All agents episode reward: [-2.21531896]
Agent gate_2 episode reward: [-2.16642771]
All agents episode reward: [-2.16642771]
Agent gate_2 episode reward: [-2.28290178]
All agents episode reward: [-2.28290178]
Agent gate_2 episode reward: [-2.30916218]
All agents episode reward: [-2.30916218]
Agent gate_2 episode reward: [-2.36982987]
All agents episode reward: [-2.36982987]
Agent gate_2 episode reward: [-2.41867852]
All agents episode reward: [-2.41867852]
Agent gate_2 episode reward: [-2.39775337]
All agents episode reward: [-2.39775337]
Agent gate_2 episode reward: [-2.44454971]
All agents episode reward: [-2.44454971]
Agent gate_2 episode reward: [-2.47144606]
All agents episode reward: [-2.47144606]
Agent gate_2 episode reward: [-2.50355302]
All agents episode reward: [-2.50355302]
Iteration 4: 100%|██████████| 10/10 [00:24<00:00,  2.49s/it, episode=50, norm_ret=-2.613, true_ret=-706746.250, steps=600]
Agent gate_2 episode reward: [-2.48454523]
All agents episode reward: [-2.48454523]
Agent gate_2 episode reward: [-2.46005789]
All agents episode reward: [-2.46005789]
Agent gate_2 episode reward: [-2.58762526]
All agents episode reward: [-2.58762526]
Agent gate_2 episode reward: [-2.60283696]
All agents episode reward: [-2.60283696]
Agent gate_2 episode reward: [-2.64581567]
All agents episode reward: [-2.64581567]
Agent gate_2 episode reward: [-2.64337578]
All agents episode reward: [-2.64337578]
Agent gate_2 episode reward: [-2.62802344]
All agents episode reward: [-2.62802344]
Agent gate_2 episode reward: [-2.70406059]
All agents episode reward: [-2.70406059]
Agent gate_2 episode reward: [-2.64423283]
All agents episode reward: [-2.64423283]
Agent gate_2 episode reward: [-2.72675862]
All agents episode reward: [-2.72675862]
Iteration 5: 100%|██████████| 10/10 [00:29<00:00,  2.90s/it, episode=60, norm_ret=-3.293, true_ret=-1299394.000, steps=600]
Agent gate_2 episode reward: [-2.90378038]
All agents episode reward: [-2.90378038]
Agent gate_2 episode reward: [-2.97706087]
All agents episode reward: [-2.97706087]
Agent gate_2 episode reward: [-2.91355237]
All agents episode reward: [-2.91355237]
Agent gate_2 episode reward: [-2.96519499]
All agents episode reward: [-2.96519499]
Agent gate_2 episode reward: [-3.13666538]
All agents episode reward: [-3.13666538]
Agent gate_2 episode reward: [-3.59246827]
All agents episode reward: [-3.59246827]
Agent gate_2 episode reward: [-2.96402299]
All agents episode reward: [-2.96402299]
Agent gate_2 episode reward: [-3.04520591]
All agents episode reward: [-3.04520591]
Agent gate_2 episode reward: [-2.95617049]
All agents episode reward: [-2.95617049]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -769438.000 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-5.47123397]
All agents episode reward: [-5.47123397]
Iteration 6: 100%|██████████| 10/10 [00:29<00:00,  2.93s/it, episode=70, norm_ret=-3.832, true_ret=-1350640.625, steps=600]
Agent gate_2 episode reward: [-3.48607222]
All agents episode reward: [-3.48607222]
Agent gate_2 episode reward: [-3.41227533]
All agents episode reward: [-3.41227533]
Agent gate_2 episode reward: [-3.42208599]
All agents episode reward: [-3.42208599]
Agent gate_2 episode reward: [-3.45967979]
All agents episode reward: [-3.45967979]
Agent gate_2 episode reward: [-3.67072976]
All agents episode reward: [-3.67072976]
Agent gate_2 episode reward: [-3.58546509]
All agents episode reward: [-3.58546509]
Agent gate_2 episode reward: [-3.51669794]
All agents episode reward: [-3.51669794]
Agent gate_2 episode reward: [-3.55547309]
All agents episode reward: [-3.55547309]
Agent gate_2 episode reward: [-3.90762577]
All agents episode reward: [-3.90762577]
Agent gate_2 episode reward: [-6.30827836]
All agents episode reward: [-6.30827836]
Iteration 7: 100%|██████████| 10/10 [00:27<00:00,  2.77s/it, episode=80, norm_ret=-5.893, true_ret=-1090543.125, steps=600]
Agent gate_2 episode reward: [-3.87796126]
All agents episode reward: [-3.87796126]
Agent gate_2 episode reward: [-4.00307547]
All agents episode reward: [-4.00307547]
Agent gate_2 episode reward: [-3.87564519]
All agents episode reward: [-3.87564519]
Agent gate_2 episode reward: [-7.26313822]
All agents episode reward: [-7.26313822]
Agent gate_2 episode reward: [-6.9511014]
All agents episode reward: [-6.9511014]
Agent gate_2 episode reward: [-3.84354351]
All agents episode reward: [-3.84354351]
Agent gate_2 episode reward: [-11.61345641]
All agents episode reward: [-11.61345641]
Agent gate_2 episode reward: [-8.45166347]
All agents episode reward: [-8.45166347]
Agent gate_2 episode reward: [-3.89857651]
All agents episode reward: [-3.89857651]
Agent gate_2 episode reward: [-5.14920171]
All agents episode reward: [-5.14920171]
Iteration 8: 100%|██████████| 10/10 [00:29<00:00,  2.91s/it, episode=90, norm_ret=-4.970, true_ret=-1691984.375, steps=600]
Agent gate_2 episode reward: [-7.23231139]
All agents episode reward: [-7.23231139]
Agent gate_2 episode reward: [-8.46502123]
All agents episode reward: [-8.46502123]
Agent gate_2 episode reward: [-3.6811672]
All agents episode reward: [-3.6811672]
Agent gate_2 episode reward: [-3.84169616]
All agents episode reward: [-3.84169616]
Agent gate_2 episode reward: [-3.68395772]
All agents episode reward: [-3.68395772]
Agent gate_2 episode reward: [-3.7866006]
All agents episode reward: [-3.7866006]
Agent gate_2 episode reward: [-3.75132551]
All agents episode reward: [-3.75132551]
Agent gate_2 episode reward: [-3.73039711]
All agents episode reward: [-3.73039711]
Agent gate_2 episode reward: [-4.19184862]
All agents episode reward: [-4.19184862]
Agent gate_2 episode reward: [-7.3341505]
All agents episode reward: [-7.3341505]
Iteration 9: 100%|██████████| 10/10 [00:29<00:00,  2.93s/it, episode=100, norm_ret=-5.042, true_ret=-921504.438, steps=600]
Agent gate_2 episode reward: [-7.11527344]
All agents episode reward: [-7.11527344]
Agent gate_2 episode reward: [-4.51893512]
All agents episode reward: [-4.51893512]
Agent gate_2 episode reward: [-6.83406752]
All agents episode reward: [-6.83406752]
Agent gate_2 episode reward: [-6.00117124]
All agents episode reward: [-6.00117124]
Agent gate_2 episode reward: [-5.05000977]
All agents episode reward: [-5.05000977]
Agent gate_2 episode reward: [-4.2134963]
All agents episode reward: [-4.2134963]
Agent gate_2 episode reward: [-4.3678369]
All agents episode reward: [-4.3678369]
Agent gate_2 episode reward: [-4.07339943]
All agents episode reward: [-4.07339943]
Agent gate_2 episode reward: [-4.07734063]
All agents episode reward: [-4.07734063]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -606495.938 at episode 100 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-4.17264034]
All agents episode reward: [-4.17264034]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -607391.938 | Total reward: -607391.938
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -803949.375 | Total reward: -803949.375
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -861434.625 | Total reward: -861434.625
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -1040807.750 | Total reward: -1040807.750
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -757079.062 | Total reward: -757079.062
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -867353.312 | Total reward: -867353.312
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -941160.625 | Total reward: -941160.625
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -809532.000 | Total reward: -809532.000
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -833653.562 | Total reward: -833653.562
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -700519.250 | Total reward: -700519.250
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -822288.125 ± 114600.727
  Average reward: -822288.125 ± 114600.727
  Total reward: -822288.125 ± 114600.727
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -643709.938 | Total reward: -643709.938
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -851560.312 | Total reward: -851560.312
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -920434.188 | Total reward: -920434.188
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1048110.500 | Total reward: -1048110.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -791232.562 | Total reward: -791232.562
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -907931.062 | Total reward: -907931.062
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -959172.375 | Total reward: -959172.375
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -854216.688 | Total reward: -854216.688
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -870864.938 | Total reward: -870864.938
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -711501.500 | Total reward: -711501.500
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -855873.375 ± 111707.203
  Average reward: -855873.375 ± 111707.203
  Total reward: -855873.375 ± 111707.203
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.938 | Total reward: -967434.938
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.688 | Total reward: -867192.688
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902276.062 | Total reward: -902276.062
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808263.062 | Total reward: -808263.062
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.438 | Total reward: -714115.438
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.219
  Average reward: -815120.250 ± 93512.219
  Total reward: -815120.250 ± 93512.219
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -822288.125
Rule-based avg reward: -855873.375
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
