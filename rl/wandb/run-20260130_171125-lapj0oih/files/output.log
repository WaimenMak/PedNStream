Iteration 0: 100%|██████████| 10/10 [00:24<00:00,  2.41s/it, episode=10, norm_ret=-12.505, true_ret=-42324196.000, steps=600]
Agent gate_2 episode reward: [-57.47444239]
All agents episode reward: [-57.47444239]
Agent gate_2 episode reward: [-0.86563288]
All agents episode reward: [-0.86563288]
Agent gate_2 episode reward: [-5.88870037]
All agents episode reward: [-5.88870037]
Agent gate_2 episode reward: [-1.26414545]
All agents episode reward: [-1.26414545]
Agent gate_2 episode reward: [-1.26669081]
All agents episode reward: [-1.26669081]
Agent gate_2 episode reward: [-1.1610788]
All agents episode reward: [-1.1610788]
Agent gate_2 episode reward: [-28.15704368]
All agents episode reward: [-28.15704368]
Agent gate_2 episode reward: [-0.59354007]
All agents episode reward: [-0.59354007]
Agent gate_2 episode reward: [-0.64929319]
All agents episode reward: [-0.64929319]
Agent gate_2 episode reward: [-27.72513468]
All agents episode reward: [-27.72513468]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.28s/it, episode=20, norm_ret=-3.524, true_ret=-765882.000, steps=600]
Agent gate_2 episode reward: [-2.96349288]
All agents episode reward: [-2.96349288]
Agent gate_2 episode reward: [-0.31248381]
All agents episode reward: [-0.31248381]
Agent gate_2 episode reward: [-0.33586728]
All agents episode reward: [-0.33586728]
Agent gate_2 episode reward: [-29.60763214]
All agents episode reward: [-29.60763214]
Agent gate_2 episode reward: [-0.24137212]
All agents episode reward: [-0.24137212]
Agent gate_2 episode reward: [-0.2151712]
All agents episode reward: [-0.2151712]
Agent gate_2 episode reward: [-0.31087545]
All agents episode reward: [-0.31087545]
Agent gate_2 episode reward: [-0.77087483]
All agents episode reward: [-0.77087483]
Agent gate_2 episode reward: [-0.22905653]
All agents episode reward: [-0.22905653]
Agent gate_2 episode reward: [-0.25121566]
All agents episode reward: [-0.25121566]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.33s/it, episode=30, norm_ret=-1.347, true_ret=-706822.938, steps=600]
Agent gate_2 episode reward: [-0.2487779]
All agents episode reward: [-0.2487779]
Agent gate_2 episode reward: [-0.3206557]
All agents episode reward: [-0.3206557]
Agent gate_2 episode reward: [-0.29766897]
All agents episode reward: [-0.29766897]
Agent gate_2 episode reward: [-0.23002684]
All agents episode reward: [-0.23002684]
Agent gate_2 episode reward: [-0.25535295]
All agents episode reward: [-0.25535295]
Agent gate_2 episode reward: [-2.71975183]
All agents episode reward: [-2.71975183]
Agent gate_2 episode reward: [-0.29515516]
All agents episode reward: [-0.29515516]
Agent gate_2 episode reward: [-1.74259263]
All agents episode reward: [-1.74259263]
Agent gate_2 episode reward: [-7.08823053]
All agents episode reward: [-7.08823053]
Agent gate_2 episode reward: [-0.27515966]
All agents episode reward: [-0.27515966]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.27s/it, episode=40, norm_ret=-1.343, true_ret=-3181513.750, steps=600]
Agent gate_2 episode reward: [-0.57759083]
All agents episode reward: [-0.57759083]
Agent gate_2 episode reward: [-1.16476447]
All agents episode reward: [-1.16476447]
Agent gate_2 episode reward: [-5.38355252]
All agents episode reward: [-5.38355252]
Agent gate_2 episode reward: [-0.44226927]
All agents episode reward: [-0.44226927]
Agent gate_2 episode reward: [-0.68213252]
All agents episode reward: [-0.68213252]
Agent gate_2 episode reward: [-2.13086558]
All agents episode reward: [-2.13086558]
Agent gate_2 episode reward: [-0.73668946]
All agents episode reward: [-0.73668946]
Agent gate_2 episode reward: [-0.31180684]
All agents episode reward: [-0.31180684]
Agent gate_2 episode reward: [-0.58977469]
All agents episode reward: [-0.58977469]
Agent gate_2 episode reward: [-1.40905983]
All agents episode reward: [-1.40905983]
Iteration 4: 100%|██████████| 10/10 [00:24<00:00,  2.41s/it, episode=50, norm_ret=-0.569, true_ret=-876972.375, steps=600]
Agent gate_2 episode reward: [-0.702932]
All agents episode reward: [-0.702932]
Agent gate_2 episode reward: [-0.52875744]
All agents episode reward: [-0.52875744]
Agent gate_2 episode reward: [-0.33593824]
All agents episode reward: [-0.33593824]
Agent gate_2 episode reward: [-0.43978502]
All agents episode reward: [-0.43978502]
Agent gate_2 episode reward: [-0.57323181]
All agents episode reward: [-0.57323181]
Agent gate_2 episode reward: [-0.75686317]
All agents episode reward: [-0.75686317]
Agent gate_2 episode reward: [-0.43343987]
All agents episode reward: [-0.43343987]
Agent gate_2 episode reward: [-0.57115649]
All agents episode reward: [-0.57115649]
Agent gate_2 episode reward: [-0.91615727]
All agents episode reward: [-0.91615727]
Agent gate_2 episode reward: [-0.43095006]
All agents episode reward: [-0.43095006]
Iteration 5: 100%|██████████| 10/10 [00:28<00:00,  2.81s/it, episode=60, norm_ret=-0.694, true_ret=-1253256.375, steps=600]
Agent gate_2 episode reward: [-0.8289941]
All agents episode reward: [-0.8289941]
Agent gate_2 episode reward: [-0.42842051]
All agents episode reward: [-0.42842051]
Agent gate_2 episode reward: [-0.53983031]
All agents episode reward: [-0.53983031]
Agent gate_2 episode reward: [-0.69075616]
All agents episode reward: [-0.69075616]
Agent gate_2 episode reward: [-0.70219937]
All agents episode reward: [-0.70219937]
Agent gate_2 episode reward: [-0.85590677]
All agents episode reward: [-0.85590677]
Agent gate_2 episode reward: [-0.71509908]
All agents episode reward: [-0.71509908]
Agent gate_2 episode reward: [-0.74976542]
All agents episode reward: [-0.74976542]
Agent gate_2 episode reward: [-0.75487411]
All agents episode reward: [-0.75487411]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -1826626.625 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.67142283]
All agents episode reward: [-0.67142283]
Iteration 6: 100%|██████████| 10/10 [00:27<00:00,  2.75s/it, episode=70, norm_ret=-0.463, true_ret=-710367.062, steps=600]
Agent gate_2 episode reward: [-0.60748863]
All agents episode reward: [-0.60748863]
Agent gate_2 episode reward: [-0.50866058]
All agents episode reward: [-0.50866058]
Agent gate_2 episode reward: [-0.50134613]
All agents episode reward: [-0.50134613]
Agent gate_2 episode reward: [-0.43483405]
All agents episode reward: [-0.43483405]
Agent gate_2 episode reward: [-0.46643977]
All agents episode reward: [-0.46643977]
Agent gate_2 episode reward: [-0.43246559]
All agents episode reward: [-0.43246559]
Agent gate_2 episode reward: [-0.36780837]
All agents episode reward: [-0.36780837]
Agent gate_2 episode reward: [-0.43022279]
All agents episode reward: [-0.43022279]
Agent gate_2 episode reward: [-0.45279165]
All agents episode reward: [-0.45279165]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -1101210.500 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.42301763]
All agents episode reward: [-0.42301763]
Iteration 7: 100%|██████████| 10/10 [00:26<00:00,  2.69s/it, episode=80, norm_ret=-0.505, true_ret=-829961.750, steps=600]
Agent gate_2 episode reward: [-0.43087965]
All agents episode reward: [-0.43087965]
Agent gate_2 episode reward: [-0.50794412]
All agents episode reward: [-0.50794412]
Agent gate_2 episode reward: [-0.49757578]
All agents episode reward: [-0.49757578]
Agent gate_2 episode reward: [-0.49014495]
All agents episode reward: [-0.49014495]
Agent gate_2 episode reward: [-0.52381218]
All agents episode reward: [-0.52381218]
Agent gate_2 episode reward: [-0.56121984]
All agents episode reward: [-0.56121984]
Agent gate_2 episode reward: [-0.49945756]
All agents episode reward: [-0.49945756]
Agent gate_2 episode reward: [-0.48612483]
All agents episode reward: [-0.48612483]
Agent gate_2 episode reward: [-0.51566684]
All agents episode reward: [-0.51566684]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -992499.188 at episode 80 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.5392079]
All agents episode reward: [-0.5392079]
Iteration 8: 100%|██████████| 10/10 [00:27<00:00,  2.77s/it, episode=90, norm_ret=-0.533, true_ret=-810871.625, steps=600]
Agent gate_2 episode reward: [-0.53500323]
All agents episode reward: [-0.53500323]
Agent gate_2 episode reward: [-0.54673393]
All agents episode reward: [-0.54673393]
Agent gate_2 episode reward: [-0.49050262]
All agents episode reward: [-0.49050262]
Agent gate_2 episode reward: [-0.53438771]
All agents episode reward: [-0.53438771]
Agent gate_2 episode reward: [-0.50522665]
All agents episode reward: [-0.50522665]
Agent gate_2 episode reward: [-0.53768352]
All agents episode reward: [-0.53768352]
Agent gate_2 episode reward: [-0.52226513]
All agents episode reward: [-0.52226513]
Agent gate_2 episode reward: [-0.54775293]
All agents episode reward: [-0.54775293]
Agent gate_2 episode reward: [-0.54276935]
All agents episode reward: [-0.54276935]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -880903.375 at episode 90 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.56714499]
All agents episode reward: [-0.56714499]
Iteration 9: 100%|██████████| 10/10 [00:26<00:00,  2.62s/it, episode=100, norm_ret=-0.618, true_ret=-831638.750, steps=600]
Agent gate_2 episode reward: [-0.59403824]
All agents episode reward: [-0.59403824]
Agent gate_2 episode reward: [-0.61896326]
All agents episode reward: [-0.61896326]
Agent gate_2 episode reward: [-0.57159633]
All agents episode reward: [-0.57159633]
Agent gate_2 episode reward: [-0.57384568]
All agents episode reward: [-0.57384568]
Agent gate_2 episode reward: [-0.61266682]
All agents episode reward: [-0.61266682]
Agent gate_2 episode reward: [-0.60104873]
All agents episode reward: [-0.60104873]
Agent gate_2 episode reward: [-0.6415791]
All agents episode reward: [-0.6415791]
Agent gate_2 episode reward: [-0.69508516]
All agents episode reward: [-0.69508516]
Agent gate_2 episode reward: [-0.64834249]
All agents episode reward: [-0.64834249]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -860780.125 at episode 100 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-0.62033264]
All agents episode reward: [-0.62033264]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -910959.312 | Total reward: -910959.312
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -810809.750 | Total reward: -810809.750
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -882200.375 | Total reward: -882200.375
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -1023553.938 | Total reward: -1023553.938
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -785085.188 | Total reward: -785085.188
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -958725.625 | Total reward: -958725.625
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -964909.438 | Total reward: -964909.438
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -898164.375 | Total reward: -898164.375
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -934486.875 | Total reward: -934486.875
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -878026.500 | Total reward: -878026.500
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -904692.188 ± 67808.656
  Average reward: -904692.188 ± 67808.656
  Total reward: -904692.188 ± 67808.656
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -643709.938 | Total reward: -643709.938
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -851560.312 | Total reward: -851560.312
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -920434.188 | Total reward: -920434.188
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1048110.500 | Total reward: -1048110.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -791232.562 | Total reward: -791232.562
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -907931.062 | Total reward: -907931.062
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -959172.375 | Total reward: -959172.375
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -854216.688 | Total reward: -854216.688
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -870864.938 | Total reward: -870864.938
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -711501.500 | Total reward: -711501.500
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -855873.375 ± 111707.203
  Average reward: -855873.375 ± 111707.203
  Total reward: -855873.375 ± 111707.203
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.938 | Total reward: -967434.938
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.688 | Total reward: -867192.688
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902276.062 | Total reward: -902276.062
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808263.062 | Total reward: -808263.062
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.438 | Total reward: -714115.438
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.219
  Average reward: -815120.250 ± 93512.219
  Total reward: -815120.250 ± 93512.219
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -904692.188
Rule-based avg reward: -855873.375
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
