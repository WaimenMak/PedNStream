Iteration 0: 100%|██████████| 10/10 [00:19<00:00,  1.95s/it, episode=10, norm_ret=-8.792, true_ret=-577623.688, steps=600]
Agent gate_2 episode reward: [-53.45309346]
All agents episode reward: [-53.45309346]
Agent gate_2 episode reward: [-16.31967759]
All agents episode reward: [-16.31967759]
Agent gate_2 episode reward: [-2.51568836]
All agents episode reward: [-2.51568836]
Agent gate_2 episode reward: [-1.72187282]
All agents episode reward: [-1.72187282]
Agent gate_2 episode reward: [-3.36899587]
All agents episode reward: [-3.36899587]
Agent gate_2 episode reward: [-1.92662315]
All agents episode reward: [-1.92662315]
Agent gate_2 episode reward: [-1.99447114]
All agents episode reward: [-1.99447114]
Agent gate_2 episode reward: [-2.09949077]
All agents episode reward: [-2.09949077]
Agent gate_2 episode reward: [-2.20814877]
All agents episode reward: [-2.20814877]
Agent gate_2 episode reward: [-2.31279139]
All agents episode reward: [-2.31279139]
Iteration 1: 100%|██████████| 10/10 [00:19<00:00,  1.99s/it, episode=20, norm_ret=-2.864, true_ret=-566230.375, steps=600]
Agent gate_2 episode reward: [-2.43214637]
All agents episode reward: [-2.43214637]
Agent gate_2 episode reward: [-2.48310568]
All agents episode reward: [-2.48310568]
Agent gate_2 episode reward: [-2.56180375]
All agents episode reward: [-2.56180375]
Agent gate_2 episode reward: [-2.65047051]
All agents episode reward: [-2.65047051]
Agent gate_2 episode reward: [-2.74219687]
All agents episode reward: [-2.74219687]
Agent gate_2 episode reward: [-2.7819772]
All agents episode reward: [-2.7819772]
Agent gate_2 episode reward: [-2.89739255]
All agents episode reward: [-2.89739255]
Agent gate_2 episode reward: [-2.90927124]
All agents episode reward: [-2.90927124]
Agent gate_2 episode reward: [-4.11618952]
All agents episode reward: [-4.11618952]
Agent gate_2 episode reward: [-3.06052457]
All agents episode reward: [-3.06052457]
Iteration 2: 100%|██████████| 10/10 [00:18<00:00,  1.87s/it, episode=30, norm_ret=-3.443, true_ret=-558726.250, steps=600]
Agent gate_2 episode reward: [-3.10330851]
All agents episode reward: [-3.10330851]
Agent gate_2 episode reward: [-3.24279756]
All agents episode reward: [-3.24279756]
Agent gate_2 episode reward: [-3.42761003]
All agents episode reward: [-3.42761003]
Agent gate_2 episode reward: [-3.34527823]
All agents episode reward: [-3.34527823]
Agent gate_2 episode reward: [-3.46938648]
All agents episode reward: [-3.46938648]
Agent gate_2 episode reward: [-3.50994368]
All agents episode reward: [-3.50994368]
Agent gate_2 episode reward: [-3.46120692]
All agents episode reward: [-3.46120692]
Agent gate_2 episode reward: [-3.60106532]
All agents episode reward: [-3.60106532]
Agent gate_2 episode reward: [-3.6468685]
All agents episode reward: [-3.6468685]
Agent gate_2 episode reward: [-3.62444542]
All agents episode reward: [-3.62444542]
Iteration 3: 100%|██████████| 10/10 [00:19<00:00,  1.94s/it, episode=40, norm_ret=-4.018, true_ret=-573615.188, steps=600]
Agent gate_2 episode reward: [-3.74781877]
All agents episode reward: [-3.74781877]
Agent gate_2 episode reward: [-3.84128398]
All agents episode reward: [-3.84128398]
Agent gate_2 episode reward: [-3.88537102]
All agents episode reward: [-3.88537102]
Agent gate_2 episode reward: [-3.9511218]
All agents episode reward: [-3.9511218]
Agent gate_2 episode reward: [-4.00337855]
All agents episode reward: [-4.00337855]
Agent gate_2 episode reward: [-4.05851145]
All agents episode reward: [-4.05851145]
Agent gate_2 episode reward: [-4.05937787]
All agents episode reward: [-4.05937787]
Agent gate_2 episode reward: [-4.27455684]
All agents episode reward: [-4.27455684]
Agent gate_2 episode reward: [-4.11876876]
All agents episode reward: [-4.11876876]
Agent gate_2 episode reward: [-4.23847551]
All agents episode reward: [-4.23847551]
Iteration 4: 100%|██████████| 10/10 [00:18<00:00,  1.85s/it, episode=50, norm_ret=-4.413, true_ret=-572040.500, steps=600]
Agent gate_2 episode reward: [-4.71683641]
All agents episode reward: [-4.71683641]
Agent gate_2 episode reward: [-4.05665514]
All agents episode reward: [-4.05665514]
Agent gate_2 episode reward: [-4.01979565]
All agents episode reward: [-4.01979565]
Agent gate_2 episode reward: [-4.08538605]
All agents episode reward: [-4.08538605]
Agent gate_2 episode reward: [-4.40338305]
All agents episode reward: [-4.40338305]
Agent gate_2 episode reward: [-4.48730218]
All agents episode reward: [-4.48730218]
Agent gate_2 episode reward: [-4.44757916]
All agents episode reward: [-4.44757916]
Agent gate_2 episode reward: [-4.61352623]
All agents episode reward: [-4.61352623]
Agent gate_2 episode reward: [-4.63199991]
All agents episode reward: [-4.63199991]
Agent gate_2 episode reward: [-4.66971469]
All agents episode reward: [-4.66971469]
Iteration 5: 100%|██████████| 10/10 [00:21<00:00,  2.15s/it, episode=60, norm_ret=-4.926, true_ret=-573680.250, steps=600]
Agent gate_2 episode reward: [-4.72158076]
All agents episode reward: [-4.72158076]
Agent gate_2 episode reward: [-4.65273686]
All agents episode reward: [-4.65273686]
Agent gate_2 episode reward: [-4.96235347]
All agents episode reward: [-4.96235347]
Agent gate_2 episode reward: [-4.81659421]
All agents episode reward: [-4.81659421]
Agent gate_2 episode reward: [-5.01603095]
All agents episode reward: [-5.01603095]
Agent gate_2 episode reward: [-4.95985]
All agents episode reward: [-4.95985]
Agent gate_2 episode reward: [-4.91240818]
All agents episode reward: [-4.91240818]
Agent gate_2 episode reward: [-5.13836006]
All agents episode reward: [-5.13836006]
Agent gate_2 episode reward: [-4.99742565]
All agents episode reward: [-4.99742565]
Saved 1 agents to ppo_agents_butterfly_scA
[Validation] New best avg return: -567162.750 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scA)
Agent gate_2 episode reward: [-5.08010712]
All agents episode reward: [-5.08010712]
Iteration 6: 100%|██████████| 10/10 [00:22<00:00,  2.29s/it, episode=70, norm_ret=-5.390, true_ret=-551494.125, steps=600]
Agent gate_2 episode reward: [-5.19821114]
All agents episode reward: [-5.19821114]
Agent gate_2 episode reward: [-5.27652444]
All agents episode reward: [-5.27652444]
Agent gate_2 episode reward: [-5.33633976]
All agents episode reward: [-5.33633976]
Agent gate_2 episode reward: [-5.42002588]
All agents episode reward: [-5.42002588]
Agent gate_2 episode reward: [-5.4172039]
All agents episode reward: [-5.4172039]
Agent gate_2 episode reward: [-5.35467088]
All agents episode reward: [-5.35467088]
Agent gate_2 episode reward: [-5.54562407]
All agents episode reward: [-5.54562407]
Agent gate_2 episode reward: [-5.23912154]
All agents episode reward: [-5.23912154]
Agent gate_2 episode reward: [-5.72691407]
All agents episode reward: [-5.72691407]
Agent gate_2 episode reward: [-5.38693103]
All agents episode reward: [-5.38693103]
Iteration 7: 100%|██████████| 10/10 [00:21<00:00,  2.17s/it, episode=80, norm_ret=-6.365, true_ret=-618167.688, steps=600]
Agent gate_2 episode reward: [-6.35828277]
All agents episode reward: [-6.35828277]
Agent gate_2 episode reward: [-6.17337486]
All agents episode reward: [-6.17337486]
Agent gate_2 episode reward: [-6.20130732]
All agents episode reward: [-6.20130732]
Agent gate_2 episode reward: [-6.2601307]
All agents episode reward: [-6.2601307]
Agent gate_2 episode reward: [-6.93312132]
All agents episode reward: [-6.93312132]
Agent gate_2 episode reward: [-6.19696203]
All agents episode reward: [-6.19696203]
Agent gate_2 episode reward: [-6.24999357]
All agents episode reward: [-6.24999357]
Agent gate_2 episode reward: [-6.34733899]
All agents episode reward: [-6.34733899]
Agent gate_2 episode reward: [-6.38706522]
All agents episode reward: [-6.38706522]
Saved 1 agents to ppo_agents_butterfly_scA
[Validation] New best avg return: -519857.406 at episode 80 (over 5 val episodes, saved to ppo_agents_butterfly_scA)
Agent gate_2 episode reward: [-6.53897725]
All agents episode reward: [-6.53897725]
Iteration 8: 100%|██████████| 10/10 [00:21<00:00,  2.15s/it, episode=90, norm_ret=-6.811, true_ret=-615068.062, steps=600]
Agent gate_2 episode reward: [-6.68391086]
All agents episode reward: [-6.68391086]
Agent gate_2 episode reward: [-6.68309878]
All agents episode reward: [-6.68309878]
Agent gate_2 episode reward: [-6.66675392]
All agents episode reward: [-6.66675392]
Agent gate_2 episode reward: [-6.71240729]
All agents episode reward: [-6.71240729]
Agent gate_2 episode reward: [-6.78207051]
All agents episode reward: [-6.78207051]
Agent gate_2 episode reward: [-6.92277294]
All agents episode reward: [-6.92277294]
Agent gate_2 episode reward: [-6.85420127]
All agents episode reward: [-6.85420127]
Agent gate_2 episode reward: [-6.8758858]
All agents episode reward: [-6.8758858]
Agent gate_2 episode reward: [-6.97972509]
All agents episode reward: [-6.97972509]
Agent gate_2 episode reward: [-6.9531026]
All agents episode reward: [-6.9531026]
Iteration 9: 100%|██████████| 10/10 [00:21<00:00,  2.17s/it, episode=100, norm_ret=-4.321, true_ret=-378977.875, steps=600]
Agent gate_2 episode reward: [-4.12362761]
All agents episode reward: [-4.12362761]
Agent gate_2 episode reward: [-3.88661973]
All agents episode reward: [-3.88661973]
Agent gate_2 episode reward: [-4.27557878]
All agents episode reward: [-4.27557878]
Agent gate_2 episode reward: [-4.28495718]
All agents episode reward: [-4.28495718]
Agent gate_2 episode reward: [-4.38028919]
All agents episode reward: [-4.38028919]
Agent gate_2 episode reward: [-4.35853482]
All agents episode reward: [-4.35853482]
Agent gate_2 episode reward: [-4.54328261]
All agents episode reward: [-4.54328261]
Agent gate_2 episode reward: [-4.33466437]
All agents episode reward: [-4.33466437]
Agent gate_2 episode reward: [-4.50179312]
All agents episode reward: [-4.50179312]
Agent gate_2 episode reward: [-4.51674606]
All agents episode reward: [-4.51674606]
Loaded 1 agents from ppo_agents_butterfly_scA
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -272727.625 | Total reward: -272727.625
Saved run 1 to rl_training/butterfly_scA/ppo_run1
  Run 2/10... Avg agent reward (episode): -490689.875 | Total reward: -490689.875
Saved run 2 to rl_training/butterfly_scA/ppo_run2
  Run 3/10... Avg agent reward (episode): -597446.125 | Total reward: -597446.125
Saved run 3 to rl_training/butterfly_scA/ppo_run3
  Run 4/10... Avg agent reward (episode): -532406.125 | Total reward: -532406.125
Saved run 4 to rl_training/butterfly_scA/ppo_run4
  Run 5/10... Avg agent reward (episode): -622170.562 | Total reward: -622170.562
Saved run 5 to rl_training/butterfly_scA/ppo_run5
  Run 6/10... Avg agent reward (episode): -592498.812 | Total reward: -592498.812
Saved run 6 to rl_training/butterfly_scA/ppo_run6
  Run 7/10... Avg agent reward (episode): -598949.812 | Total reward: -598949.812
Saved run 7 to rl_training/butterfly_scA/ppo_run7
  Run 8/10... Avg agent reward (episode): -550361.875 | Total reward: -550361.875
Saved run 8 to rl_training/butterfly_scA/ppo_run8
  Run 9/10... Avg agent reward (episode): -590151.062 | Total reward: -590151.062
Saved run 9 to rl_training/butterfly_scA/ppo_run9
  Run 10/10... Avg agent reward (episode): -617299.062 | Total reward: -617299.062
Saved run 10 to rl_training/butterfly_scA/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -546470.125 ± 99189.703
  Average reward: -546470.125 ± 99189.703
  Total reward: -546470.125 ± 99189.703
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -272727.625 | Total reward: -272727.625
Saved run 1 to rl_training/butterfly_scA/rule_based_run1
  Run 2/10... Avg agent reward (episode): -490689.875 | Total reward: -490689.875
Saved run 2 to rl_training/butterfly_scA/rule_based_run2
  Run 3/10... Avg agent reward (episode): -597446.125 | Total reward: -597446.125
Saved run 3 to rl_training/butterfly_scA/rule_based_run3
  Run 4/10... Avg agent reward (episode): -532406.125 | Total reward: -532406.125
Saved run 4 to rl_training/butterfly_scA/rule_based_run4
  Run 5/10... Avg agent reward (episode): -622170.562 | Total reward: -622170.562
Saved run 5 to rl_training/butterfly_scA/rule_based_run5
  Run 6/10... Avg agent reward (episode): -592498.812 | Total reward: -592498.812
Saved run 6 to rl_training/butterfly_scA/rule_based_run6
  Run 7/10... Avg agent reward (episode): -598949.812 | Total reward: -598949.812
Saved run 7 to rl_training/butterfly_scA/rule_based_run7
  Run 8/10... Avg agent reward (episode): -550361.875 | Total reward: -550361.875
Saved run 8 to rl_training/butterfly_scA/rule_based_run8
  Run 9/10... Avg agent reward (episode): -590151.062 | Total reward: -590151.062
Saved run 9 to rl_training/butterfly_scA/rule_based_run9
  Run 10/10... Avg agent reward (episode): -617299.062 | Total reward: -617299.062
Saved run 10 to rl_training/butterfly_scA/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -546470.125 ± 99189.703
  Average reward: -546470.125 ± 99189.703
  Total reward: -546470.125 ± 99189.703
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -272727.625 | Total reward: -272727.625
Saved run 1 to rl_training/butterfly_scA/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -490689.875 | Total reward: -490689.875
Saved run 2 to rl_training/butterfly_scA/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -597446.125 | Total reward: -597446.125
Saved run 3 to rl_training/butterfly_scA/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -532406.125 | Total reward: -532406.125
Saved run 4 to rl_training/butterfly_scA/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -622170.562 | Total reward: -622170.562
Saved run 5 to rl_training/butterfly_scA/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -592498.812 | Total reward: -592498.812
Saved run 6 to rl_training/butterfly_scA/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -598949.812 | Total reward: -598949.812
Saved run 7 to rl_training/butterfly_scA/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -550361.875 | Total reward: -550361.875
Saved run 8 to rl_training/butterfly_scA/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -590151.062 | Total reward: -590151.062
Saved run 9 to rl_training/butterfly_scA/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -617299.062 | Total reward: -617299.062
Saved run 10 to rl_training/butterfly_scA/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -546470.125 ± 99189.703
  Average reward: -546470.125 ± 99189.703
  Total reward: -546470.125 ± 99189.703
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -546470.125
Rule-based avg reward: -546470.125
No control avg reward: -546470.125
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
