Iteration 0: 100%|██████████| 10/10 [00:23<00:00,  2.38s/it, episode=10, norm_ret=-7.846, true_ret=-734366.688, steps=600]
Agent gate_2 episode reward: [-56.81497729]
All agents episode reward: [-56.81497729]
Agent gate_2 episode reward: [-11.58330805]
All agents episode reward: [-11.58330805]
Agent gate_2 episode reward: [-1.06690656]
All agents episode reward: [-1.06690656]
Agent gate_2 episode reward: [-0.97627059]
All agents episode reward: [-0.97627059]
Agent gate_2 episode reward: [-1.79395624]
All agents episode reward: [-1.79395624]
Agent gate_2 episode reward: [-1.18384797]
All agents episode reward: [-1.18384797]
Agent gate_2 episode reward: [-1.25158677]
All agents episode reward: [-1.25158677]
Agent gate_2 episode reward: [-1.19513701]
All agents episode reward: [-1.19513701]
Agent gate_2 episode reward: [-1.26852458]
All agents episode reward: [-1.26852458]
Agent gate_2 episode reward: [-1.32814513]
All agents episode reward: [-1.32814513]
Iteration 1: 100%|██████████| 10/10 [00:22<00:00,  2.27s/it, episode=20, norm_ret=-1.578, true_ret=-736996.938, steps=600]
Agent gate_2 episode reward: [-1.38680878]
All agents episode reward: [-1.38680878]
Agent gate_2 episode reward: [-1.39179489]
All agents episode reward: [-1.39179489]
Agent gate_2 episode reward: [-1.41393002]
All agents episode reward: [-1.41393002]
Agent gate_2 episode reward: [-1.52439915]
All agents episode reward: [-1.52439915]
Agent gate_2 episode reward: [-1.5787159]
All agents episode reward: [-1.5787159]
Agent gate_2 episode reward: [-1.625663]
All agents episode reward: [-1.625663]
Agent gate_2 episode reward: [-1.63979317]
All agents episode reward: [-1.63979317]
Agent gate_2 episode reward: [-1.69756287]
All agents episode reward: [-1.69756287]
Agent gate_2 episode reward: [-1.69176594]
All agents episode reward: [-1.69176594]
Agent gate_2 episode reward: [-1.82900688]
All agents episode reward: [-1.82900688]
Iteration 2: 100%|██████████| 10/10 [00:23<00:00,  2.30s/it, episode=30, norm_ret=-2.037, true_ret=-740451.250, steps=600]
Agent gate_2 episode reward: [-1.9128691]
All agents episode reward: [-1.9128691]
Agent gate_2 episode reward: [-1.87620821]
All agents episode reward: [-1.87620821]
Agent gate_2 episode reward: [-1.88786837]
All agents episode reward: [-1.88786837]
Agent gate_2 episode reward: [-1.96373745]
All agents episode reward: [-1.96373745]
Agent gate_2 episode reward: [-1.96369372]
All agents episode reward: [-1.96369372]
Agent gate_2 episode reward: [-2.07024286]
All agents episode reward: [-2.07024286]
Agent gate_2 episode reward: [-2.20825393]
All agents episode reward: [-2.20825393]
Agent gate_2 episode reward: [-2.09719411]
All agents episode reward: [-2.09719411]
Agent gate_2 episode reward: [-2.16902591]
All agents episode reward: [-2.16902591]
Agent gate_2 episode reward: [-2.22576197]
All agents episode reward: [-2.22576197]
Iteration 3: 100%|██████████| 10/10 [00:22<00:00,  2.27s/it, episode=40, norm_ret=-2.311, true_ret=-724586.938, steps=600]
Agent gate_2 episode reward: [-2.13942875]
All agents episode reward: [-2.13942875]
Agent gate_2 episode reward: [-2.21146573]
All agents episode reward: [-2.21146573]
Agent gate_2 episode reward: [-2.22383895]
All agents episode reward: [-2.22383895]
Agent gate_2 episode reward: [-2.2751232]
All agents episode reward: [-2.2751232]
Agent gate_2 episode reward: [-2.26171148]
All agents episode reward: [-2.26171148]
Agent gate_2 episode reward: [-2.30260968]
All agents episode reward: [-2.30260968]
Agent gate_2 episode reward: [-2.32900837]
All agents episode reward: [-2.32900837]
Agent gate_2 episode reward: [-2.39170992]
All agents episode reward: [-2.39170992]
Agent gate_2 episode reward: [-2.47541167]
All agents episode reward: [-2.47541167]
Agent gate_2 episode reward: [-2.49687797]
All agents episode reward: [-2.49687797]
Iteration 4: 100%|██████████| 10/10 [00:22<00:00,  2.24s/it, episode=50, norm_ret=-2.622, true_ret=-720055.812, steps=600]
Agent gate_2 episode reward: [-2.51633939]
All agents episode reward: [-2.51633939]
Agent gate_2 episode reward: [-2.57045719]
All agents episode reward: [-2.57045719]
Agent gate_2 episode reward: [-2.55288539]
All agents episode reward: [-2.55288539]
Agent gate_2 episode reward: [-2.57041293]
All agents episode reward: [-2.57041293]
Agent gate_2 episode reward: [-2.58250055]
All agents episode reward: [-2.58250055]
Agent gate_2 episode reward: [-2.67269919]
All agents episode reward: [-2.67269919]
Agent gate_2 episode reward: [-2.52817702]
All agents episode reward: [-2.52817702]
Agent gate_2 episode reward: [-2.69725466]
All agents episode reward: [-2.69725466]
Agent gate_2 episode reward: [-2.7729298]
All agents episode reward: [-2.7729298]
Agent gate_2 episode reward: [-2.7588493]
All agents episode reward: [-2.7588493]
Iteration 5: 100%|██████████| 10/10 [00:27<00:00,  2.78s/it, episode=60, norm_ret=-2.892, true_ret=-696100.312, steps=600]
Agent gate_2 episode reward: [-2.7367013]
All agents episode reward: [-2.7367013]
Agent gate_2 episode reward: [-2.85932422]
All agents episode reward: [-2.85932422]
Agent gate_2 episode reward: [-2.77231815]
All agents episode reward: [-2.77231815]
Agent gate_2 episode reward: [-2.87301424]
All agents episode reward: [-2.87301424]
Agent gate_2 episode reward: [-2.8961037]
All agents episode reward: [-2.8961037]
Agent gate_2 episode reward: [-2.98810858]
All agents episode reward: [-2.98810858]
Agent gate_2 episode reward: [-2.866835]
All agents episode reward: [-2.866835]
Agent gate_2 episode reward: [-2.93552851]
All agents episode reward: [-2.93552851]
Agent gate_2 episode reward: [-3.08723216]
All agents episode reward: [-3.08723216]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -840706.625 at episode 60 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-2.90778831]
All agents episode reward: [-2.90778831]
Iteration 6: 100%|██████████| 10/10 [00:26<00:00,  2.70s/it, episode=70, norm_ret=-4.958, true_ret=-1003263.250, steps=600]
Agent gate_2 episode reward: [-8.82877249]
All agents episode reward: [-8.82877249]
Agent gate_2 episode reward: [-3.70058163]
All agents episode reward: [-3.70058163]
Agent gate_2 episode reward: [-3.67149746]
All agents episode reward: [-3.67149746]
Agent gate_2 episode reward: [-3.74286494]
All agents episode reward: [-3.74286494]
Agent gate_2 episode reward: [-3.82385903]
All agents episode reward: [-3.82385903]
Agent gate_2 episode reward: [-3.96064035]
All agents episode reward: [-3.96064035]
Agent gate_2 episode reward: [-3.8509711]
All agents episode reward: [-3.8509711]
Agent gate_2 episode reward: [-4.59104169]
All agents episode reward: [-4.59104169]
Agent gate_2 episode reward: [-8.82220544]
All agents episode reward: [-8.82220544]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -705625.750 at episode 70 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-4.58363244]
All agents episode reward: [-4.58363244]
Iteration 7: 100%|██████████| 10/10 [00:27<00:00,  2.76s/it, episode=80, norm_ret=-7.868, true_ret=-883996.062, steps=600]
Agent gate_2 episode reward: [-2.74486931]
All agents episode reward: [-2.74486931]
Agent gate_2 episode reward: [-2.82682242]
All agents episode reward: [-2.82682242]
Agent gate_2 episode reward: [-2.78879359]
All agents episode reward: [-2.78879359]
Agent gate_2 episode reward: [-2.91287086]
All agents episode reward: [-2.91287086]
Agent gate_2 episode reward: [-5.35583558]
All agents episode reward: [-5.35583558]
Agent gate_2 episode reward: [-8.05005179]
All agents episode reward: [-8.05005179]
Agent gate_2 episode reward: [-18.853543]
All agents episode reward: [-18.853543]
Agent gate_2 episode reward: [-20.34073339]
All agents episode reward: [-20.34073339]
Agent gate_2 episode reward: [-10.87395899]
All agents episode reward: [-10.87395899]
Agent gate_2 episode reward: [-3.93433847]
All agents episode reward: [-3.93433847]
Iteration 8: 100%|██████████| 10/10 [00:26<00:00,  2.65s/it, episode=90, norm_ret=-2.804, true_ret=-671960.312, steps=600]
Agent gate_2 episode reward: [-2.6184766]
All agents episode reward: [-2.6184766]
Agent gate_2 episode reward: [-2.7313743]
All agents episode reward: [-2.7313743]
Agent gate_2 episode reward: [-2.7860557]
All agents episode reward: [-2.7860557]
Agent gate_2 episode reward: [-2.77063723]
All agents episode reward: [-2.77063723]
Agent gate_2 episode reward: [-2.666435]
All agents episode reward: [-2.666435]
Agent gate_2 episode reward: [-2.72562694]
All agents episode reward: [-2.72562694]
Agent gate_2 episode reward: [-2.73351854]
All agents episode reward: [-2.73351854]
Agent gate_2 episode reward: [-2.78484479]
All agents episode reward: [-2.78484479]
Agent gate_2 episode reward: [-3.0274189]
All agents episode reward: [-3.0274189]
Agent gate_2 episode reward: [-3.19355693]
All agents episode reward: [-3.19355693]
Iteration 9: 100%|██████████| 10/10 [00:26<00:00,  2.65s/it, episode=100, norm_ret=-5.298, true_ret=-966724.688, steps=600]
Agent gate_2 episode reward: [-11.70364139]
All agents episode reward: [-11.70364139]
Agent gate_2 episode reward: [-4.6895884]
All agents episode reward: [-4.6895884]
Agent gate_2 episode reward: [-5.26149346]
All agents episode reward: [-5.26149346]
Agent gate_2 episode reward: [-4.85203749]
All agents episode reward: [-4.85203749]
Agent gate_2 episode reward: [-4.85631555]
All agents episode reward: [-4.85631555]
Agent gate_2 episode reward: [-4.33908518]
All agents episode reward: [-4.33908518]
Agent gate_2 episode reward: [-4.54848955]
All agents episode reward: [-4.54848955]
Agent gate_2 episode reward: [-4.08915404]
All agents episode reward: [-4.08915404]
Agent gate_2 episode reward: [-4.05646862]
All agents episode reward: [-4.05646862]
Agent gate_2 episode reward: [-4.58024088]
All agents episode reward: [-4.58024088]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -611515.375 | Total reward: -611515.375
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -832557.500 | Total reward: -832557.500
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -859763.188 | Total reward: -859763.188
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -966232.750 | Total reward: -966232.750
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -763236.438 | Total reward: -763236.438
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -863564.625 | Total reward: -863564.625
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -918103.562 | Total reward: -918103.562
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -808719.625 | Total reward: -808719.625
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -839700.312 | Total reward: -839700.312
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -700676.938 | Total reward: -700676.938
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -816407.062 ± 97957.742
  Average reward: -816407.062 ± 97957.742
  Total reward: -816407.062 ± 97957.742
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -643709.938 | Total reward: -643709.938
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -851560.312 | Total reward: -851560.312
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -920434.188 | Total reward: -920434.188
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1048110.500 | Total reward: -1048110.500
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -791232.562 | Total reward: -791232.562
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -907931.062 | Total reward: -907931.062
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -959172.375 | Total reward: -959172.375
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -854216.688 | Total reward: -854216.688
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -870864.938 | Total reward: -870864.938
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -711501.500 | Total reward: -711501.500
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -855873.375 ± 111707.203
  Average reward: -855873.375 ± 111707.203
  Total reward: -855873.375 ± 111707.203
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -619125.000 | Total reward: -619125.000
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -806306.500 | Total reward: -806306.500
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -868706.875 | Total reward: -868706.875
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -967434.938 | Total reward: -967434.938
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -768901.188 | Total reward: -768901.188
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -867192.688 | Total reward: -867192.688
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -902276.062 | Total reward: -902276.062
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -808263.062 | Total reward: -808263.062
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -828881.250 | Total reward: -828881.250
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -714115.438 | Total reward: -714115.438
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -815120.250 ± 93512.219
  Average reward: -815120.250 ± 93512.219
  Total reward: -815120.250 ± 93512.219
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -816407.062
Rule-based avg reward: -855873.375
No control avg reward: -815120.250
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
