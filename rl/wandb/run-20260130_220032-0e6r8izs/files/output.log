Iteration 0: 100%|██████████| 15/15 [00:33<00:00,  2.22s/it, episode=10, norm_ret=-10.802, true_ret=-922205.312, steps=600]
Agent gate_2 episode reward: [-46.62472617]
All agents episode reward: [-46.62472617]
Agent gate_2 episode reward: [-8.06794831]
All agents episode reward: [-8.06794831]
Agent gate_2 episode reward: [-4.87907839]
All agents episode reward: [-4.87907839]
Agent gate_2 episode reward: [-4.41389545]
All agents episode reward: [-4.41389545]
Agent gate_2 episode reward: [-4.50535316]
All agents episode reward: [-4.50535316]
Agent gate_2 episode reward: [-5.23549501]
All agents episode reward: [-5.23549501]
Agent gate_2 episode reward: [-6.8958087]
All agents episode reward: [-6.8958087]
Agent gate_2 episode reward: [-8.32805222]
All agents episode reward: [-8.32805222]
Agent gate_2 episode reward: [-9.56930817]
All agents episode reward: [-9.56930817]
Agent gate_2 episode reward: [-9.50478001]
All agents episode reward: [-9.50478001]
Agent gate_2 episode reward: [-10.30928363]
All agents episode reward: [-10.30928363]
Agent gate_2 episode reward: [-9.72946012]
All agents episode reward: [-9.72946012]
Agent gate_2 episode reward: [-8.95941011]
All agents episode reward: [-8.95941011]
Agent gate_2 episode reward: [-8.73254694]
All agents episode reward: [-8.73254694]
Agent gate_2 episode reward: [-9.90974937]
All agents episode reward: [-9.90974937]
Iteration 1: 100%|██████████| 15/15 [00:33<00:00,  2.26s/it, episode=25, norm_ret=-9.030, true_ret=-635580.125, steps=600]
Agent gate_2 episode reward: [-9.29033035]
All agents episode reward: [-9.29033035]
Agent gate_2 episode reward: [-8.14956256]
All agents episode reward: [-8.14956256]
Agent gate_2 episode reward: [-7.40518519]
All agents episode reward: [-7.40518519]
Agent gate_2 episode reward: [-8.38990423]
All agents episode reward: [-8.38990423]
Agent gate_2 episode reward: [-11.35796563]
All agents episode reward: [-11.35796563]
Agent gate_2 episode reward: [-10.50404541]
All agents episode reward: [-10.50404541]
Agent gate_2 episode reward: [-9.25789583]
All agents episode reward: [-9.25789583]
Agent gate_2 episode reward: [-8.31080935]
All agents episode reward: [-8.31080935]
Agent gate_2 episode reward: [-8.70584799]
All agents episode reward: [-8.70584799]
Agent gate_2 episode reward: [-8.92764533]
All agents episode reward: [-8.92764533]
Agent gate_2 episode reward: [-7.79768319]
All agents episode reward: [-7.79768319]
Agent gate_2 episode reward: [-8.64184261]
All agents episode reward: [-8.64184261]
Agent gate_2 episode reward: [-9.85656505]
All agents episode reward: [-9.85656505]
Agent gate_2 episode reward: [-13.12871388]
All agents episode reward: [-13.12871388]
Agent gate_2 episode reward: [-10.83779081]
All agents episode reward: [-10.83779081]
Iteration 2: 100%|██████████| 15/15 [00:33<00:00,  2.24s/it, episode=40, norm_ret=-10.300, true_ret=-664500.875, steps=600]
Agent gate_2 episode reward: [-10.94630947]
All agents episode reward: [-10.94630947]
Agent gate_2 episode reward: [-11.47709631]
All agents episode reward: [-11.47709631]
Agent gate_2 episode reward: [-12.67510246]
All agents episode reward: [-12.67510246]
Agent gate_2 episode reward: [-13.82281203]
All agents episode reward: [-13.82281203]
Agent gate_2 episode reward: [-7.79542187]
All agents episode reward: [-7.79542187]
Agent gate_2 episode reward: [-8.90437257]
All agents episode reward: [-8.90437257]
Agent gate_2 episode reward: [-9.42701293]
All agents episode reward: [-9.42701293]
Agent gate_2 episode reward: [-8.86972741]
All agents episode reward: [-8.86972741]
Agent gate_2 episode reward: [-8.38912616]
All agents episode reward: [-8.38912616]
Agent gate_2 episode reward: [-10.69040783]
All agents episode reward: [-10.69040783]
Agent gate_2 episode reward: [-9.58909796]
All agents episode reward: [-9.58909796]
Agent gate_2 episode reward: [-10.69293283]
All agents episode reward: [-10.69293283]
Agent gate_2 episode reward: [-9.3782509]
All agents episode reward: [-9.3782509]
Agent gate_2 episode reward: [-9.44056174]
All agents episode reward: [-9.44056174]
Agent gate_2 episode reward: [-14.66321982]
All agents episode reward: [-14.66321982]
Iteration 3: 100%|██████████| 15/15 [00:32<00:00,  2.20s/it, episode=55, norm_ret=-11.805, true_ret=-846012.500, steps=600]
Agent gate_2 episode reward: [-13.54305689]
All agents episode reward: [-13.54305689]
Agent gate_2 episode reward: [-11.85545941]
All agents episode reward: [-11.85545941]
Agent gate_2 episode reward: [-9.38374771]
All agents episode reward: [-9.38374771]
Agent gate_2 episode reward: [-10.88984022]
All agents episode reward: [-10.88984022]
Agent gate_2 episode reward: [-11.36398195]
All agents episode reward: [-11.36398195]
Agent gate_2 episode reward: [-8.79984543]
All agents episode reward: [-8.79984543]
Agent gate_2 episode reward: [-9.78932298]
All agents episode reward: [-9.78932298]
Agent gate_2 episode reward: [-11.56191438]
All agents episode reward: [-11.56191438]
Agent gate_2 episode reward: [-16.08946411]
All agents episode reward: [-16.08946411]
Agent gate_2 episode reward: [-14.77279829]
All agents episode reward: [-14.77279829]
Agent gate_2 episode reward: [-15.11655215]
All agents episode reward: [-15.11655215]
Agent gate_2 episode reward: [-11.98681263]
All agents episode reward: [-11.98681263]
Agent gate_2 episode reward: [-13.29487366]
All agents episode reward: [-13.29487366]
Agent gate_2 episode reward: [-14.54266475]
All agents episode reward: [-14.54266475]
Agent gate_2 episode reward: [-14.43462922]
All agents episode reward: [-14.43462922]
Iteration 4: 100%|██████████| 15/15 [00:33<00:00,  2.25s/it, episode=70, norm_ret=-12.511, true_ret=-573093.562, steps=600]
Agent gate_2 episode reward: [-12.04848183]
All agents episode reward: [-12.04848183]
Agent gate_2 episode reward: [-11.75722916]
All agents episode reward: [-11.75722916]
Agent gate_2 episode reward: [-13.91847524]
All agents episode reward: [-13.91847524]
Agent gate_2 episode reward: [-14.56375115]
All agents episode reward: [-14.56375115]
Agent gate_2 episode reward: [-12.4156236]
All agents episode reward: [-12.4156236]
Agent gate_2 episode reward: [-12.36827051]
All agents episode reward: [-12.36827051]
Agent gate_2 episode reward: [-12.42649739]
All agents episode reward: [-12.42649739]
Agent gate_2 episode reward: [-14.34468676]
All agents episode reward: [-14.34468676]
Agent gate_2 episode reward: [-10.75966302]
All agents episode reward: [-10.75966302]
Agent gate_2 episode reward: [-10.50258944]
All agents episode reward: [-10.50258944]
Agent gate_2 episode reward: [-12.22634595]
All agents episode reward: [-12.22634595]
Agent gate_2 episode reward: [-15.73184187]
All agents episode reward: [-15.73184187]
Agent gate_2 episode reward: [-11.6953507]
All agents episode reward: [-11.6953507]
Agent gate_2 episode reward: [-10.40324488]
All agents episode reward: [-10.40324488]
Agent gate_2 episode reward: [-11.07379334]
All agents episode reward: [-11.07379334]
Iteration 5: 100%|██████████| 15/15 [00:40<00:00,  3.39s/it, episode=85, norm_ret=-12.048, true_ret=-724011.938, steps=600]
Agent gate_2 episode reward: [-13.2513371]
All agents episode reward: [-13.2513371]
Agent gate_2 episode reward: [-10.6095551]
All agents episode reward: [-10.6095551]
Agent gate_2 episode reward: [-10.56929328]
All agents episode reward: [-10.56929328]
Agent gate_2 episode reward: [-11.21212839]
All agents episode reward: [-11.21212839]
Saved 1 agents to ppo_agents_butterfly_scB
[Validation] New best avg return: -714318.188 at episode 80 (over 5 val episodes, saved to ppo_agents_butterfly_scB)
Agent gate_2 episode reward: [-11.94827418]
All agents episode reward: [-11.94827418]
Agent gate_2 episode reward: [-10.67724046]
All agents episode reward: [-10.67724046]
Agent gate_2 episode reward: [-10.76612361]
All agents episode reward: [-10.76612361]
Agent gate_2 episode reward: [-12.92266676]
All agents episode reward: [-12.92266676]
Agent gate_2 episode reward: [-14.35474385]
All agents episode reward: [-14.35474385]
Agent gate_2 episode reward: [-14.1703559]
All agents episode reward: [-14.1703559]
Agent gate_2 episode reward: [-13.55812903]
All agents episode reward: [-13.55812903]
Agent gate_2 episode reward: [-13.99203036]
All agents episode reward: [-13.99203036]
Agent gate_2 episode reward: [-15.70761036]
All agents episode reward: [-15.70761036]
Agent gate_2 episode reward: [-12.21875475]
All agents episode reward: [-12.21875475]
Agent gate_2 episode reward: [-11.33703502]
All agents episode reward: [-11.33703502]
Iteration 6: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, episode=100, norm_ret=-12.818, true_ret=-745572.188, steps=600]
Agent gate_2 episode reward: [-11.91044789]
All agents episode reward: [-11.91044789]
Agent gate_2 episode reward: [-10.85446953]
All agents episode reward: [-10.85446953]
Agent gate_2 episode reward: [-11.27308553]
All agents episode reward: [-11.27308553]
Agent gate_2 episode reward: [-10.95235907]
All agents episode reward: [-10.95235907]
Agent gate_2 episode reward: [-11.71173953]
All agents episode reward: [-11.71173953]
Agent gate_2 episode reward: [-10.51213553]
All agents episode reward: [-10.51213553]
Agent gate_2 episode reward: [-12.36306817]
All agents episode reward: [-12.36306817]
Agent gate_2 episode reward: [-16.1967427]
All agents episode reward: [-16.1967427]
Agent gate_2 episode reward: [-17.41241819]
All agents episode reward: [-17.41241819]
Agent gate_2 episode reward: [-14.99794847]
All agents episode reward: [-14.99794847]
Agent gate_2 episode reward: [-12.11503818]
All agents episode reward: [-12.11503818]
Agent gate_2 episode reward: [-11.89950466]
All agents episode reward: [-11.89950466]
Agent gate_2 episode reward: [-11.87086301]
All agents episode reward: [-11.87086301]
Agent gate_2 episode reward: [-12.39480327]
All agents episode reward: [-12.39480327]
Agent gate_2 episode reward: [-12.09476297]
All agents episode reward: [-12.09476297]
Iteration 7: 100%|██████████| 15/15 [00:40<00:00,  2.68s/it, episode=115, norm_ret=-11.975, true_ret=-609009.688, steps=600]
Agent gate_2 episode reward: [-10.97821806]
All agents episode reward: [-10.97821806]
Agent gate_2 episode reward: [-11.510535]
All agents episode reward: [-11.510535]
Agent gate_2 episode reward: [-12.10705052]
All agents episode reward: [-12.10705052]
Agent gate_2 episode reward: [-13.4390833]
All agents episode reward: [-13.4390833]
Agent gate_2 episode reward: [-11.82430839]
All agents episode reward: [-11.82430839]
Agent gate_2 episode reward: [-11.43958735]
All agents episode reward: [-11.43958735]
Agent gate_2 episode reward: [-12.10774757]
All agents episode reward: [-12.10774757]
Agent gate_2 episode reward: [-11.76271981]
All agents episode reward: [-11.76271981]
Agent gate_2 episode reward: [-11.73099552]
All agents episode reward: [-11.73099552]
Agent gate_2 episode reward: [-12.8533687]
All agents episode reward: [-12.8533687]
Agent gate_2 episode reward: [-12.40440051]
All agents episode reward: [-12.40440051]
Agent gate_2 episode reward: [-12.1794425]
All agents episode reward: [-12.1794425]
Agent gate_2 episode reward: [-11.65382146]
All agents episode reward: [-11.65382146]
Agent gate_2 episode reward: [-14.48494069]
All agents episode reward: [-14.48494069]
Agent gate_2 episode reward: [-12.21084644]
All agents episode reward: [-12.21084644]
Iteration 8: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, episode=130, norm_ret=-11.114, true_ret=-585253.562, steps=600]
Agent gate_2 episode reward: [-11.85058551]
All agents episode reward: [-11.85058551]
Agent gate_2 episode reward: [-12.02010551]
All agents episode reward: [-12.02010551]
Agent gate_2 episode reward: [-11.22599323]
All agents episode reward: [-11.22599323]
Agent gate_2 episode reward: [-10.72221662]
All agents episode reward: [-10.72221662]
Agent gate_2 episode reward: [-11.98815604]
All agents episode reward: [-11.98815604]
Agent gate_2 episode reward: [-10.6679626]
All agents episode reward: [-10.6679626]
Agent gate_2 episode reward: [-10.76827071]
All agents episode reward: [-10.76827071]
Agent gate_2 episode reward: [-10.21282347]
All agents episode reward: [-10.21282347]
Agent gate_2 episode reward: [-10.48240826]
All agents episode reward: [-10.48240826]
Agent gate_2 episode reward: [-11.20448441]
All agents episode reward: [-11.20448441]
Agent gate_2 episode reward: [-10.89195087]
All agents episode reward: [-10.89195087]
Agent gate_2 episode reward: [-10.5504143]
All agents episode reward: [-10.5504143]
Agent gate_2 episode reward: [-11.8414434]
All agents episode reward: [-11.8414434]
Agent gate_2 episode reward: [-11.40594955]
All agents episode reward: [-11.40594955]
Agent gate_2 episode reward: [-10.22804899]
All agents episode reward: [-10.22804899]
Iteration 9: 100%|██████████| 15/15 [00:39<00:00,  2.63s/it, episode=145, norm_ret=-10.916, true_ret=-535276.125, steps=600]
Agent gate_2 episode reward: [-11.19077433]
All agents episode reward: [-11.19077433]
Agent gate_2 episode reward: [-10.83372932]
All agents episode reward: [-10.83372932]
Agent gate_2 episode reward: [-11.48426993]
All agents episode reward: [-11.48426993]
Agent gate_2 episode reward: [-10.52237521]
All agents episode reward: [-10.52237521]
Agent gate_2 episode reward: [-10.93802753]
All agents episode reward: [-10.93802753]
Agent gate_2 episode reward: [-10.55314867]
All agents episode reward: [-10.55314867]
Agent gate_2 episode reward: [-10.16229386]
All agents episode reward: [-10.16229386]
Agent gate_2 episode reward: [-11.76275002]
All agents episode reward: [-11.76275002]
Agent gate_2 episode reward: [-11.28325022]
All agents episode reward: [-11.28325022]
Agent gate_2 episode reward: [-10.43030965]
All agents episode reward: [-10.43030965]
Agent gate_2 episode reward: [-11.69365555]
All agents episode reward: [-11.69365555]
Agent gate_2 episode reward: [-11.14570539]
All agents episode reward: [-11.14570539]
Agent gate_2 episode reward: [-10.31041011]
All agents episode reward: [-10.31041011]
Agent gate_2 episode reward: [-10.69980724]
All agents episode reward: [-10.69980724]
Agent gate_2 episode reward: [-10.86329163]
All agents episode reward: [-10.86329163]
Loaded 1 agents from ppo_agents_butterfly_scB
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -591955.188 | Total reward: -591955.188
Saved run 1 to rl_training/butterfly_scB/ppo_run1
  Run 2/10... Avg agent reward (episode): -618999.312 | Total reward: -618999.312
Saved run 2 to rl_training/butterfly_scB/ppo_run2
  Run 3/10... Avg agent reward (episode): -710052.562 | Total reward: -710052.562
Saved run 3 to rl_training/butterfly_scB/ppo_run3
  Run 4/10... Avg agent reward (episode): -658102.062 | Total reward: -658102.062
Saved run 4 to rl_training/butterfly_scB/ppo_run4
  Run 5/10... Avg agent reward (episode): -742367.000 | Total reward: -742367.000
Saved run 5 to rl_training/butterfly_scB/ppo_run5
  Run 6/10... Avg agent reward (episode): -716146.250 | Total reward: -716146.250
Saved run 6 to rl_training/butterfly_scB/ppo_run6
  Run 7/10... Avg agent reward (episode): -734992.312 | Total reward: -734992.312
Saved run 7 to rl_training/butterfly_scB/ppo_run7
  Run 8/10... Avg agent reward (episode): -749369.500 | Total reward: -749369.500
Saved run 8 to rl_training/butterfly_scB/ppo_run8
  Run 9/10... Avg agent reward (episode): -713236.562 | Total reward: -713236.562
Saved run 9 to rl_training/butterfly_scB/ppo_run9
  Run 10/10... Avg agent reward (episode): -736079.875 | Total reward: -736079.875
Saved run 10 to rl_training/butterfly_scB/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -697130.062 ± 52156.836
  Average reward: -697130.062 ± 52156.836
  Total reward: -697130.062 ± 52156.836
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -1009728.375 | Total reward: -1009728.375
Saved run 1 to rl_training/butterfly_scB/rule_based_run1
  Run 2/10... Avg agent reward (episode): -581025.625 | Total reward: -581025.625
Saved run 2 to rl_training/butterfly_scB/rule_based_run2
  Run 3/10... Avg agent reward (episode): -606126.875 | Total reward: -606126.875
Saved run 3 to rl_training/butterfly_scB/rule_based_run3
  Run 4/10... Avg agent reward (episode): -590441.875 | Total reward: -590441.875
Saved run 4 to rl_training/butterfly_scB/rule_based_run4
  Run 5/10... Avg agent reward (episode): -635100.750 | Total reward: -635100.750
Saved run 5 to rl_training/butterfly_scB/rule_based_run5
  Run 6/10... Avg agent reward (episode): -1034824.812 | Total reward: -1034824.812
Saved run 6 to rl_training/butterfly_scB/rule_based_run6
  Run 7/10... Avg agent reward (episode): -610005.688 | Total reward: -610005.688
Saved run 7 to rl_training/butterfly_scB/rule_based_run7
  Run 8/10... Avg agent reward (episode): -1242870.500 | Total reward: -1242870.500
Saved run 8 to rl_training/butterfly_scB/rule_based_run8
  Run 9/10... Avg agent reward (episode): -1039737.562 | Total reward: -1039737.562
Saved run 9 to rl_training/butterfly_scB/rule_based_run9
  Run 10/10... Avg agent reward (episode): -618528.438 | Total reward: -618528.438
Saved run 10 to rl_training/butterfly_scB/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -796839.062 ± 240480.734
  Average reward: -796839.062 ± 240480.734
  Total reward: -796839.062 ± 240480.734
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -756539.750 | Total reward: -756539.750
Saved run 1 to rl_training/butterfly_scB/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -969458.938 | Total reward: -969458.938
Saved run 2 to rl_training/butterfly_scB/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -1051892.500 | Total reward: -1051892.500
Saved run 3 to rl_training/butterfly_scB/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -970126.438 | Total reward: -970126.438
Saved run 4 to rl_training/butterfly_scB/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -1049075.500 | Total reward: -1049075.500
Saved run 5 to rl_training/butterfly_scB/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -1048883.500 | Total reward: -1048883.500
Saved run 6 to rl_training/butterfly_scB/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -1055748.000 | Total reward: -1055748.000
Saved run 7 to rl_training/butterfly_scB/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -1040111.750 | Total reward: -1040111.750
Saved run 8 to rl_training/butterfly_scB/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -1044339.750 | Total reward: -1044339.750
Saved run 9 to rl_training/butterfly_scB/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -1057111.625 | Total reward: -1057111.625
Saved run 10 to rl_training/butterfly_scB/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -1004328.812 ± 88513.320
  Average reward: -1004328.812 ± 88513.320
  Total reward: -1004328.812 ± 88513.320
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -697130.062
Rule-based avg reward: -796839.062
No control avg reward: -1004328.812
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
