Iteration 0: 100%|██████████| 15/15 [00:35<00:00,  2.39s/it, episode=10, norm_ret=-7.778, true_ret=-732291.625, steps=600]
Agent gate_2 episode reward: [-56.79236452]
All agents episode reward: [-56.79236452]
Agent gate_2 episode reward: [-11.13763739]
All agents episode reward: [-11.13763739]
Agent gate_2 episode reward: [-1.09495178]
All agents episode reward: [-1.09495178]
Agent gate_2 episode reward: [-0.91889651]
All agents episode reward: [-0.91889651]
Agent gate_2 episode reward: [-1.54094238]
All agents episode reward: [-1.54094238]
Agent gate_2 episode reward: [-1.18047241]
All agents episode reward: [-1.18047241]
Agent gate_2 episode reward: [-1.2133889]
All agents episode reward: [-1.2133889]
Agent gate_2 episode reward: [-1.23450259]
All agents episode reward: [-1.23450259]
Agent gate_2 episode reward: [-1.31112189]
All agents episode reward: [-1.31112189]
Agent gate_2 episode reward: [-1.35759398]
All agents episode reward: [-1.35759398]
Agent gate_2 episode reward: [-1.46247782]
All agents episode reward: [-1.46247782]
Agent gate_2 episode reward: [-1.47841687]
All agents episode reward: [-1.47841687]
Agent gate_2 episode reward: [-1.52604784]
All agents episode reward: [-1.52604784]
Agent gate_2 episode reward: [-1.53918304]
All agents episode reward: [-1.53918304]
Agent gate_2 episode reward: [-1.66160709]
All agents episode reward: [-1.66160709]
Iteration 1: 100%|██████████| 15/15 [00:34<00:00,  2.29s/it, episode=25, norm_ret=-1.916, true_ret=-731980.750, steps=600]
Agent gate_2 episode reward: [-1.70896989]
All agents episode reward: [-1.70896989]
Agent gate_2 episode reward: [-1.85157546]
All agents episode reward: [-1.85157546]
Agent gate_2 episode reward: [-1.75292807]
All agents episode reward: [-1.75292807]
Agent gate_2 episode reward: [-1.79959079]
All agents episode reward: [-1.79959079]
Agent gate_2 episode reward: [-1.91494935]
All agents episode reward: [-1.91494935]
Agent gate_2 episode reward: [-2.03666224]
All agents episode reward: [-2.03666224]
Agent gate_2 episode reward: [-1.92337336]
All agents episode reward: [-1.92337336]
Agent gate_2 episode reward: [-2.00204464]
All agents episode reward: [-2.00204464]
Agent gate_2 episode reward: [-2.09936984]
All agents episode reward: [-2.09936984]
Agent gate_2 episode reward: [-2.07403472]
All agents episode reward: [-2.07403472]
Agent gate_2 episode reward: [-2.12003776]
All agents episode reward: [-2.12003776]
Agent gate_2 episode reward: [-2.23983255]
All agents episode reward: [-2.23983255]
Agent gate_2 episode reward: [-2.23902256]
All agents episode reward: [-2.23902256]
Agent gate_2 episode reward: [-2.27276928]
All agents episode reward: [-2.27276928]
Agent gate_2 episode reward: [-2.25961486]
All agents episode reward: [-2.25961486]
Iteration 2: 100%|██████████| 15/15 [00:34<00:00,  2.30s/it, episode=40, norm_ret=-2.786, true_ret=-885189.812, steps=600]
Agent gate_2 episode reward: [-2.28919553]
All agents episode reward: [-2.28919553]
Agent gate_2 episode reward: [-2.32726726]
All agents episode reward: [-2.32726726]
Agent gate_2 episode reward: [-2.27922677]
All agents episode reward: [-2.27922677]
Agent gate_2 episode reward: [-2.34148175]
All agents episode reward: [-2.34148175]
Agent gate_2 episode reward: [-2.38810478]
All agents episode reward: [-2.38810478]
Agent gate_2 episode reward: [-2.46810614]
All agents episode reward: [-2.46810614]
Agent gate_2 episode reward: [-4.77750751]
All agents episode reward: [-4.77750751]
Agent gate_2 episode reward: [-3.05954366]
All agents episode reward: [-3.05954366]
Agent gate_2 episode reward: [-2.80148075]
All agents episode reward: [-2.80148075]
Agent gate_2 episode reward: [-3.12607301]
All agents episode reward: [-3.12607301]
Agent gate_2 episode reward: [-2.52009398]
All agents episode reward: [-2.52009398]
Agent gate_2 episode reward: [-2.75456809]
All agents episode reward: [-2.75456809]
Agent gate_2 episode reward: [-3.07454733]
All agents episode reward: [-3.07454733]
Agent gate_2 episode reward: [-4.49686578]
All agents episode reward: [-4.49686578]
Agent gate_2 episode reward: [-2.84817812]
All agents episode reward: [-2.84817812]
Iteration 3: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it, episode=55, norm_ret=-3.942, true_ret=-733754.125, steps=600]
Agent gate_2 episode reward: [-2.82006846]
All agents episode reward: [-2.82006846]
Agent gate_2 episode reward: [-6.33265453]
All agents episode reward: [-6.33265453]
Agent gate_2 episode reward: [-2.89992993]
All agents episode reward: [-2.89992993]
Agent gate_2 episode reward: [-3.07308014]
All agents episode reward: [-3.07308014]
Agent gate_2 episode reward: [-10.11393214]
All agents episode reward: [-10.11393214]
Agent gate_2 episode reward: [-2.71571308]
All agents episode reward: [-2.71571308]
Agent gate_2 episode reward: [-3.03871545]
All agents episode reward: [-3.03871545]
Agent gate_2 episode reward: [-2.70208055]
All agents episode reward: [-2.70208055]
Agent gate_2 episode reward: [-2.81471806]
All agents episode reward: [-2.81471806]
Agent gate_2 episode reward: [-2.91387428]
All agents episode reward: [-2.91387428]
Agent gate_2 episode reward: [-2.90539523]
All agents episode reward: [-2.90539523]
Agent gate_2 episode reward: [-2.79694463]
All agents episode reward: [-2.79694463]
Agent gate_2 episode reward: [-2.86916018]
All agents episode reward: [-2.86916018]
Agent gate_2 episode reward: [-2.9655857]
All agents episode reward: [-2.9655857]
Agent gate_2 episode reward: [-2.91675713]
All agents episode reward: [-2.91675713]
Iteration 4: 100%|██████████| 15/15 [00:34<00:00,  2.27s/it, episode=70, norm_ret=-3.234, true_ret=-816257.938, steps=600]
Agent gate_2 episode reward: [-3.07785472]
All agents episode reward: [-3.07785472]
Agent gate_2 episode reward: [-3.09920028]
All agents episode reward: [-3.09920028]
Agent gate_2 episode reward: [-2.90146001]
All agents episode reward: [-2.90146001]
Agent gate_2 episode reward: [-3.18804122]
All agents episode reward: [-3.18804122]
Agent gate_2 episode reward: [-3.39346486]
All agents episode reward: [-3.39346486]
Agent gate_2 episode reward: [-3.1565289]
All agents episode reward: [-3.1565289]
Agent gate_2 episode reward: [-3.12418238]
All agents episode reward: [-3.12418238]
Agent gate_2 episode reward: [-3.17272225]
All agents episode reward: [-3.17272225]
Agent gate_2 episode reward: [-3.59321872]
All agents episode reward: [-3.59321872]
Agent gate_2 episode reward: [-3.6304237]
All agents episode reward: [-3.6304237]
Agent gate_2 episode reward: [-3.19974159]
All agents episode reward: [-3.19974159]
Agent gate_2 episode reward: [-3.33665861]
All agents episode reward: [-3.33665861]
Agent gate_2 episode reward: [-3.64805204]
All agents episode reward: [-3.64805204]
Agent gate_2 episode reward: [-3.84788622]
All agents episode reward: [-3.84788622]
Agent gate_2 episode reward: [-4.39160701]
All agents episode reward: [-4.39160701]
Iteration 5:  93%|█████████▎| 14/15 [00:36<00:02,  2.34s/it, episode=85, norm_ret=-5.739, true_ret=-819538.188, steps=600]
Agent gate_2 episode reward: [-4.0195022]
All agents episode reward: [-4.0195022]
Agent gate_2 episode reward: [-9.20607295]
All agents episode reward: [-9.20607295]
Agent gate_2 episode reward: [-8.31684509]
All agents episode reward: [-8.31684509]
Agent gate_2 episode reward: [-7.06555074]
All agents episode reward: [-7.06555074]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -2831556.750 at episode 80 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-5.40575835]
All agents episode reward: [-5.40575835]
Agent gate_2 episode reward: [-5.05121008]
All agents episode reward: [-5.05121008]
Agent gate_2 episode reward: [-6.4855471]
All agents episode reward: [-6.4855471]
Agent gate_2 episode reward: [-3.19709281]
All agents episode reward: [-3.19709281]
Agent gate_2 episode reward: [-4.99210069]
All agents episode reward: [-4.99210069]
Agent gate_2 episode reward: [-3.65288763]
All agents episode reward: [-3.65288763]
Agent gate_2 episode reward: [-5.07917694]
All agents episode reward: [-5.07917694]
Agent gate_2 episode reward: [-4.61590658]
All agents episode reward: [-4.61590658]
Agent gate_2 episode reward: [-3.2782451]
All agents episode reward: [-3.2782451]
Agent gate_2 episode reward: [-5.08200006]
All agents episode reward: [-5.08200006]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -1604004.875 at episode 90 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-3.48076542]
All agents episode reward: [-3.48076542]
Iteration 6: 100%|██████████| 15/15 [00:38<00:00,  2.45s/it, episode=100, norm_ret=-6.853, true_ret=-1300675.875, steps=600]
Agent gate_2 episode reward: [-6.24665441]
All agents episode reward: [-6.24665441]
Agent gate_2 episode reward: [-5.66455747]
All agents episode reward: [-5.66455747]
Agent gate_2 episode reward: [-8.32980818]
All agents episode reward: [-8.32980818]
Agent gate_2 episode reward: [-6.46847617]
All agents episode reward: [-6.46847617]
Agent gate_2 episode reward: [-7.09539007]
All agents episode reward: [-7.09539007]
Agent gate_2 episode reward: [-4.94024866]
All agents episode reward: [-4.94024866]
Agent gate_2 episode reward: [-11.22300413]
All agents episode reward: [-11.22300413]
Agent gate_2 episode reward: [-6.21715923]
All agents episode reward: [-6.21715923]
Agent gate_2 episode reward: [-6.1706531]
All agents episode reward: [-6.1706531]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -1168540.250 at episode 100 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-6.17204674]
All agents episode reward: [-6.17204674]
Agent gate_2 episode reward: [-1.80573201]
All agents episode reward: [-1.80573201]
Agent gate_2 episode reward: [-1.82291033]
All agents episode reward: [-1.82291033]
Agent gate_2 episode reward: [-1.8298801]
All agents episode reward: [-1.8298801]
Agent gate_2 episode reward: [-1.83645562]
All agents episode reward: [-1.83645562]
Agent gate_2 episode reward: [-1.84688662]
All agents episode reward: [-1.84688662]
Iteration 7: 100%|██████████| 15/15 [00:42<00:00,  3.44s/it, episode=115, norm_ret=-7.330, true_ret=-2312001.000, steps=600]
Agent gate_2 episode reward: [-1.86753858]
All agents episode reward: [-1.86753858]
Agent gate_2 episode reward: [-1.83488857]
All agents episode reward: [-1.83488857]
Agent gate_2 episode reward: [-1.87586608]
All agents episode reward: [-1.87586608]
Agent gate_2 episode reward: [-1.98517268]
All agents episode reward: [-1.98517268]
Agent gate_2 episode reward: [-1.94174678]
All agents episode reward: [-1.94174678]
Agent gate_2 episode reward: [-13.94633067]
All agents episode reward: [-13.94633067]
Agent gate_2 episode reward: [-14.85060459]
All agents episode reward: [-14.85060459]
Agent gate_2 episode reward: [-12.59692815]
All agents episode reward: [-12.59692815]
Agent gate_2 episode reward: [-11.33769085]
All agents episode reward: [-11.33769085]
Agent gate_2 episode reward: [-11.06170601]
All agents episode reward: [-11.06170601]
Agent gate_2 episode reward: [-17.84533604]
All agents episode reward: [-17.84533604]
Agent gate_2 episode reward: [-13.17904339]
All agents episode reward: [-13.17904339]
Agent gate_2 episode reward: [-9.73637742]
All agents episode reward: [-9.73637742]
Agent gate_2 episode reward: [-7.11494268]
All agents episode reward: [-7.11494268]
Saved 1 agents to ppo_agents_butterfly_scC
[Validation] New best avg return: -1003093.375 at episode 120 (over 5 val episodes, saved to ppo_agents_butterfly_scC)
Agent gate_2 episode reward: [-9.43833695]
All agents episode reward: [-9.43833695]
Iteration 8: 100%|██████████| 15/15 [00:38<00:00,  2.59s/it, episode=130, norm_ret=-1.947, true_ret=-512318.406, steps=600]
Agent gate_2 episode reward: [-1.79376958]
All agents episode reward: [-1.79376958]
Agent gate_2 episode reward: [-1.76259996]
All agents episode reward: [-1.76259996]
Agent gate_2 episode reward: [-1.73506482]
All agents episode reward: [-1.73506482]
Agent gate_2 episode reward: [-1.78177852]
All agents episode reward: [-1.78177852]
Agent gate_2 episode reward: [-1.90110672]
All agents episode reward: [-1.90110672]
Agent gate_2 episode reward: [-1.80274937]
All agents episode reward: [-1.80274937]
Agent gate_2 episode reward: [-1.81596845]
All agents episode reward: [-1.81596845]
Agent gate_2 episode reward: [-2.1983908]
All agents episode reward: [-2.1983908]
Agent gate_2 episode reward: [-2.18264341]
All agents episode reward: [-2.18264341]
Agent gate_2 episode reward: [-2.49716906]
All agents episode reward: [-2.49716906]
Agent gate_2 episode reward: [-5.89659982]
All agents episode reward: [-5.89659982]
Agent gate_2 episode reward: [-7.53720385]
All agents episode reward: [-7.53720385]
Agent gate_2 episode reward: [-6.50288045]
All agents episode reward: [-6.50288045]
Agent gate_2 episode reward: [-4.36568313]
All agents episode reward: [-4.36568313]
Agent gate_2 episode reward: [-4.86501262]
All agents episode reward: [-4.86501262]
Iteration 9: 100%|██████████| 15/15 [00:43<00:00,  2.87s/it, episode=145, norm_ret=-5.403, true_ret=-1048353.875, steps=600]
Agent gate_2 episode reward: [-6.2472609]
All agents episode reward: [-6.2472609]
Agent gate_2 episode reward: [-5.98165743]
All agents episode reward: [-5.98165743]
Agent gate_2 episode reward: [-5.39523513]
All agents episode reward: [-5.39523513]
Agent gate_2 episode reward: [-5.67259525]
All agents episode reward: [-5.67259525]
Agent gate_2 episode reward: [-5.50872656]
All agents episode reward: [-5.50872656]
Agent gate_2 episode reward: [-4.88910471]
All agents episode reward: [-4.88910471]
Agent gate_2 episode reward: [-4.73144557]
All agents episode reward: [-4.73144557]
Agent gate_2 episode reward: [-4.57968256]
All agents episode reward: [-4.57968256]
Agent gate_2 episode reward: [-5.6184991]
All agents episode reward: [-5.6184991]
Agent gate_2 episode reward: [-5.40294638]
All agents episode reward: [-5.40294638]
Agent gate_2 episode reward: [-5.10218704]
All agents episode reward: [-5.10218704]
Agent gate_2 episode reward: [-4.87187681]
All agents episode reward: [-4.87187681]
Agent gate_2 episode reward: [-4.85077996]
All agents episode reward: [-4.85077996]
Agent gate_2 episode reward: [-5.00296513]
All agents episode reward: [-5.00296513]
Agent gate_2 episode reward: [-5.42668111]
All agents episode reward: [-5.42668111]
Loaded 1 agents from ppo_agents_butterfly_scC
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -682365.250 | Total reward: -682365.250
Saved run 1 to rl_training/butterfly_scC/ppo_run1
  Run 2/10... Avg agent reward (episode): -898589.125 | Total reward: -898589.125
Saved run 2 to rl_training/butterfly_scC/ppo_run2
  Run 3/10... Avg agent reward (episode): -1304036.375 | Total reward: -1304036.375
Saved run 3 to rl_training/butterfly_scC/ppo_run3
  Run 4/10... Avg agent reward (episode): -1452908.625 | Total reward: -1452908.625
Saved run 4 to rl_training/butterfly_scC/ppo_run4
  Run 5/10... Avg agent reward (episode): -1064382.625 | Total reward: -1064382.625
Saved run 5 to rl_training/butterfly_scC/ppo_run5
  Run 6/10... Avg agent reward (episode): -1142085.125 | Total reward: -1142085.125
Saved run 6 to rl_training/butterfly_scC/ppo_run6
  Run 7/10... Avg agent reward (episode): -1548387.000 | Total reward: -1548387.000
Saved run 7 to rl_training/butterfly_scC/ppo_run7
  Run 8/10... Avg agent reward (episode): -1169073.250 | Total reward: -1169073.250
Saved run 8 to rl_training/butterfly_scC/ppo_run8
  Run 9/10... Avg agent reward (episode): -1018413.688 | Total reward: -1018413.688
Saved run 9 to rl_training/butterfly_scC/ppo_run9
  Run 10/10... Avg agent reward (episode): -751899.625 | Total reward: -751899.625
Saved run 10 to rl_training/butterfly_scC/ppo_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -1103214.250 ± 267908.406
  Average reward: -1103214.250 ± 267908.406
  Total reward: -1103214.250 ± 267908.406
============================================================
Running 10 evaluation runs...
  Run 1/10... Avg agent reward (episode): -651404.562 | Total reward: -651404.562
Saved run 1 to rl_training/butterfly_scC/rule_based_run1
  Run 2/10... Avg agent reward (episode): -861129.875 | Total reward: -861129.875
Saved run 2 to rl_training/butterfly_scC/rule_based_run2
  Run 3/10... Avg agent reward (episode): -930033.312 | Total reward: -930033.312
Saved run 3 to rl_training/butterfly_scC/rule_based_run3
  Run 4/10... Avg agent reward (episode): -1058483.625 | Total reward: -1058483.625
Saved run 4 to rl_training/butterfly_scC/rule_based_run4
  Run 5/10... Avg agent reward (episode): -799844.375 | Total reward: -799844.375
Saved run 5 to rl_training/butterfly_scC/rule_based_run5
  Run 6/10... Avg agent reward (episode): -917745.062 | Total reward: -917745.062
Saved run 6 to rl_training/butterfly_scC/rule_based_run6
  Run 7/10... Avg agent reward (episode): -969063.438 | Total reward: -969063.438
Saved run 7 to rl_training/butterfly_scC/rule_based_run7
  Run 8/10... Avg agent reward (episode): -863329.250 | Total reward: -863329.250
Saved run 8 to rl_training/butterfly_scC/rule_based_run8
  Run 9/10... Avg agent reward (episode): -880622.750 | Total reward: -880622.750
Saved run 9 to rl_training/butterfly_scC/rule_based_run9
  Run 10/10... Avg agent reward (episode): -720244.438 | Total reward: -720244.438
Saved run 10 to rl_training/butterfly_scC/rule_based_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -865190.125 ± 112410.141
  Average reward: -865190.125 ± 112410.141
  Total reward: -865190.125 ± 112410.141
============================================================
Running 10 evaluation runs...
  Run 1/10... No actions provided, skipping action application.
Avg agent reward (episode): -626372.125 | Total reward: -626372.125
Saved run 1 to rl_training/butterfly_scC/no_control_run1
  Run 2/10... No actions provided, skipping action application.
Avg agent reward (episode): -815678.250 | Total reward: -815678.250
Saved run 2 to rl_training/butterfly_scC/no_control_run2
  Run 3/10... No actions provided, skipping action application.
Avg agent reward (episode): -877883.938 | Total reward: -877883.938
Saved run 3 to rl_training/butterfly_scC/no_control_run3
  Run 4/10... No actions provided, skipping action application.
Avg agent reward (episode): -977291.562 | Total reward: -977291.562
Saved run 4 to rl_training/butterfly_scC/no_control_run4
  Run 5/10... No actions provided, skipping action application.
Avg agent reward (episode): -777219.875 | Total reward: -777219.875
Saved run 5 to rl_training/butterfly_scC/no_control_run5
  Run 6/10... No actions provided, skipping action application.
Avg agent reward (episode): -876539.812 | Total reward: -876539.812
Saved run 6 to rl_training/butterfly_scC/no_control_run6
  Run 7/10... No actions provided, skipping action application.
Avg agent reward (episode): -911672.812 | Total reward: -911672.812
Saved run 7 to rl_training/butterfly_scC/no_control_run7
  Run 8/10... No actions provided, skipping action application.
Avg agent reward (episode): -816960.875 | Total reward: -816960.875
Saved run 8 to rl_training/butterfly_scC/no_control_run8
  Run 9/10... No actions provided, skipping action application.
Avg agent reward (episode): -838304.125 | Total reward: -838304.125
Saved run 9 to rl_training/butterfly_scC/no_control_run9
  Run 10/10... No actions provided, skipping action application.
Avg agent reward (episode): -722990.250 | Total reward: -722990.250
Saved run 10 to rl_training/butterfly_scC/no_control_run10
============================================================
Evaluation Results
  Number of runs: 10
============================================================
  Agent gate_2: -824091.375 ± 94138.289
  Average reward: -824091.375 ± 94138.289
  Total reward: -824091.375 ± 94138.289
============================================================

============================================================
Comparison of All Methods
============================================================
ppo avg reward:        -1103214.250
Rule-based avg reward: -865190.125
No control avg reward: -824091.375
============================================================
/Users/mmai/anaconda3/envs/control/lib/python3.11/site-packages/matplotlib/patches.py:3421: RuntimeWarning: invalid value encountered in scalar divide
  cos_t, sin_t = head_length / head_dist, head_width / head_dist
